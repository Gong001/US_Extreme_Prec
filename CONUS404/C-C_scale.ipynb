{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c6051e-761c-4969-9d14-c6ee213b9c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### automatically refresh the buffer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### solve the auto-complete issue\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "### lvl 2 setups (systerm)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pylab import *\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Wedge, Circle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0cf74fe-4f14-4665-a355-f1a647305358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-17 01:25:28\n",
      "2025-02-17 01:25:59\n",
      "2025-02-17 01:26:21\n",
      "2025-02-17 01:26:46\n",
      "2025-02-17 01:27:08\n",
      "2025-02-17 01:27:33\n",
      "2025-02-17 01:27:52\n",
      "2025-02-17 01:28:09\n",
      "2025-02-17 01:28:27\n",
      "2025-02-17 01:28:46\n",
      "2025-02-17 01:29:05\n",
      "2025-02-17 01:29:27\n",
      "2025-02-17 01:29:46\n",
      "2025-02-17 01:30:06\n",
      "2025-02-17 01:30:28\n",
      "2025-02-17 01:30:49\n",
      "2025-02-17 01:31:08\n",
      "2025-02-17 01:31:31\n",
      "2025-02-17 01:31:54\n",
      "2025-02-17 01:32:24\n",
      "2025-02-17 01:32:48\n",
      "2025-02-17 01:33:15\n",
      "2025-02-17 01:33:36\n",
      "2025-02-17 01:34:01\n",
      "2025-02-17 01:34:21\n",
      "2025-02-17 01:34:51\n",
      "2025-02-17 01:35:17\n",
      "2025-02-17 01:35:31\n",
      "2025-02-17 01:36:04\n",
      "2025-02-17 01:36:25\n",
      "2025-02-17 01:36:48\n",
      "2025-02-17 01:37:11\n",
      "2025-02-17 01:37:13\n",
      "2025-02-17 01:37:31\n",
      "2025-02-17 01:37:50\n",
      "2025-02-17 01:38:13\n",
      "2025-02-17 01:38:36\n",
      "2025-02-17 01:39:09\n",
      "2025-02-17 01:39:34\n",
      "2025-02-17 01:39:54\n",
      "2025-02-17 01:40:15\n",
      "2025-02-17 01:40:36\n",
      "2025-02-17 01:40:58\n",
      "2025-02-17 01:41:24\n",
      "2025-02-17 01:41:51\n",
      "2025-02-17 01:42:13\n",
      "2025-02-17 01:42:39\n",
      "2025-02-17 01:43:05\n",
      "2025-02-17 01:43:30\n",
      "2025-02-17 01:43:56\n",
      "2025-02-17 01:44:15\n",
      "2025-02-17 01:44:42\n",
      "2025-02-17 01:45:09\n",
      "2025-02-17 01:45:37\n",
      "2025-02-17 01:46:03\n",
      "2025-02-17 01:46:30\n",
      "2025-02-17 01:46:58\n",
      "2025-02-17 01:47:22\n",
      "2025-02-17 01:47:49\n",
      "2025-02-17 01:48:16\n",
      "2025-02-17 01:48:40\n",
      "2025-02-17 01:49:05\n",
      "2025-02-17 01:49:31\n",
      "2025-02-17 01:49:34\n",
      "2025-02-17 01:49:58\n",
      "2025-02-17 01:50:26\n",
      "2025-02-17 01:50:55\n",
      "2025-02-17 01:51:22\n",
      "2025-02-17 01:51:52\n",
      "2025-02-17 01:52:20\n",
      "2025-02-17 01:52:46\n",
      "2025-02-17 01:53:11\n",
      "2025-02-17 01:53:34\n",
      "2025-02-17 01:54:00\n",
      "2025-02-17 01:54:30\n",
      "2025-02-17 01:54:54\n",
      "2025-02-17 01:55:27\n",
      "2025-02-17 01:55:57\n",
      "2025-02-17 01:56:25\n",
      "2025-02-17 01:56:51\n",
      "2025-02-17 01:57:20\n",
      "2025-02-17 01:57:45\n",
      "2025-02-17 01:58:15\n",
      "2025-02-17 01:58:44\n",
      "2025-02-17 01:59:12\n",
      "2025-02-17 01:59:41\n",
      "2025-02-17 02:00:10\n",
      "2025-02-17 02:00:37\n",
      "2025-02-17 02:01:05\n",
      "2025-02-17 02:01:35\n",
      "2025-02-17 02:02:04\n",
      "2025-02-17 02:02:31\n",
      "2025-02-17 02:02:59\n",
      "2025-02-17 02:03:28\n",
      "2025-02-17 02:03:59\n",
      "2025-02-17 02:04:02\n",
      "2025-02-17 02:04:27\n",
      "2025-02-17 02:04:56\n",
      "2025-02-17 02:05:27\n",
      "2025-02-17 02:05:54\n",
      "2025-02-17 02:06:18\n",
      "2025-02-17 02:06:43\n",
      "2025-02-17 02:07:15\n",
      "2025-02-17 02:07:47\n",
      "2025-02-17 02:08:23\n",
      "2025-02-17 02:08:59\n",
      "2025-02-17 02:09:24\n",
      "2025-02-17 02:09:57\n",
      "2025-02-17 02:10:29\n",
      "2025-02-17 02:11:00\n",
      "2025-02-17 02:11:35\n",
      "2025-02-17 02:12:09\n",
      "2025-02-17 02:12:41\n",
      "2025-02-17 02:13:12\n",
      "2025-02-17 02:13:43\n",
      "2025-02-17 02:14:18\n",
      "2025-02-17 02:14:52\n",
      "2025-02-17 02:15:22\n",
      "2025-02-17 02:15:54\n",
      "2025-02-17 02:16:28\n",
      "2025-02-17 02:17:10\n",
      "2025-02-17 02:17:42\n",
      "2025-02-17 02:18:08\n",
      "2025-02-17 02:18:44\n",
      "2025-02-17 02:19:25\n",
      "2025-02-17 02:19:59\n",
      "2025-02-17 02:20:37\n",
      "2025-02-17 02:20:40\n",
      "2025-02-17 02:21:10\n",
      "2025-02-17 02:21:49\n",
      "2025-02-17 02:22:21\n",
      "2025-02-17 02:22:54\n",
      "2025-02-17 02:23:32\n",
      "2025-02-17 02:24:01\n",
      "2025-02-17 02:24:30\n",
      "2025-02-17 02:24:50\n",
      "2025-02-17 02:25:19\n",
      "2025-02-17 02:25:51\n",
      "2025-02-17 02:26:21\n",
      "2025-02-17 02:26:49\n",
      "2025-02-17 02:27:26\n",
      "2025-02-17 02:27:53\n",
      "2025-02-17 02:28:33\n",
      "2025-02-17 02:29:10\n",
      "2025-02-17 02:29:44\n",
      "2025-02-17 02:30:18\n",
      "2025-02-17 02:30:48\n",
      "2025-02-17 02:31:20\n",
      "2025-02-17 02:31:57\n",
      "2025-02-17 02:32:29\n",
      "2025-02-17 02:33:02\n",
      "2025-02-17 02:33:30\n",
      "2025-02-17 02:34:02\n",
      "2025-02-17 02:34:37\n",
      "2025-02-17 02:35:09\n",
      "2025-02-17 02:35:40\n",
      "2025-02-17 02:36:10\n",
      "2025-02-17 02:36:13\n",
      "2025-02-17 02:36:40\n",
      "2025-02-17 02:37:14\n",
      "2025-02-17 02:37:50\n",
      "2025-02-17 02:38:21\n",
      "2025-02-17 02:38:50\n",
      "2025-02-17 02:39:14\n",
      "2025-02-17 02:39:50\n",
      "2025-02-17 02:40:18\n",
      "2025-02-17 02:40:49\n",
      "2025-02-17 02:41:15\n",
      "2025-02-17 02:41:41\n",
      "2025-02-17 02:42:09\n",
      "2025-02-17 02:42:39\n",
      "2025-02-17 02:43:11\n",
      "2025-02-17 02:43:40\n",
      "2025-02-17 02:44:08\n",
      "2025-02-17 02:44:32\n",
      "2025-02-17 02:44:58\n",
      "2025-02-17 02:45:24\n",
      "2025-02-17 02:45:52\n",
      "2025-02-17 02:46:19\n",
      "2025-02-17 02:46:45\n",
      "2025-02-17 02:47:05\n",
      "2025-02-17 02:47:29\n",
      "2025-02-17 02:47:59\n",
      "2025-02-17 02:48:27\n",
      "2025-02-17 02:48:57\n",
      "2025-02-17 02:49:27\n",
      "2025-02-17 02:49:54\n",
      "2025-02-17 02:50:28\n",
      "2025-02-17 02:51:02\n",
      "2025-02-17 02:51:06\n",
      "2025-02-17 02:51:34\n",
      "2025-02-17 02:51:57\n",
      "2025-02-17 02:52:29\n",
      "2025-02-17 02:52:49\n",
      "2025-02-17 02:53:15\n",
      "2025-02-17 02:53:39\n",
      "2025-02-17 02:54:12\n",
      "2025-02-17 02:54:43\n",
      "2025-02-17 02:55:14\n",
      "2025-02-17 02:55:48\n",
      "2025-02-17 02:56:27\n",
      "2025-02-17 02:57:01\n",
      "2025-02-17 02:57:30\n",
      "2025-02-17 02:57:59\n",
      "2025-02-17 02:58:30\n",
      "2025-02-17 02:59:01\n",
      "2025-02-17 02:59:32\n",
      "2025-02-17 03:00:00\n",
      "2025-02-17 03:00:35\n",
      "2025-02-17 03:01:05\n",
      "2025-02-17 03:01:33\n",
      "2025-02-17 03:02:03\n",
      "2025-02-17 03:02:33\n",
      "2025-02-17 03:03:10\n",
      "2025-02-17 03:03:41\n",
      "2025-02-17 03:04:07\n",
      "2025-02-17 03:04:36\n",
      "2025-02-17 03:05:10\n",
      "2025-02-17 03:05:34\n",
      "2025-02-17 03:06:10\n",
      "2025-02-17 03:06:16\n",
      "2025-02-17 03:06:44\n",
      "2025-02-17 03:07:11\n",
      "2025-02-17 03:07:39\n",
      "2025-02-17 03:08:06\n",
      "2025-02-17 03:08:38\n",
      "2025-02-17 03:09:09\n",
      "2025-02-17 03:09:37\n",
      "2025-02-17 03:10:12\n",
      "2025-02-17 03:10:45\n",
      "2025-02-17 03:11:09\n",
      "2025-02-17 03:11:38\n",
      "2025-02-17 03:12:05\n",
      "2025-02-17 03:12:37\n",
      "2025-02-17 03:13:08\n",
      "2025-02-17 03:13:38\n",
      "2025-02-17 03:14:05\n",
      "2025-02-17 03:14:36\n",
      "2025-02-17 03:15:04\n",
      "2025-02-17 03:15:34\n",
      "2025-02-17 03:16:01\n",
      "2025-02-17 03:16:23\n",
      "2025-02-17 03:16:46\n",
      "2025-02-17 03:17:14\n",
      "2025-02-17 03:17:45\n",
      "2025-02-17 03:18:10\n",
      "2025-02-17 03:18:39\n",
      "2025-02-17 03:19:10\n",
      "2025-02-17 03:19:33\n",
      "2025-02-17 03:20:07\n",
      "2025-02-17 03:20:43\n",
      "2025-02-17 03:21:10\n",
      "2025-02-17 03:21:14\n",
      "2025-02-17 03:21:34\n",
      "2025-02-17 03:22:05\n",
      "2025-02-17 03:22:43\n",
      "2025-02-17 03:23:12\n",
      "2025-02-17 03:23:49\n",
      "2025-02-17 03:24:13\n",
      "2025-02-17 03:24:46\n",
      "2025-02-17 03:25:16\n",
      "2025-02-17 03:25:55\n",
      "2025-02-17 03:26:24\n",
      "2025-02-17 03:26:49\n",
      "2025-02-17 03:27:18\n",
      "2025-02-17 03:27:50\n",
      "2025-02-17 03:28:21\n",
      "2025-02-17 03:28:51\n",
      "2025-02-17 03:29:18\n",
      "2025-02-17 03:29:42\n",
      "2025-02-17 03:30:13\n",
      "2025-02-17 03:30:40\n",
      "2025-02-17 03:31:06\n",
      "2025-02-17 03:31:32\n",
      "2025-02-17 03:32:01\n",
      "2025-02-17 03:32:31\n",
      "2025-02-17 03:32:58\n",
      "2025-02-17 03:33:27\n",
      "2025-02-17 03:33:52\n",
      "2025-02-17 03:34:22\n",
      "2025-02-17 03:34:49\n",
      "2025-02-17 03:35:23\n",
      "2025-02-17 03:35:49\n",
      "2025-02-17 03:35:55\n",
      "2025-02-17 03:36:15\n",
      "2025-02-17 03:36:43\n",
      "2025-02-17 03:37:17\n",
      "2025-02-17 03:37:43\n",
      "2025-02-17 03:38:12\n",
      "2025-02-17 03:38:51\n",
      "2025-02-17 03:39:28\n",
      "2025-02-17 03:39:57\n",
      "2025-02-17 03:40:26\n",
      "2025-02-17 03:40:56\n",
      "2025-02-17 03:41:24\n",
      "2025-02-17 03:41:51\n",
      "2025-02-17 03:42:34\n",
      "2025-02-17 03:43:08\n",
      "2025-02-17 03:43:38\n",
      "2025-02-17 03:44:06\n",
      "2025-02-17 03:44:30\n",
      "2025-02-17 03:44:52\n",
      "2025-02-17 03:45:17\n",
      "2025-02-17 03:45:46\n",
      "2025-02-17 03:46:09\n",
      "2025-02-17 03:46:40\n",
      "2025-02-17 03:47:12\n",
      "2025-02-17 03:47:44\n",
      "2025-02-17 03:48:15\n",
      "2025-02-17 03:48:43\n",
      "2025-02-17 03:49:13\n",
      "2025-02-17 03:49:43\n",
      "2025-02-17 03:50:12\n",
      "2025-02-17 03:50:41\n",
      "2025-02-17 03:51:11\n",
      "2025-02-17 03:51:13\n",
      "2025-02-17 03:51:44\n",
      "2025-02-17 03:52:14\n",
      "2025-02-17 03:52:40\n",
      "2025-02-17 03:53:09\n",
      "2025-02-17 03:53:39\n",
      "2025-02-17 03:54:05\n",
      "2025-02-17 03:54:36\n",
      "2025-02-17 03:55:11\n",
      "2025-02-17 03:55:38\n",
      "2025-02-17 03:56:03\n",
      "2025-02-17 03:56:34\n",
      "2025-02-17 03:57:00\n",
      "2025-02-17 03:57:26\n",
      "2025-02-17 03:57:58\n",
      "2025-02-17 03:58:29\n",
      "2025-02-17 03:58:58\n",
      "2025-02-17 03:59:30\n",
      "2025-02-17 03:59:58\n",
      "2025-02-17 04:00:27\n",
      "2025-02-17 04:00:57\n",
      "2025-02-17 04:01:31\n",
      "2025-02-17 04:01:57\n",
      "2025-02-17 04:02:22\n",
      "2025-02-17 04:02:59\n",
      "2025-02-17 04:03:26\n",
      "2025-02-17 04:04:01\n",
      "2025-02-17 04:04:28\n",
      "2025-02-17 04:04:59\n",
      "2025-02-17 04:05:38\n",
      "2025-02-17 04:06:08\n",
      "2025-02-17 04:06:33\n",
      "2025-02-17 04:06:39\n",
      "2025-02-17 04:07:09\n",
      "2025-02-17 04:07:43\n",
      "2025-02-17 04:08:08\n",
      "2025-02-17 04:08:42\n",
      "2025-02-17 04:09:05\n",
      "2025-02-17 04:09:33\n",
      "2025-02-17 04:10:08\n",
      "2025-02-17 04:10:39\n",
      "2025-02-17 04:11:11\n",
      "2025-02-17 04:11:37\n",
      "2025-02-17 04:12:09\n",
      "2025-02-17 04:12:42\n",
      "2025-02-17 04:13:13\n",
      "2025-02-17 04:13:38\n",
      "2025-02-17 04:14:12\n",
      "2025-02-17 04:14:40\n",
      "2025-02-17 04:15:04\n",
      "2025-02-17 04:15:28\n",
      "2025-02-17 04:15:49\n",
      "2025-02-17 04:16:13\n",
      "2025-02-17 04:16:43\n",
      "2025-02-17 04:17:07\n",
      "2025-02-17 04:17:35\n",
      "2025-02-17 04:18:00\n",
      "2025-02-17 04:18:36\n",
      "2025-02-17 04:19:02\n",
      "2025-02-17 04:19:28\n",
      "2025-02-17 04:19:50\n",
      "2025-02-17 04:20:14\n",
      "2025-02-17 04:20:46\n",
      "2025-02-17 04:20:50\n",
      "2025-02-17 04:21:16\n",
      "2025-02-17 04:21:51\n",
      "2025-02-17 04:22:24\n",
      "2025-02-17 04:22:50\n",
      "2025-02-17 04:23:10\n",
      "2025-02-17 04:23:37\n",
      "2025-02-17 04:24:03\n",
      "2025-02-17 04:24:29\n",
      "2025-02-17 04:25:01\n",
      "2025-02-17 04:25:33\n",
      "2025-02-17 04:26:06\n",
      "2025-02-17 04:26:36\n",
      "2025-02-17 04:27:04\n",
      "2025-02-17 04:27:36\n",
      "2025-02-17 04:28:04\n",
      "2025-02-17 04:28:33\n",
      "2025-02-17 04:28:59\n",
      "2025-02-17 04:29:35\n",
      "2025-02-17 04:30:03\n",
      "2025-02-17 04:30:31\n",
      "2025-02-17 04:31:00\n",
      "2025-02-17 04:31:25\n",
      "2025-02-17 04:31:56\n",
      "2025-02-17 04:32:23\n",
      "2025-02-17 04:32:52\n",
      "2025-02-17 04:33:20\n",
      "2025-02-17 04:33:53\n",
      "2025-02-17 04:34:24\n",
      "2025-02-17 04:34:50\n",
      "2025-02-17 04:35:14\n",
      "2025-02-17 04:35:39\n",
      "2025-02-17 04:35:43\n",
      "2025-02-17 04:36:09\n",
      "2025-02-17 04:36:32\n",
      "2025-02-17 04:36:59\n",
      "2025-02-17 04:37:29\n",
      "2025-02-17 04:37:59\n",
      "2025-02-17 04:38:27\n",
      "2025-02-17 04:38:53\n",
      "2025-02-17 04:39:23\n",
      "2025-02-17 04:39:50\n",
      "2025-02-17 04:40:19\n",
      "2025-02-17 04:40:50\n",
      "2025-02-17 04:41:28\n",
      "2025-02-17 04:41:56\n",
      "2025-02-17 04:42:25\n",
      "2025-02-17 04:42:50\n",
      "2025-02-17 04:43:18\n",
      "2025-02-17 04:43:49\n",
      "2025-02-17 04:44:20\n",
      "2025-02-17 04:44:54\n",
      "2025-02-17 04:45:25\n",
      "2025-02-17 04:45:57\n",
      "2025-02-17 04:46:26\n",
      "2025-02-17 04:46:59\n",
      "2025-02-17 04:47:28\n",
      "2025-02-17 04:47:53\n",
      "2025-02-17 04:48:18\n",
      "2025-02-17 04:48:44\n",
      "2025-02-17 04:49:07\n",
      "2025-02-17 04:49:46\n",
      "2025-02-17 04:50:20\n",
      "2025-02-17 04:50:23\n",
      "2025-02-17 04:50:48\n",
      "2025-02-17 04:51:13\n",
      "2025-02-17 04:51:39\n",
      "2025-02-17 04:52:08\n",
      "2025-02-17 04:52:38\n",
      "2025-02-17 04:53:06\n",
      "2025-02-17 04:53:31\n",
      "2025-02-17 04:53:59\n",
      "2025-02-17 04:54:25\n",
      "2025-02-17 04:54:51\n",
      "2025-02-17 04:55:16\n",
      "2025-02-17 04:55:44\n",
      "2025-02-17 04:56:11\n",
      "2025-02-17 04:56:39\n",
      "2025-02-17 04:57:12\n",
      "2025-02-17 04:57:40\n",
      "2025-02-17 04:58:08\n",
      "2025-02-17 04:58:39\n",
      "2025-02-17 04:59:09\n",
      "2025-02-17 04:59:38\n",
      "2025-02-17 05:00:08\n",
      "2025-02-17 05:00:37\n",
      "2025-02-17 05:01:09\n",
      "2025-02-17 05:01:38\n",
      "2025-02-17 05:02:13\n",
      "2025-02-17 05:02:42\n",
      "2025-02-17 05:03:14\n",
      "2025-02-17 05:03:43\n",
      "2025-02-17 05:04:14\n",
      "2025-02-17 05:04:41\n",
      "2025-02-17 05:05:15\n",
      "2025-02-17 05:05:19\n",
      "2025-02-17 05:05:46\n",
      "2025-02-17 05:06:11\n",
      "2025-02-17 05:06:37\n",
      "2025-02-17 05:07:10\n",
      "2025-02-17 05:07:35\n",
      "2025-02-17 05:08:00\n",
      "2025-02-17 05:08:30\n",
      "2025-02-17 05:09:03\n",
      "2025-02-17 05:09:28\n",
      "2025-02-17 05:09:51\n",
      "2025-02-17 05:10:13\n",
      "2025-02-17 05:10:31\n",
      "2025-02-17 05:10:59\n",
      "2025-02-17 05:11:19\n",
      "2025-02-17 05:11:42\n",
      "2025-02-17 05:12:06\n",
      "2025-02-17 05:12:30\n",
      "2025-02-17 05:12:57\n",
      "2025-02-17 05:13:21\n",
      "2025-02-17 05:13:44\n",
      "2025-02-17 05:14:09\n",
      "2025-02-17 05:14:35\n",
      "2025-02-17 05:14:58\n",
      "2025-02-17 05:15:29\n",
      "2025-02-17 05:15:51\n",
      "2025-02-17 05:16:13\n",
      "2025-02-17 05:16:39\n",
      "2025-02-17 05:17:02\n",
      "2025-02-17 05:17:25\n",
      "2025-02-17 05:17:53\n",
      "2025-02-17 05:18:14\n",
      "2025-02-17 05:18:17\n",
      "2025-02-17 05:18:39\n",
      "2025-02-17 05:18:58\n",
      "2025-02-17 05:19:23\n",
      "2025-02-17 05:19:47\n",
      "2025-02-17 05:20:07\n",
      "2025-02-17 05:20:34\n",
      "2025-02-17 05:20:55\n",
      "2025-02-17 05:21:22\n",
      "2025-02-17 05:21:38\n",
      "2025-02-17 05:22:04\n",
      "2025-02-17 05:22:28\n",
      "2025-02-17 05:22:52\n",
      "2025-02-17 05:23:21\n",
      "2025-02-17 05:23:41\n",
      "2025-02-17 05:24:07\n",
      "2025-02-17 05:24:35\n",
      "2025-02-17 05:25:04\n",
      "2025-02-17 05:25:27\n",
      "2025-02-17 05:25:50\n",
      "2025-02-17 05:26:17\n",
      "2025-02-17 05:26:41\n",
      "2025-02-17 05:27:08\n",
      "2025-02-17 05:27:37\n",
      "2025-02-17 05:28:04\n",
      "2025-02-17 05:28:27\n",
      "2025-02-17 05:28:56\n",
      "2025-02-17 05:29:21\n",
      "2025-02-17 05:29:52\n",
      "2025-02-17 05:29:55\n",
      "2025-02-17 05:30:15\n",
      "2025-02-17 05:30:42\n",
      "2025-02-17 05:31:07\n",
      "2025-02-17 05:31:35\n",
      "2025-02-17 05:32:05\n",
      "2025-02-17 05:32:32\n",
      "2025-02-17 05:32:57\n",
      "2025-02-17 05:33:28\n",
      "2025-02-17 05:33:50\n",
      "2025-02-17 05:34:16\n",
      "2025-02-17 05:34:35\n",
      "2025-02-17 05:35:00\n",
      "2025-02-17 05:35:20\n",
      "2025-02-17 05:35:41\n",
      "2025-02-17 05:36:06\n",
      "2025-02-17 05:36:27\n",
      "2025-02-17 05:36:58\n",
      "2025-02-17 05:37:23\n",
      "2025-02-17 05:37:52\n",
      "2025-02-17 05:38:15\n",
      "2025-02-17 05:38:35\n",
      "2025-02-17 05:39:48\n",
      "2025-02-17 05:40:10\n",
      "2025-02-17 05:40:37\n",
      "2025-02-17 05:41:00\n",
      "2025-02-17 05:41:28\n",
      "2025-02-17 05:41:52\n",
      "2025-02-17 05:42:21\n",
      "2025-02-17 05:42:47\n",
      "2025-02-17 05:43:12\n",
      "2025-02-17 05:43:38\n",
      "2025-02-17 05:43:40\n",
      "2025-02-17 05:44:01\n",
      "2025-02-17 05:44:28\n",
      "2025-02-17 05:44:55\n",
      "2025-02-17 05:45:20\n",
      "2025-02-17 05:45:43\n",
      "2025-02-17 05:46:10\n",
      "2025-02-17 05:46:37\n",
      "2025-02-17 05:47:02\n",
      "2025-02-17 05:47:24\n",
      "2025-02-17 05:47:46\n",
      "2025-02-17 05:48:11\n",
      "2025-02-17 05:48:35\n",
      "2025-02-17 05:49:05\n",
      "2025-02-17 05:49:27\n",
      "2025-02-17 05:49:50\n",
      "2025-02-17 05:50:18\n",
      "2025-02-17 05:50:45\n",
      "2025-02-17 05:51:30\n",
      "2025-02-17 05:51:49\n",
      "2025-02-17 05:52:11\n",
      "2025-02-17 05:52:36\n",
      "2025-02-17 05:53:01\n",
      "2025-02-17 05:53:22\n",
      "2025-02-17 05:53:45\n",
      "2025-02-17 05:54:04\n",
      "2025-02-17 05:54:27\n",
      "2025-02-17 05:54:51\n",
      "2025-02-17 05:55:15\n",
      "2025-02-17 05:55:43\n",
      "2025-02-17 05:56:10\n",
      "2025-02-17 05:56:16\n",
      "2025-02-17 05:56:34\n",
      "2025-02-17 05:57:02\n",
      "2025-02-17 05:57:32\n",
      "2025-02-17 05:57:55\n",
      "2025-02-17 05:58:21\n",
      "2025-02-17 05:58:52\n",
      "2025-02-17 05:59:25\n",
      "2025-02-17 05:59:49\n",
      "2025-02-17 06:00:10\n",
      "2025-02-17 06:00:33\n",
      "2025-02-17 06:00:57\n",
      "2025-02-17 06:01:25\n",
      "2025-02-17 06:01:48\n",
      "2025-02-17 06:02:14\n",
      "2025-02-17 06:02:36\n",
      "2025-02-17 06:03:05\n",
      "2025-02-17 06:03:35\n",
      "2025-02-17 06:04:06\n",
      "2025-02-17 06:04:26\n",
      "2025-02-17 06:04:51\n",
      "2025-02-17 06:05:18\n",
      "2025-02-17 06:05:42\n",
      "2025-02-17 06:06:06\n",
      "2025-02-17 06:06:35\n",
      "2025-02-17 06:07:00\n",
      "2025-02-17 06:07:25\n",
      "2025-02-17 06:07:46\n",
      "2025-02-17 06:08:09\n",
      "2025-02-17 06:08:33\n",
      "2025-02-17 06:08:55\n",
      "2025-02-17 06:09:17\n",
      "2025-02-17 06:09:20\n",
      "2025-02-17 06:09:40\n",
      "2025-02-17 06:10:04\n",
      "2025-02-17 06:10:28\n",
      "2025-02-17 06:10:50\n",
      "2025-02-17 06:11:13\n",
      "2025-02-17 06:11:36\n",
      "2025-02-17 06:12:07\n",
      "2025-02-17 06:12:38\n",
      "2025-02-17 06:13:00\n",
      "2025-02-17 06:13:18\n",
      "2025-02-17 06:13:45\n",
      "2025-02-17 06:14:09\n",
      "2025-02-17 06:14:36\n",
      "2025-02-17 06:15:04\n",
      "2025-02-17 06:15:33\n",
      "2025-02-17 06:15:54\n",
      "2025-02-17 06:16:21\n",
      "2025-02-17 06:16:46\n",
      "2025-02-17 06:17:02\n",
      "2025-02-17 06:17:22\n",
      "2025-02-17 06:17:47\n",
      "2025-02-17 06:18:09\n",
      "2025-02-17 06:18:33\n",
      "2025-02-17 06:19:04\n",
      "2025-02-17 06:19:30\n",
      "2025-02-17 06:19:58\n",
      "2025-02-17 06:20:21\n",
      "2025-02-17 06:20:45\n",
      "2025-02-17 06:21:15\n",
      "2025-02-17 06:21:44\n",
      "2025-02-17 06:21:48\n",
      "2025-02-17 06:22:10\n",
      "2025-02-17 06:22:37\n",
      "2025-02-17 06:22:59\n",
      "2025-02-17 06:23:29\n",
      "2025-02-17 06:23:57\n",
      "2025-02-17 06:24:21\n",
      "2025-02-17 06:24:44\n",
      "2025-02-17 06:25:07\n",
      "2025-02-17 06:25:32\n",
      "2025-02-17 06:25:59\n",
      "2025-02-17 06:26:27\n",
      "2025-02-17 06:26:55\n",
      "2025-02-17 06:27:17\n",
      "2025-02-17 06:27:39\n",
      "2025-02-17 06:28:01\n",
      "2025-02-17 06:28:22\n",
      "2025-02-17 06:28:43\n",
      "2025-02-17 06:29:04\n",
      "2025-02-17 06:29:24\n",
      "2025-02-17 06:29:50\n",
      "2025-02-17 06:30:18\n",
      "2025-02-17 06:30:43\n",
      "2025-02-17 06:31:02\n",
      "2025-02-17 06:31:28\n",
      "2025-02-17 06:31:49\n",
      "2025-02-17 06:32:17\n",
      "2025-02-17 06:32:40\n",
      "2025-02-17 06:33:03\n",
      "2025-02-17 06:33:22\n",
      "2025-02-17 06:33:47\n",
      "2025-02-17 06:34:10\n",
      "2025-02-17 06:34:13\n",
      "2025-02-17 06:34:32\n",
      "2025-02-17 06:34:55\n",
      "2025-02-17 06:35:28\n",
      "2025-02-17 06:35:53\n",
      "2025-02-17 06:36:17\n",
      "2025-02-17 06:36:42\n",
      "2025-02-17 06:37:05\n",
      "2025-02-17 06:37:26\n",
      "2025-02-17 06:37:50\n",
      "2025-02-17 06:38:10\n",
      "2025-02-17 06:38:33\n",
      "2025-02-17 06:39:09\n",
      "2025-02-17 06:39:31\n",
      "2025-02-17 06:40:00\n",
      "2025-02-17 06:40:20\n",
      "2025-02-17 06:40:41\n",
      "2025-02-17 06:41:00\n",
      "2025-02-17 06:41:17\n",
      "2025-02-17 06:41:37\n",
      "2025-02-17 06:41:53\n",
      "2025-02-17 06:42:07\n",
      "2025-02-17 06:42:23\n",
      "2025-02-17 06:42:41\n",
      "2025-02-17 06:43:00\n",
      "2025-02-17 06:43:19\n",
      "2025-02-17 06:43:37\n",
      "2025-02-17 06:43:56\n",
      "2025-02-17 06:44:12\n",
      "2025-02-17 06:44:30\n",
      "2025-02-17 06:44:44\n",
      "2025-02-17 06:45:01\n",
      "2025-02-17 06:45:03\n",
      "2025-02-17 06:45:17\n",
      "2025-02-17 06:45:33\n",
      "2025-02-17 06:45:51\n",
      "2025-02-17 06:46:07\n",
      "2025-02-17 06:46:22\n",
      "2025-02-17 06:46:38\n",
      "2025-02-17 06:46:52\n",
      "2025-02-17 06:47:09\n",
      "2025-02-17 06:47:26\n",
      "2025-02-17 06:47:41\n",
      "2025-02-17 06:47:59\n",
      "2025-02-17 06:48:16\n",
      "2025-02-17 06:48:34\n",
      "2025-02-17 06:48:51\n",
      "2025-02-17 06:49:08\n",
      "2025-02-17 06:49:25\n",
      "2025-02-17 06:49:42\n",
      "2025-02-17 06:49:58\n",
      "2025-02-17 06:50:18\n",
      "2025-02-17 06:50:39\n",
      "2025-02-17 06:51:01\n",
      "2025-02-17 06:51:21\n",
      "2025-02-17 06:51:39\n",
      "2025-02-17 06:51:55\n",
      "2025-02-17 06:52:17\n",
      "2025-02-17 06:52:39\n",
      "2025-02-17 06:52:57\n",
      "2025-02-17 06:53:12\n",
      "2025-02-17 06:53:27\n",
      "2025-02-17 06:53:47\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('/N/project/Zli_lab/Data/Other/tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/prec_acc_files/'\n",
    "\n",
    "start_year = 2011\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "            ds_era = xr.Dataset({'p': (['time', 'latitude', 'longitude'], ds.PREC_ACC_NC.values)},\n",
    "                                coords={'longitude': (['longitude'], ds.XLONG.values[500]),\n",
    "                                        'latitude': (['latitude'], ds.XLAT.values[:,500]),\n",
    "                                        'time': ('time', ds.Time.values)})\n",
    "            ds_era_lon, ds_era_lat = np.meshgrid(ds_era.longitude.values, ds_era.latitude.values, indexing='xy')\n",
    "            # 转换为 xarray DataArray，确保其维度与 ds_era_clipped 对齐\n",
    "            ds_era_lon_da = xr.DataArray(ds_era_lon, dims=(\"latitude\", \"longitude\"), coords={\"latitude\": ds_era.latitude, \"longitude\": ds_era.longitude})\n",
    "            ds_era_lat_da = xr.DataArray(ds_era_lat, dims=(\"latitude\", \"longitude\"), coords={\"latitude\": ds_era.latitude, \"longitude\": ds_era.longitude})\n",
    "\n",
    "            # 使用 assign_coords 将二维坐标添加到 ds_era_clipped\n",
    "            ds_era_clipped = ds_era.assign_coords(lon_2d=ds_era_lon_da, lat_2d=ds_era_lat_da)\n",
    "\n",
    "            lon = ds_era_clipped['lon_2d'].values\n",
    "            lat = ds_era_clipped['lat_2d'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "\n",
    "            mask = np.full(ds_era_clipped['p'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds_era_clipped['p'].dims[1:], coords={'latitude': ds_era_clipped['p'].coords['latitude'], 'longitude': ds_era_clipped['p'].coords['longitude']})\n",
    "            ds_sss = ds_era_clipped.where(mask_da, drop=True)\n",
    "            ds_sss = ds_sss.drop_vars(['lon_2d', 'lat_2d'])\n",
    "\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.longitude >= lon_min) & (ds_sss.longitude < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.latitude.size > 0 and ds_lon_subset.longitude.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.latitude.min().values\n",
    "                    lat_max = ds_lon_subset.latitude.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "                    \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.latitude >= lat_min_split) & (ds_lon_subset.latitude < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '/N/project/Zli_lab/gongg/CONUS404_data/LST/re_UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cc109-a935-4527-964b-4a305cf9fea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49dac4f-3423-4aa3-a14e-4aeebb4be781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db6e585-df97-4bf3-bfc3-368b09f14b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdf670-8d30-4732-98d3-1e4abca972a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d7a22-5785-419c-85cd-9787a499bd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14462953-e4c4-47a4-afbd-3c7742bb4e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "612ac8b9-547d-411a-8b0d-15d161838db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_dn_averages(data, block_size=12):\n",
    "    \"\"\"\n",
    "    计算每个时间块的平均温度值。\n",
    "\n",
    "    参数:\n",
    "    data -- 输入的温度数据数组。\n",
    "    block_size -- 每个时间块的大小（默认为12个月）。\n",
    "\n",
    "    返回:\n",
    "    包含平均温度值的新数组，形状与输入数组相同。\n",
    "    \"\"\"\n",
    "    # 创建一个形状相同的数组来存放结果，所有元素初始化为 NaN\n",
    "    arr_t_dn = np.full_like(data, np.nan)\n",
    "    \n",
    "    # 循环处理每个位置的数据\n",
    "    for i in range(data.shape[1]):\n",
    "\n",
    "        for j in range(data.shape[2]):\n",
    "            for k in range(data.shape[0] // block_size):\n",
    "                # 选择第k个时间块的数据块进行平均\n",
    "                arr_t_avg = np.mean(data[k*block_size:(k+1)*block_size, i, j])\n",
    "                # 将平均结果填充到新数组的相应位置\n",
    "                arr_t_dn[k*block_size:(k+1)*block_size, i, j] = arr_t_avg\n",
    "\n",
    "    return arr_t_dn\n",
    "\n",
    "# 使用示例：\n",
    "# 假设 ds_selected 是你的数据集，并且已经加载了需要的数据。\n",
    "# arr_t = ds_selected.t2.values\n",
    "# 计算平均值\n",
    "# result = calculate_monthly_averages(arr_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c1138e-5ada-4bd2-a7b3-3def4cb64ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_dn_t(array, dataset):\n",
    "    lonn = dataset.lon.values\n",
    "    latt = dataset.lat.values\n",
    "    timee = dataset.time.values\n",
    "    \n",
    "    ds_dn_t = xr.Dataset(\n",
    "        {'dnt': (['time', 'lat', 'lon'], array)},\n",
    "        coords={\n",
    "            'lon': (['lon'], lonn),\n",
    "            'lat': (['lat'], latt),\n",
    "            'time': ('time', timee)\n",
    "        }\n",
    "    )\n",
    "    return ds_dn_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf20f68-4f0d-4ee2-93e7-0d50c66918d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = '/N/project/Zli_lab/gongg/CONUS404_data/LST/UTC/'\n",
    "file_pattern_p = 'PREC_ACC_NC.wrf2d_d01_????-??-??.nc'\n",
    "file_pattern_t = 'T2.wrf2d_d01_????-??-??.nc'\n",
    "output_folder = '/N/project/Zli_lab/gongg/CONUS404_data/LST/JJA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "399fa498-d03e-4f29-bc53-a5cdd0b92147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_names = [\n",
    "   # 'U-50',\n",
    "    'U-51', 'U-52', 'U-53', 'U-54', 'U-55', 'U-56', 'U-57', 'U-58',\n",
    "    # 'U-60', 'U-61', 'U-62', 'U-63', 'U-64', 'U-65', 'U-66', 'U-67', 'U-68',\n",
    "    # 'U-70', 'U-71', 'U-72', 'U-73', 'U-74', 'U-75', 'U-76', 'U-77', 'U-78',\n",
    "    # 'U-80', 'U-81', 'U-82', 'U-83', 'U-84', 'U-85', 'U-86', 'U-87', 'U-88',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e6d7d54-6209-421c-965b-f5ce67846b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-27 16:13:58\n",
      "2024-12-27 16:53:35\n",
      "2024-12-27 17:32:56\n",
      "2024-12-27 18:11:18\n",
      "2024-12-27 18:48:48\n",
      "2024-12-27 19:27:41\n",
      "2024-12-27 20:05:14\n",
      "2024-12-27 20:44:10\n"
     ]
    }
   ],
   "source": [
    "for folder in folder_names:\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    full_path_t = os.path.join(base_path, folder, file_pattern_t)\n",
    "    all_files_t = glob.glob(full_path_t)\n",
    "    #####\n",
    "    summer_files_t = [f for f in all_files_t if '-06-' in f or '-07-' in f or '-08-' in f or '-09-' in f or '-05-' in f]\n",
    "    ds = xr.open_mfdataset(summer_files_t)\n",
    "    \n",
    "\n",
    "    # 构建时间选择器，每年的5月31日18:00到9月1日05:00\n",
    "    time_selection = (ds.time.dt.month == 5) & (ds.time.dt.day == 31) & (ds.time.dt.hour >= 18) | \\\n",
    "                     (ds.time.dt.month == 6) | \\\n",
    "                     (ds.time.dt.month == 7) | \\\n",
    "                     (ds.time.dt.month == 8) | \\\n",
    "                     ((ds.time.dt.month == 9) & (ds.time.dt.day == 1) & (ds.time.dt.hour <= 5))\n",
    "\n",
    "    # 应用时间选择器\n",
    "    ds_selected = ds.where(time_selection, drop=True)\n",
    "    arr_t = ds_selected.t2.values\n",
    "    arr_dnt = calculate_dn_averages(arr_t)\n",
    "    ds_dnt = cal_dn_t(arr_dnt, ds_selected)\n",
    "    ds_dnt_jja = ds_dnt.sel(time=ds_dnt['time'].dt.month.isin([6, 7, 8]))\n",
    "    ds_dnt_jja.to_netcdf(output_folder+'dn_temp_'+folder+'.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c950a49-4f8c-4ea5-a8ff-63d67944918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_dn_averages(data, block_size=12):\n",
    "    \"\"\"\n",
    "    计算每个时间块的平均温度值。\n",
    "\n",
    "    参数:\n",
    "    data -- 输入的温度数据数组。\n",
    "    block_size -- 每个时间块的大小（默认为12个月）。\n",
    "\n",
    "    返回:\n",
    "    包含平均温度值的新数组，形状与输入数组相同。\n",
    "    \"\"\"\n",
    "    # 创建一个形状相同的数组来存放结果，所有元素初始化为 NaN\n",
    "    arr_t_dn = np.full_like(data, np.nan)\n",
    "    \n",
    "    # 循环处理每个位置的数据\n",
    "    for i in range(data.shape[1]):\n",
    "        for j in range(data.shape[2]):\n",
    "            for k in range(data.shape[0] // block_size):\n",
    "                # 选择第k个时间块的数据块进行平均\n",
    "                arr_t_avg = np.mean(data[k*block_size:(k+1)*block_size, i, j])\n",
    "                # 将平均结果填充到新数组的相应位置\n",
    "                arr_t_dn[k*block_size:(k+1)*block_size, i, j] = arr_t_avg\n",
    "\n",
    "    return arr_t_dn\n",
    "\n",
    "# 使用示例：\n",
    "# 假设 ds_selected 是你的数据集，并且已经加载了需要的数据。\n",
    "# arr_t = ds_selected.t2.values\n",
    "# 计算平均值\n",
    "# result = calculate_monthly_averages(arr_t)\n",
    "\n",
    "def cal_dn_t(array, dataset):\n",
    "    lonn = dataset.lon.values\n",
    "    latt = dataset.lat.values\n",
    "    timee = dataset.time.values\n",
    "    \n",
    "    ds_dn_t = xr.Dataset(\n",
    "        {'dnt': (['time', 'lat', 'lon'], array)},\n",
    "        coords={\n",
    "            'lon': (['lon'], lonn),\n",
    "            'lat': (['lat'], latt),\n",
    "            'time': ('time', timee)\n",
    "        }\n",
    "    )\n",
    "    return ds_dn_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a324ee25-6f05-4ea5-9635-4c7dbb5c1af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = '/N/project/Zli_lab/gongg/CONUS404_data/LST/UTC/'\n",
    "file_pattern_p = 'PREC_ACC_NC.wrf2d_d01_????-??-??.nc'\n",
    "file_pattern_t = 'TD2.wrf2d_d01_????-??-??.nc'\n",
    "output_folder = '/N/project/Zli_lab/gongg/CONUS404_data/LST/JJA/'\n",
    "\n",
    "folder_names = [\n",
    "     'U-50', 'U-51', 'U-52', 'U-53', 'U-54', 'U-55', 'U-56', 'U-57', 'U-58',\n",
    "     #'U-60', 'U-61', 'U-62', 'U-63', 'U-64', 'U-65', 'U-66', 'U-67', 'U-68',\n",
    "    # 'U-70', 'U-71', 'U-72', 'U-73', 'U-74', 'U-75', 'U-76', 'U-77', 'U-78',\n",
    "    # 'U-80', 'U-81', 'U-82', 'U-83', 'U-84', 'U-85', 'U-86', 'U-87', 'U-88',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb106af-34b8-410c-8d4e-bf25d403d8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-29 00:48:59\n",
      "2024-12-29 01:27:38\n",
      "2024-12-29 02:05:22\n",
      "2024-12-29 02:43:01\n",
      "2024-12-29 03:19:52\n",
      "2024-12-29 03:55:21\n",
      "2024-12-29 04:30:53\n",
      "2024-12-29 05:07:16\n",
      "2024-12-29 05:43:24\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for folder in folder_names:\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    full_path_t = os.path.join(base_path, folder, file_pattern_t)\n",
    "    all_files_t = glob.glob(full_path_t)\n",
    "    #####\n",
    "    summer_files_t = [f for f in all_files_t if '-06-' in f or '-07-' in f or '-08-' in f or '-09-' in f or '-05-' in f]\n",
    "    ds = xr.open_mfdataset(summer_files_t)\n",
    "    \n",
    "\n",
    "    # 构建时间选择器，每年的5月31日18:00到9月1日05:00\n",
    "    time_selection = (ds.time.dt.month == 5) & (ds.time.dt.day == 31) & (ds.time.dt.hour >= 18) | \\\n",
    "                     (ds.time.dt.month == 6) | \\\n",
    "                     (ds.time.dt.month == 7) | \\\n",
    "                     (ds.time.dt.month == 8) | \\\n",
    "                     ((ds.time.dt.month == 9) & (ds.time.dt.day == 1) & (ds.time.dt.hour <= 5))\n",
    "\n",
    "    # 应用时间选择器\n",
    "    ds_selected = ds.where(time_selection, drop=True)\n",
    "    arr_t = ds_selected.td2.values\n",
    "    arr_dnt = calculate_dn_averages(arr_t)\n",
    "    ds_dnt = cal_dn_t(arr_dnt, ds_selected)\n",
    "    ds_dnt_jja = ds_dnt.sel(time=ds_dnt['time'].dt.month.isin([6, 7, 8]))\n",
    "    ds_dnt_jja.to_netcdf(output_folder+'dn_dewtemp_'+folder+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93773ed-d1a1-4a59-86fd-5a7f9a4dbd45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829b9b6-a279-4681-9984-f49f6e88b205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355db239-2c44-407e-b317-23b9ce6c737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 25.0% quantile:\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                 Scores   Pseudo R-squared:           -3.144e-05\n",
      "Model:                       QuantReg   Bandwidth:                       1861.\n",
      "Method:                 Least Squares   Sparsity:                        7538.\n",
      "Date:                Sun, 12 Jan 2025   No. Observations:                  100\n",
      "Time:                        15:15:23   Df Residuals:                       98\n",
      "                                        Df Model:                            1\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept  -1464.8099   1314.470     -1.114      0.268   -4073.333    1143.713\n",
      "Income        -0.0075      0.025     -0.305      0.761      -0.056       0.041\n",
      "==============================================================================\n",
      "\n",
      "The condition number is large, 2.19e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Results for 50.0% quantile:\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                 Scores   Pseudo R-squared:             0.003867\n",
      "Model:                       QuantReg   Bandwidth:                       2187.\n",
      "Method:                 Least Squares   Sparsity:                        5542.\n",
      "Date:                Sun, 12 Jan 2025   No. Observations:                  100\n",
      "Time:                        15:15:23   Df Residuals:                       98\n",
      "                                        Df Model:                            1\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   -774.1337   1146.787     -0.675      0.501   -3049.895    1501.628\n",
      "Income         0.0098      0.022      0.454      0.651      -0.033       0.053\n",
      "==============================================================================\n",
      "\n",
      "The condition number is large, 2.19e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Results for 75.0% quantile:\n",
      "                         QuantReg Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                 Scores   Pseudo R-squared:             -0.01614\n",
      "Model:                       QuantReg   Bandwidth:                       2003.\n",
      "Method:                 Least Squares   Sparsity:                        5800.\n",
      "Date:                Sun, 12 Jan 2025   No. Observations:                  100\n",
      "Time:                        15:15:23   Df Residuals:                       98\n",
      "                                        Df Model:                            1\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   -413.1158   1219.379     -0.339      0.735   -2832.934    2006.702\n",
      "Income         0.0135      0.024      0.571      0.569      -0.033       0.060\n",
      "==============================================================================\n",
      "\n",
      "The condition number is large, 2.19e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/gongg/Quartz/.local/lib/python3.11/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n",
      "/N/u/gongg/Quartz/.local/lib/python3.11/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# 假设有一个DataFrame名为df，包含'Income'和'Scores'两列\n",
    "data = {\n",
    "    'Income': np.random.normal(50000, 15000, 100),\n",
    "    'Scores': np.random.normal(75, 10, 100) + np.random.normal(0, 0.05, 100) * np.random.normal(50000, 15000, 100)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 分位数回归：分别对25%，50%，75%分位数进行回归\n",
    "quantiles = [0.25, 0.5, 0.75]\n",
    "models = {}\n",
    "results = {}\n",
    "for qt in quantiles:\n",
    "    models[qt] = smf.quantreg('Scores ~ Income', df)\n",
    "    results[qt] = models[qt].fit(q=qt)\n",
    "    print(f'Results for {qt*100}% quantile:')\n",
    "    print(results[qt].summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a2b87d-79b3-4641-9142-0108bbd3b796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
