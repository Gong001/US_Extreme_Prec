{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0eaa9d5-0bed-4420-8fda-747f320d4b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "from pylab import *\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Wedge, Circle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "485d86e1-b7ab-4c5c-9323-3477135b12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ref = xr.open_dataset('/N/project/Zli_lab/gongg/regrid/ref_.1deg.nc')\n",
    "\n",
    "lat_min = float(ds_ref.lat.min())\n",
    "lat_max = float(ds_ref.lat.max())\n",
    "lon_min = float(ds_ref.lon.min())\n",
    "lon_max = float(ds_ref.lon.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d201dc1c-c76f-43ea-bc6e-42f40ff228c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    '/N/project/Zli_lab/amulla/JJA/ERA5_land_data_recalculated/Hourly_Total_Precipitation_T_06*',\n",
    "    '/N/project/Zli_lab/amulla/JJA/ERA5_land_data_recalculated/Hourly_Total_Precipitation_T_07*',\n",
    "    '/N/project/Zli_lab/amulla/JJA/ERA5_land_data_recalculated/Hourly_Total_Precipitation_T_08*',\n",
    "    '/N/project/Zli_lab/amulla/JJA/ERA5_land_data_recalculated/Hourly_Total_Precipitation_T_09*'\n",
    "]\n",
    "\n",
    "all_files = []\n",
    "\n",
    "for pattern in paths:\n",
    "    files = glob.glob(pattern)\n",
    "    all_files.extend(files)\n",
    "all_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe848fe-6f55-4140-9c51-af314c6d00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_era = xr.open_dataset('/N/project/Zli_lab/amulla/JJA/ERA5_land_data_recalculated/Hourly_Total_Precipitation_T_122022.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff847ef-af66-4a29-96e6-557d6696c0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 863MB\n",
      "Dimensions:  (time: 744, lat: 250, lon: 580)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 6kB 2022-12-01 ... 2022-12-31T23:00:00\n",
      "  * lon      (lon) float32 2kB -124.8 -124.7 -124.6 -124.5 ... -67.1 -67.0 -66.9\n",
      "  * lat      (lat) float32 1kB 24.4 24.5 24.6 24.7 24.8 ... 49.0 49.1 49.2 49.3\n",
      "Data variables:\n",
      "    tp       (time, lat, lon) float64 863MB nan nan nan nan ... nan nan nan nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ds_era_sorted = ds_era.sortby(\"latitude\")\n",
    "ds_era_sub = ds_era_sorted.sel(\n",
    "    latitude=slice(lat_min, lat_max),\n",
    "    longitude=slice(lon_min, lon_max)\n",
    ")\n",
    "\n",
    "ds_era_sub = ds_era_sub.rename({\"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "ds_era_sub[\"tp\"] = ds_era_sub[\"tp\"] * 1000\n",
    "mask_nan = ds_ref[\"tp\"].isel(time=0).isnull()\n",
    "ds_era_sub = ds_era_sub.where(~mask_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc7500-df46-4d30-b130-708ee7aeacfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17f4c8-813b-4404-8adf-d3241b1e4371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa59b7b6-13d9-419f-8cb5-ba1a99a0ced4",
   "metadata": {},
   "source": [
    "### do not run this again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9873f91-73b2-4f21-add2-396dec40dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-26 22:09:08.296707\n",
      "2025-03-26 22:09:39.035494\n",
      "2025-03-26 22:10:08.740201\n",
      "2025-03-26 22:10:41.006497\n",
      "2025-03-26 22:11:13.440162\n",
      "2025-03-26 22:11:45.754505\n",
      "2025-03-26 22:12:18.746613\n",
      "2025-03-26 22:12:52.638568\n",
      "2025-03-26 22:13:25.778202\n",
      "2025-03-26 22:13:59.197229\n",
      "2025-03-26 22:14:33.834998\n",
      "2025-03-26 22:15:07.132316\n",
      "2025-03-26 22:15:40.927022\n",
      "2025-03-26 22:16:13.587624\n",
      "2025-03-26 22:16:46.063476\n",
      "2025-03-26 22:17:19.839924\n",
      "2025-03-26 22:18:09.446278\n",
      "2025-03-26 22:19:00.115666\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------------------\n",
    "# 1. 利用 glob 获取所有目标文件并排序\n",
    "# ---------------------------\n",
    "patterns = [\n",
    "    '/N/project/Zli_lab/amulla/JJA/ERA5_land_data_recalculated/Hourly_Total_Precipitation_T_06*',\n",
    "    '/N/project/Zli_lab/amulla/JJA/ERA5_land_data_recalculated/Hourly_Total_Precipitation_T_07*',\n",
    "    '/N/project/Zli_lab/amulla/JJA/ERA5_land_data_recalculated/Hourly_Total_Precipitation_T_08*',\n",
    "    '/N/project/Zli_lab/amulla/JJA/ERA5_land_data_recalculated/Hourly_Total_Precipitation_T_09*'\n",
    "]\n",
    "\n",
    "all_files = []\n",
    "for pattern in patterns:\n",
    "    all_files.extend(glob.glob(pattern))\n",
    "all_files.sort()\n",
    "\n",
    "# ---------------------------\n",
    "# 2. 加载 ds_ref，用于获取裁剪区域与生成掩膜\n",
    "# ---------------------------\n",
    "# 请根据实际情况修改 ds_ref 的文件路径\n",
    "ds_ref = xr.open_dataset('/N/project/Zli_lab/gongg/regrid/ref_.1deg.nc')\n",
    "lat_min = float(ds_ref.lat.min())\n",
    "lat_max = float(ds_ref.lat.max())\n",
    "lon_min = float(ds_ref.lon.min())\n",
    "lon_max = float(ds_ref.lon.max())\n",
    "mask_nan = ds_ref[\"tp\"].isel(time=0).isnull()\n",
    "\n",
    "# 输出文件存储目录\n",
    "output_dir = \"/N/project/Zli_lab/gongg/ERA_data/LST\"\n",
    "\n",
    "# ---------------------------\n",
    "# 3. 定义经度区间及对应的 UTC 偏移量\n",
    "# ---------------------------\n",
    "lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "utc_offsets = [-8, -7, -6, -5]\n",
    "\n",
    "# ---------------------------\n",
    "# 4. 遍历每个 ds_era 文件并处理\n",
    "# ---------------------------\n",
    "for i, file in enumerate(all_files, start=1):\n",
    "    ds_era = xr.open_dataset(file)\n",
    "    ds_era_sorted = ds_era.sortby(\"latitude\")\n",
    "    \n",
    "    ds_era_sub = ds_era_sorted.sel(\n",
    "        latitude=slice(lat_min, lat_max),\n",
    "        longitude=slice(lon_min, lon_max)\n",
    "    )\n",
    "    ds_era_sub = ds_era_sub.rename({\"latitude\": \"lat\", \"longitude\": \"lon\"})\n",
    "    ds_era_sub[\"tp\"] = ds_era_sub[\"tp\"] * 1000\n",
    "    ds_era_sub = ds_era_sub.where(~mask_nan)\n",
    "    \n",
    "    # 提取年月（yyyymm），这里取 time 坐标中第一个时间点\n",
    "    yyyymm = ds_era_sub.time.dt.strftime('%Y%m').values[0]\n",
    "    \n",
    "    for (lon_min_range, lon_max_range), offset in zip(lon_ranges, utc_offsets):\n",
    "        mask = (ds_era_sub.lon >= lon_min_range) & (ds_era_sub.lon < lon_max_range)\n",
    "        ds_lon_subset = ds_era_sub.where(mask, drop=True)\n",
    "        if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            original_times = ds_lon_subset.time\n",
    "            adjusted_times = original_times + np.timedelta64(offset, 'h')\n",
    "            ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "            output_filename = f\"{yyyymm}_U-{abs(offset)}.nc\"\n",
    "            output_path = f\"{output_dir}/{output_filename}\"\n",
    "            ds_lon_subset.to_netcdf(output_path)\n",
    "    \n",
    "    # 每处理10个文件，打印一次当前时间\n",
    "    if i % 10 == 0:\n",
    "        print(datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a82044-7ba5-4856-b8a3-be646ac35ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c93a1-0693-4ba4-ae68-9cdc3cdccbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024571e9-7572-449b-b71e-6b07e1fbd315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff91ac80-eea4-4e7c-bfd1-c5a240954d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-26 22:41:25.692688\n",
      "2025-03-26 22:41:50.814597\n",
      "2025-03-26 22:42:18.357485\n",
      "2025-03-26 22:42:47.333969\n",
      "2025-03-26 22:43:14.678724\n",
      "2025-03-26 22:43:43.273382\n",
      "2025-03-26 22:44:10.964123\n",
      "2025-03-26 22:44:39.239085\n",
      "2025-03-26 22:45:07.888390\n",
      "2025-03-26 22:45:35.636872\n",
      "2025-03-26 22:46:03.882590\n",
      "2025-03-26 22:46:32.585437\n",
      "2025-03-26 22:47:00.824420\n",
      "2025-03-26 22:47:27.611738\n",
      "2025-03-26 22:47:54.504160\n",
      "2025-03-26 22:48:22.290772\n",
      "2025-03-26 22:48:52.018127\n",
      "2025-03-26 22:49:18.569681\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "# 输入与输出目录\n",
    "input_dir = \"/N/project/Zli_lab/gongg/ERA_data/LST\"\n",
    "output_dir = \"/N/project/Zli_lab/gongg/ERA_data/JJA_LST\"\n",
    "\n",
    "# 获取输入目录下所有 .nc 文件\n",
    "all_files = glob.glob(os.path.join(input_dir, \"*.nc\"))\n",
    "\n",
    "# 根据文件名按 (year, utc_offset) 分组\n",
    "groups = {}\n",
    "for file in all_files:\n",
    "    basename = os.path.basename(file)  # 如 \"200506_U-8.nc\"\n",
    "    name, ext = os.path.splitext(basename)  # name: \"200506_U-8\"\n",
    "    # year 为前4位\n",
    "    year = name[:4]\n",
    "    # utc 部分：通过下划线分隔，第二部分如 \"U-8\"\n",
    "    parts = name.split('_')\n",
    "    if len(parts) < 2:\n",
    "        continue\n",
    "    utc_str = parts[1]  # e.g., \"U-8\"\n",
    "    # 去掉 'U' 后转成 int（这里 -8 表示 UTC-8）\n",
    "    offset = int(utc_str.replace('U', ''))\n",
    "    key = (year, offset)\n",
    "    groups.setdefault(key, []).append(file)\n",
    "\n",
    "# 遍历每个分组，读取组合数据，筛选6、7、8月，并保存到指定目录\n",
    "counter = 0\n",
    "for (year, offset), files in groups.items():\n",
    "    ds = xr.open_mfdataset(files, combine='by_coords')\n",
    "    ds_jja = ds.where(ds.time.dt.month.isin([6, 7, 8]), drop=True)\n",
    "    \n",
    "    output_filename = f\"{year}_U_{abs(offset)}.nc\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    ds_jja.to_netcdf(output_path)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 10 == 0:\n",
    "        print(datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27dc29-2a20-46d2-a148-e15f8c5c23eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
