{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8e29754-f249-40ad-8273-063ef2a21ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be790792-cb06-413e-8f19-2ce023c1eeb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def local_to_utc(start_datetime_str, timezone_offset):\n",
    "    local_time = datetime.strptime(start_datetime_str, '%Y%m%d%H')\n",
    "    offset = timedelta(hours=timezone_offset)\n",
    "    utc_time = local_time - offset\n",
    "    utc_time_str = utc_time.strftime('%Y%m%d%H')\n",
    "    \n",
    "    return utc_time_str\n",
    "\n",
    "def calculate_lst(utc_time_str, longitude):\n",
    "    utc_time = datetime.strptime(utc_time_str, '%Y%m%d%H')\n",
    "    time_difference = longitude / 15.0  \n",
    "    lst_time = utc_time + timedelta(hours=time_difference)\n",
    "\n",
    "    minutes = lst_time.minute\n",
    "    if minutes < 30:\n",
    "        lst_time = lst_time - timedelta(minutes=minutes)\n",
    "    else:\n",
    "        lst_time = lst_time + timedelta(minutes=(60 - minutes))\n",
    "    \n",
    "    lst_time_str = lst_time.strftime('%Y%m%d%H')\n",
    "    \n",
    "    return lst_time_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c13138b-e8d9-408b-9b1b-0c2a9ab78174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 files have been processed\n",
      "100 files have been processed\n",
      "150 files have been processed\n",
      "200 files have been processed\n",
      "250 files have been processed\n",
      "300 files have been processed\n",
      "350 files have been processed\n",
      "400 files have been processed\n",
      "450 files have been processed\n",
      "500 files have been processed\n",
      "Processed 20 files. Stopping.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os  # Ensure this import is included for os.listdir\n",
    "\n",
    "directory = '/N/project/Zli_lab/Data/GSDR/QC_d_data_US/'\n",
    "\n",
    "time_range = pd.date_range(start='1900-01-01 00:00', end='2014-01-01 01:00', freq='H')\n",
    "time_list = time_range.strftime('%Y%m%d%H').tolist()\n",
    "\n",
    "df = pd.DataFrame({'datetime': time_list})\n",
    "file_count = 0\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "\n",
    "        with open(os.path.join(directory, filename), 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "            # Extract Station ID\n",
    "            station_id = lines[0].split(':')[1].strip()\n",
    "\n",
    "            # Extract Time Zone and clean it up\n",
    "            time_zone_str = lines[16].split(':')[1].strip()\n",
    "            match = re.search(r'\\(UTC[^\\)]+\\)', time_zone_str)\n",
    "            if match:\n",
    "                time_zone = match.group(0).strip('()')\n",
    "            else:\n",
    "                time_zone = 'Unknown'\n",
    "\n",
    "            # Extract Latitude and Longitude\n",
    "            latitude = lines[5].split(':')[1].strip()\n",
    "            longitude = lines[6].split(':')[1].strip()\n",
    "\n",
    "            # Extract Start Datetime\n",
    "            start_datetime = lines[7].split(':')[1].strip()\n",
    "            \n",
    "            \n",
    "            if match.group(0).strip('()')[-1] in ['5', '6', '7', '8']:\n",
    "\n",
    "                # Ensure calculate_lst and local_to_utc functions are defined\n",
    "                lst_time_str = calculate_lst(local_to_utc(start_datetime, -int(match.group(0).strip('()')[-1])), float(longitude))\n",
    "\n",
    "                # Process Precipitation Data\n",
    "                precip_data = lines[21:]\n",
    "                precip_values = [float(value.strip()) if value.strip() != '-999' else None for value in precip_data]\n",
    "\n",
    "                try:\n",
    "                    start_index = time_list.index(lst_time_str)\n",
    "                except ValueError:\n",
    "                    print(f\"lst datetime {lst_time_str} not found in time_list.\")\n",
    "                    continue\n",
    "\n",
    "                aligned_precip_values = [None] * len(time_list)\n",
    "                for i, value in enumerate(precip_values):\n",
    "                    if start_index + i < len(time_list):\n",
    "                        aligned_precip_values[start_index + i] = value\n",
    "\n",
    "                # Format the column name\n",
    "                column_name = f\"{station_id}, {time_zone}, {longitude}, {latitude}\"\n",
    "                df[column_name] = aligned_precip_values\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            file_count += 1\n",
    "\n",
    "            if file_count % 500 == 0:\n",
    "                print(f\"{file_count} files have been processed\")\n",
    "            \n",
    "            \n",
    "df.to_csv('sumup_GSDR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b576f302-352e-4233-ae4c-075a572b67f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files processed. Saved as ../GSDR_data/sumup_GSDR0-5.csv\n",
      "10 files processed. Saved as ../GSDR_data/sumup_GSDR5-10.csv\n",
      "15 files processed. Saved as ../GSDR_data/sumup_GSDR10-15.csv\n",
      "20 files processed. Saved as ../GSDR_data/sumup_GSDR15-20.csv\n",
      "25 files processed. Saved as ../GSDR_data/sumup_GSDR20-25.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m batch_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     71\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../GSDR_data/sumup_GSDR\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(batch_number\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_number\u001b[38;5;241m*\u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files processed. Saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Reset dataframe for the next batch\u001b[39;00m\n",
      "File \u001b[0;32m/N/soft/rhel8/python/gnu/3.11.4/lib/python3.11/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/N/soft/rhel8/python/gnu/3.11.4/lib/python3.11/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/N/soft/rhel8/python/gnu/3.11.4/lib/python3.11/site-packages/pandas/io/formats/csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/N/soft/rhel8/python/gnu/3.11.4/lib/python3.11/site-packages/pandas/io/formats/csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/N/soft/rhel8/python/gnu/3.11.4/lib/python3.11/site-packages/pandas/io/formats/csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/N/soft/rhel8/python/gnu/3.11.4/lib/python3.11/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    310\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    312\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 313\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/N/soft/rhel8/python/gnu/3.11.4/lib/python3.11/site-packages/pandas/_libs/writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os  # Ensure this import is included for os.listdir\n",
    "\n",
    "directory = '/N/project/Zli_lab/Data/GSDR/QC_d_data_US/'\n",
    "\n",
    "time_range = pd.date_range(start='1900-01-01 00:00', end='2014-01-01 01:00', freq='H')\n",
    "time_list = time_range.strftime('%Y%m%d%H').tolist()\n",
    "\n",
    "df = pd.DataFrame({'datetime': time_list})\n",
    "file_count = 0\n",
    "batch_size = 500\n",
    "batch_number = 0\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "\n",
    "        with open(os.path.join(directory, filename), 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "            # Extract Station ID\n",
    "            station_id = lines[0].split(':')[1].strip()\n",
    "\n",
    "            # Extract Time Zone and clean it up\n",
    "            time_zone_str = lines[16].split(':')[1].strip()\n",
    "            match = re.search(r'\\(UTC[^\\)]+\\)', time_zone_str)\n",
    "            if match:\n",
    "                time_zone = match.group(0).strip('()')\n",
    "            else:\n",
    "                time_zone = 'Unknown'\n",
    "\n",
    "            # Extract Latitude and Longitude\n",
    "            latitude = lines[5].split(':')[1].strip()\n",
    "            longitude = lines[6].split(':')[1].strip()\n",
    "\n",
    "            # Extract Start Datetime\n",
    "            start_datetime = lines[7].split(':')[1].strip()\n",
    "            \n",
    "            if match.group(0).strip('()')[-1] in ['5', '6', '7', '8']:\n",
    "\n",
    "                # Ensure calculate_lst and local_to_utc functions are defined\n",
    "                lst_time_str = calculate_lst(local_to_utc(start_datetime, -int(match.group(0).strip('()')[-1])), float(longitude))\n",
    "\n",
    "                # Process Precipitation Data\n",
    "                precip_data = lines[21:]\n",
    "                precip_values = [float(value.strip()) if value.strip() != '-999' else None for value in precip_data]\n",
    "\n",
    "                try:\n",
    "                    start_index = time_list.index(lst_time_str)\n",
    "                except ValueError:\n",
    "                    print(f\"lst datetime {lst_time_str} not found in time_list.\")\n",
    "                    continue\n",
    "\n",
    "                aligned_precip_values = [None] * len(time_list)\n",
    "                for i, value in enumerate(precip_values):\n",
    "                    if start_index + i < len(time_list):\n",
    "                        aligned_precip_values[start_index + i] = value\n",
    "\n",
    "                # Format the column name\n",
    "                column_name = f\"{station_id}, {time_zone}, {longitude}, {latitude}\"\n",
    "                df[column_name] = aligned_precip_values\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            file_count += 1\n",
    "\n",
    "            # Every 500 files, save a new CSV file\n",
    "            if file_count % batch_size == 0:\n",
    "                batch_number += 1\n",
    "                output_filename = f'../GSDR_data/sumup_GSDR{(batch_number-1)*batch_size}-{batch_number*batch_size}.csv'\n",
    "                df.to_csv(output_filename, index=False)\n",
    "                print(f\"{file_count} files processed. Saved as {output_filename}\")\n",
    "                \n",
    "                # Reset dataframe for the next batch\n",
    "                df = pd.DataFrame({'datetime': time_list})\n",
    "\n",
    "# Save remaining data if there are leftover files\n",
    "if not df.empty:\n",
    "    batch_number += 1\n",
    "    output_filename = f'sumup_GSDR{(batch_number-1)*batch_size}-{file_count}.csv'\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    print(f\"Processed remaining files. Saved as {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021be86-531a-4f84-9bfd-047364e7b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#\n",
    "#SBATCH -J sumup\n",
    "#SBATCH -p general\n",
    "#SBATCH -o %j.txt\n",
    "#SBATCH -e %j.err\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=gongg@iu.edu\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --time=10:00:00\n",
    "#SBATCH --mem=256G\n",
    "#SBATCH -A r00599\n",
    "\n",
    "# load Conda config\n",
    "source /N/u/gongg/Quartz/anaconda3/etc/profile.d/conda.sh\n",
    "\n",
    "# activate gongg\n",
    "conda activate gongg\n",
    "\n",
    "\n",
    "# makesure env activate\n",
    "which python\n",
    "python --version\n",
    "\n",
    "#Run your program\n",
    "srun python GSDR_data_processing.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
