{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ee76b6-51df-494c-90e2-a92b2941e6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### automatically refresh the buffer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### solve the auto-complete issue\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "### lvl 2 setups (systerm)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pylab import *\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Wedge, Circle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0073be-a0e7-4ebd-9142-f6b25ecf60d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../../tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/prec_acc_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d881bf-18cd-4ab2-8dec-b6f5799a3857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-06 17:11:35\n",
      "2024-10-06 17:25:03\n",
      "2024-10-06 17:37:48\n",
      "2024-10-06 17:51:51\n",
      "2024-10-06 18:04:55\n",
      "2024-10-06 18:19:11\n",
      "2024-10-06 18:33:58\n",
      "2024-10-06 18:48:41\n",
      "2024-10-06 19:02:40\n",
      "2024-10-06 19:16:03\n",
      "2024-10-06 19:30:22\n",
      "2024-10-06 19:44:16\n",
      "2024-10-06 19:57:33\n",
      "2024-10-06 20:11:24\n",
      "2024-10-06 20:26:33\n",
      "2024-10-06 20:40:32\n",
      "2024-10-06 20:54:45\n",
      "2024-10-06 21:08:00\n",
      "2024-10-06 21:23:10\n",
      "2024-10-06 21:38:03\n",
      "2024-10-06 21:54:18\n",
      "2024-10-06 22:09:13\n",
      "2024-10-06 22:25:20\n",
      "2024-10-06 22:33:27\n"
     ]
    }
   ],
   "source": [
    "start_year = 2013\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "        # 提取CONUS数据\n",
    "            lon = ds['XLONG'].values\n",
    "            lat = ds['XLAT'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "            \n",
    "            mask = np.full(ds['PREC_ACC_NC'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds['PREC_ACC_NC'].dims[1:], coords={'south_north': ds['PREC_ACC_NC'].coords['south_north'], 'west_east': ds['PREC_ACC_NC'].coords['west_east']})\n",
    "            ds_s = ds.where(mask_da, drop=True)\n",
    "            lonn = np.linspace(-124.848, -66.885, 1137)\n",
    "            latt = np.linspace(24.396, 49.384, 708)\n",
    "            prec = ds_s.PREC_ACC_NC.values\n",
    "            lat_min = latt.min()\n",
    "            lat_max = latt.max()\n",
    "            ds_sss = xr.Dataset({'p': (['time', 'lat', 'lon'], prec)},\n",
    "                                coords={'lon': (['lon'], lonn),\n",
    "                                        'lat': (['lat'], latt),\n",
    "                                        'time': ('time', ds_s.Time.values)})\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            \n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.lon >= lon_min) & (ds_sss.lon < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.lat.min().values\n",
    "                    lat_max = ds_lon_subset.lat.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "            \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.lat >= lat_min_split) & (ds_lon_subset.lat < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '../CONUS404_data/LST/UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df60ff8-0058-4436-83bf-dd1bd6795dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02 20:42:02\n",
      "2024-11-02 20:55:53\n",
      "2024-11-02 21:09:40\n",
      "2024-11-02 21:23:55\n",
      "2024-11-02 21:38:41\n",
      "2024-11-02 21:51:22\n",
      "2024-11-02 22:05:43\n",
      "2024-11-02 22:19:01\n",
      "2024-11-02 22:32:46\n",
      "2024-11-02 22:46:59\n",
      "2024-11-02 23:01:21\n",
      "2024-11-02 23:16:05\n",
      "2024-11-02 23:29:36\n",
      "2024-11-02 23:43:15\n",
      "2024-11-02 23:56:35\n",
      "2024-11-03 00:09:25\n",
      "2024-11-03 00:23:06\n",
      "2024-11-03 00:35:28\n",
      "2024-11-03 00:50:14\n",
      "2024-11-03 01:02:58\n",
      "2024-11-03 01:17:02\n",
      "2024-11-03 01:30:43\n",
      "2024-11-03 01:46:02\n",
      "2024-11-03 01:00:15\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('../../tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/CONUS404_T_dT/TarFiles/'\n",
    "\n",
    "start_year = 2013\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'765041.T2.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "        # 提取CONUS数据\n",
    "            lon = ds['XLONG'].values\n",
    "            lat = ds['XLAT'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "            \n",
    "            mask = np.full(ds['T2'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds['T2'].dims[1:], coords={'south_north': ds['T2'].coords['south_north'], 'west_east': ds['T2'].coords['west_east']})\n",
    "            ds_s = ds.where(mask_da, drop=True)\n",
    "            lonn = np.linspace(-124.848, -66.885, 1137)\n",
    "            latt = np.linspace(24.396, 49.384, 708)\n",
    "            prec = ds_s['T2'].values\n",
    "            lat_min = latt.min()\n",
    "            lat_max = latt.max()\n",
    "            ds_sss = xr.Dataset({'t2': (['time', 'lat', 'lon'], prec)},\n",
    "                                coords={'lon': (['lon'], lonn),\n",
    "                                        'lat': (['lat'], latt),\n",
    "                                        'time': ('time', ds_s.Time.values)})\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            \n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.lon >= lon_min) & (ds_sss.lon < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.lat.min().values\n",
    "                    lat_max = ds_lon_subset.lat.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "            \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.lat >= lat_min_split) & (ds_lon_subset.lat < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '../CONUS404_data/LST/UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'T2.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdde2eb7-e671-440c-aeec-349760393c45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-03 01:13:22\n",
      "2024-11-03 01:27:57\n",
      "2024-11-03 01:41:56\n",
      "2024-11-03 01:56:01\n",
      "2024-11-03 02:10:59\n",
      "2024-11-03 02:24:22\n",
      "2024-11-03 02:37:43\n",
      "2024-11-03 02:50:46\n",
      "2024-11-03 03:05:05\n",
      "2024-11-03 03:18:51\n",
      "2024-11-03 03:32:49\n",
      "2024-11-03 03:46:26\n",
      "2024-11-03 03:59:33\n",
      "2024-11-03 04:13:08\n",
      "2024-11-03 04:26:24\n",
      "2024-11-03 04:39:52\n",
      "2024-11-03 04:53:09\n",
      "2024-11-03 05:05:45\n",
      "2024-11-03 05:19:13\n",
      "2024-11-03 05:32:00\n",
      "2024-11-03 05:44:32\n",
      "2024-11-03 05:56:38\n",
      "2024-11-03 06:09:30\n",
      "2024-11-03 06:21:32\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('../../tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/CONUS404_T_dT/TarFiles/'\n",
    "\n",
    "start_year = 2013\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  \n",
    "            else:\n",
    "                num_days = 28  \n",
    "\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'765041.TD2.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "\n",
    "            lon = ds['XLONG'].values\n",
    "            lat = ds['XLAT'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "            \n",
    "            mask = np.full(ds['TD2'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds['TD2'].dims[1:], coords={'south_north': ds['TD2'].coords['south_north'], 'west_east': ds['TD2'].coords['west_east']})\n",
    "            ds_s = ds.where(mask_da, drop=True)\n",
    "            lonn = np.linspace(-124.848, -66.885, 1137)\n",
    "            latt = np.linspace(24.396, 49.384, 708)\n",
    "            prec = ds_s['TD2'].values\n",
    "            lat_min = latt.min()\n",
    "            lat_max = latt.max()\n",
    "            ds_sss = xr.Dataset({'td2': (['time', 'lat', 'lon'], prec)},\n",
    "                                coords={'lon': (['lon'], lonn),\n",
    "                                        'lat': (['lat'], latt),\n",
    "                                        'time': ('time', ds_s.Time.values)})\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            \n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.lon >= lon_min) & (ds_sss.lon < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.lat.min().values\n",
    "                    lat_max = ds_lon_subset.lat.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "            \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.lat >= lat_min_split) & (ds_lon_subset.lat < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '../CONUS404_data/LST/UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'TD2.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a4f50b3-301d-450e-b469-e1a774b0a915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-17 01:44:09\n",
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n",
      "2025-02-17 01:44:41\n",
      "2025-02-17 01:45:09\n",
      "2025-02-17 01:45:38\n",
      "2025-02-17 01:46:01\n",
      "2025-02-17 01:46:26\n",
      "2025-02-17 01:46:51\n",
      "2025-02-17 01:47:14\n",
      "2025-02-17 01:47:39\n",
      "2025-02-17 01:48:04\n",
      "2025-02-17 01:48:31\n",
      "2025-02-17 01:48:54\n",
      "2025-02-17 01:49:22\n",
      "2025-02-17 01:49:50\n",
      "2025-02-17 01:50:14\n",
      "2025-02-17 01:50:42\n",
      "2025-02-17 01:51:12\n",
      "2025-02-17 01:51:38\n",
      "2025-02-17 01:52:02\n",
      "2025-02-17 01:52:29\n",
      "2025-02-17 01:52:57\n",
      "2025-02-17 01:53:26\n",
      "2025-02-17 01:53:55\n",
      "2025-02-17 01:54:19\n",
      "2025-02-17 01:54:46\n",
      "2025-02-17 01:55:16\n",
      "2025-02-17 01:55:39\n",
      "2025-02-17 01:56:04\n",
      "2025-02-17 01:56:30\n",
      "2025-02-17 01:56:55\n",
      "2025-02-17 01:57:21\n",
      "2025-02-17 01:57:48\n",
      "2025-02-17 01:57:50\n",
      "2025-02-17 01:58:14\n",
      "2025-02-17 01:58:43\n",
      "2025-02-17 01:59:08\n",
      "2025-02-17 01:59:40\n",
      "2025-02-17 02:00:08\n",
      "2025-02-17 02:00:38\n",
      "2025-02-17 02:01:01\n",
      "2025-02-17 02:01:31\n",
      "2025-02-17 02:02:01\n",
      "2025-02-17 02:02:32\n",
      "2025-02-17 02:03:01\n",
      "2025-02-17 02:03:28\n",
      "2025-02-17 02:03:55\n",
      "2025-02-17 02:04:31\n",
      "2025-02-17 02:04:56\n",
      "2025-02-17 02:05:28\n",
      "2025-02-17 02:05:58\n",
      "2025-02-17 02:06:28\n",
      "2025-02-17 02:06:49\n",
      "2025-02-17 02:07:20\n",
      "2025-02-17 02:07:53\n",
      "2025-02-17 02:08:26\n",
      "2025-02-17 02:08:53\n",
      "2025-02-17 02:09:18\n",
      "2025-02-17 02:09:47\n",
      "2025-02-17 02:10:13\n",
      "2025-02-17 02:10:39\n",
      "2025-02-17 02:11:10\n",
      "2025-02-17 02:11:41\n",
      "2025-02-17 02:12:10\n",
      "2025-02-17 02:12:13\n",
      "2025-02-17 02:12:35\n",
      "2025-02-17 02:13:02\n",
      "2025-02-17 02:13:30\n",
      "2025-02-17 02:14:03\n",
      "2025-02-17 02:14:22\n",
      "2025-02-17 02:14:53\n",
      "2025-02-17 02:15:14\n",
      "2025-02-17 02:15:44\n",
      "2025-02-17 02:16:23\n",
      "2025-02-17 02:16:52\n",
      "2025-02-17 02:17:27\n",
      "2025-02-17 02:17:56\n",
      "2025-02-17 02:18:28\n",
      "2025-02-17 02:19:06\n",
      "2025-02-17 02:19:32\n",
      "2025-02-17 02:19:55\n",
      "2025-02-17 02:20:19\n",
      "2025-02-17 02:20:49\n",
      "2025-02-17 02:21:10\n",
      "2025-02-17 02:21:32\n",
      "2025-02-17 02:21:57\n",
      "2025-02-17 02:22:21\n",
      "2025-02-17 02:22:51\n",
      "2025-02-17 02:23:24\n",
      "2025-02-17 02:23:53\n",
      "2025-02-17 02:24:20\n",
      "2025-02-17 02:24:54\n",
      "2025-02-17 02:25:29\n",
      "2025-02-17 02:26:00\n",
      "2025-02-17 02:26:36\n",
      "2025-02-17 02:27:07\n",
      "2025-02-17 02:27:13\n",
      "2025-02-17 02:27:35\n",
      "2025-02-17 02:28:05\n",
      "2025-02-17 02:28:39\n",
      "2025-02-17 02:29:13\n",
      "2025-02-17 02:29:42\n",
      "2025-02-17 02:30:17\n",
      "2025-02-17 02:30:54\n",
      "2025-02-17 02:31:17\n",
      "2025-02-17 02:31:57\n",
      "2025-02-17 02:32:34\n",
      "2025-02-17 02:33:09\n",
      "2025-02-17 02:33:38\n",
      "2025-02-17 02:34:07\n",
      "2025-02-17 02:34:34\n",
      "2025-02-17 02:35:05\n",
      "2025-02-17 02:35:37\n",
      "2025-02-17 02:36:09\n",
      "2025-02-17 02:36:41\n",
      "2025-02-17 02:37:11\n",
      "2025-02-17 02:37:29\n",
      "2025-02-17 02:37:52\n",
      "2025-02-17 02:38:27\n",
      "2025-02-17 02:38:53\n",
      "2025-02-17 02:39:19\n",
      "2025-02-17 02:39:49\n",
      "2025-02-17 02:40:16\n",
      "2025-02-17 02:40:46\n",
      "2025-02-17 02:41:17\n",
      "2025-02-17 02:41:43\n",
      "2025-02-17 02:42:12\n",
      "2025-02-17 02:42:43\n",
      "2025-02-17 02:42:46\n",
      "2025-02-17 02:43:13\n",
      "2025-02-17 02:43:40\n",
      "2025-02-17 02:44:08\n",
      "2025-02-17 02:44:33\n",
      "2025-02-17 02:44:56\n",
      "2025-02-17 02:45:25\n",
      "2025-02-17 02:45:53\n",
      "2025-02-17 02:46:23\n",
      "2025-02-17 02:46:59\n",
      "2025-02-17 02:47:29\n",
      "2025-02-17 02:48:01\n",
      "2025-02-17 02:48:25\n",
      "2025-02-17 02:49:02\n",
      "2025-02-17 02:49:38\n",
      "2025-02-17 02:50:08\n",
      "2025-02-17 02:50:34\n",
      "2025-02-17 02:51:00\n",
      "2025-02-17 02:51:32\n",
      "2025-02-17 02:52:02\n",
      "2025-02-17 02:52:27\n",
      "2025-02-17 02:52:51\n",
      "2025-02-17 02:53:21\n",
      "2025-02-17 02:53:46\n",
      "2025-02-17 02:54:17\n",
      "2025-02-17 02:54:49\n",
      "2025-02-17 02:55:18\n",
      "2025-02-17 02:55:50\n",
      "2025-02-17 02:56:26\n",
      "2025-02-17 02:57:00\n",
      "2025-02-17 02:57:03\n",
      "2025-02-17 02:57:29\n",
      "2025-02-17 02:57:56\n",
      "2025-02-17 02:58:37\n",
      "2025-02-17 02:59:06\n",
      "2025-02-17 02:59:32\n",
      "2025-02-17 03:00:02\n",
      "2025-02-17 03:00:42\n",
      "2025-02-17 03:01:13\n",
      "2025-02-17 03:01:43\n",
      "2025-02-17 03:02:12\n",
      "2025-02-17 03:02:42\n",
      "2025-02-17 03:03:07\n",
      "2025-02-17 03:03:31\n",
      "2025-02-17 03:03:57\n",
      "2025-02-17 03:04:28\n",
      "2025-02-17 03:04:53\n",
      "2025-02-17 03:05:17\n",
      "2025-02-17 03:05:45\n",
      "2025-02-17 03:06:17\n",
      "2025-02-17 03:06:41\n",
      "2025-02-17 03:07:06\n",
      "2025-02-17 03:07:29\n",
      "2025-02-17 03:07:51\n",
      "2025-02-17 03:08:17\n",
      "2025-02-17 03:08:45\n",
      "2025-02-17 03:09:11\n",
      "2025-02-17 03:09:41\n",
      "2025-02-17 03:10:14\n",
      "2025-02-17 03:10:44\n",
      "2025-02-17 03:11:08\n",
      "2025-02-17 03:11:33\n",
      "2025-02-17 03:11:37\n",
      "2025-02-17 03:11:57\n",
      "2025-02-17 03:12:23\n",
      "2025-02-17 03:12:53\n",
      "2025-02-17 03:13:18\n",
      "2025-02-17 03:13:46\n",
      "2025-02-17 03:14:11\n",
      "2025-02-17 03:14:38\n",
      "2025-02-17 03:15:07\n",
      "2025-02-17 03:15:38\n",
      "2025-02-17 03:16:05\n",
      "2025-02-17 03:16:43\n",
      "2025-02-17 03:17:12\n",
      "2025-02-17 03:17:41\n",
      "2025-02-17 03:18:11\n",
      "2025-02-17 03:18:40\n",
      "2025-02-17 03:19:07\n",
      "2025-02-17 03:19:35\n",
      "2025-02-17 03:20:15\n",
      "2025-02-17 03:20:48\n",
      "2025-02-17 03:21:13\n",
      "2025-02-17 03:21:40\n",
      "2025-02-17 03:22:21\n",
      "2025-02-17 03:22:47\n",
      "2025-02-17 03:23:18\n",
      "2025-02-17 03:23:50\n",
      "2025-02-17 03:24:20\n",
      "2025-02-17 03:24:51\n",
      "2025-02-17 03:25:16\n",
      "2025-02-17 03:25:45\n",
      "2025-02-17 03:26:20\n",
      "2025-02-17 03:26:25\n",
      "2025-02-17 03:26:51\n",
      "2025-02-17 03:27:19\n",
      "2025-02-17 03:27:47\n",
      "2025-02-17 03:28:14\n",
      "2025-02-17 03:28:47\n",
      "2025-02-17 03:29:13\n",
      "2025-02-17 03:29:40\n",
      "2025-02-17 03:30:07\n",
      "2025-02-17 03:30:36\n",
      "2025-02-17 03:31:06\n",
      "2025-02-17 03:31:33\n",
      "2025-02-17 03:31:56\n",
      "2025-02-17 03:32:23\n",
      "2025-02-17 03:32:50\n",
      "2025-02-17 03:33:17\n",
      "2025-02-17 03:33:45\n",
      "2025-02-17 03:34:10\n",
      "2025-02-17 03:34:40\n",
      "2025-02-17 03:35:10\n",
      "2025-02-17 03:35:42\n",
      "2025-02-17 03:36:14\n",
      "2025-02-17 03:36:42\n",
      "2025-02-17 03:37:15\n",
      "2025-02-17 03:37:53\n",
      "2025-02-17 03:38:18\n",
      "2025-02-17 03:38:58\n",
      "2025-02-17 03:39:34\n",
      "2025-02-17 03:40:05\n",
      "2025-02-17 03:40:32\n",
      "2025-02-17 03:41:03\n",
      "2025-02-17 03:41:27\n",
      "2025-02-17 03:41:31\n",
      "2025-02-17 03:41:55\n",
      "2025-02-17 03:42:36\n",
      "2025-02-17 03:43:08\n",
      "2025-02-17 03:43:37\n",
      "2025-02-17 03:44:21\n",
      "2025-02-17 03:44:47\n",
      "2025-02-17 03:45:16\n",
      "2025-02-17 03:45:42\n",
      "2025-02-17 03:46:11\n",
      "2025-02-17 03:46:41\n",
      "2025-02-17 03:47:13\n",
      "2025-02-17 03:47:42\n",
      "2025-02-17 03:48:10\n",
      "2025-02-17 03:48:41\n",
      "2025-02-17 03:49:16\n",
      "2025-02-17 03:49:38\n",
      "2025-02-17 03:50:11\n",
      "2025-02-17 03:50:45\n",
      "2025-02-17 03:51:12\n",
      "2025-02-17 03:51:42\n",
      "2025-02-17 03:52:12\n",
      "2025-02-17 03:52:36\n",
      "2025-02-17 03:53:09\n",
      "2025-02-17 03:53:37\n",
      "2025-02-17 03:54:07\n",
      "2025-02-17 03:54:35\n",
      "2025-02-17 03:55:10\n",
      "2025-02-17 03:55:39\n",
      "2025-02-17 03:56:06\n",
      "2025-02-17 03:56:36\n",
      "2025-02-17 03:56:39\n",
      "2025-02-17 03:57:04\n",
      "2025-02-17 03:57:32\n",
      "2025-02-17 03:58:01\n",
      "2025-02-17 03:58:26\n",
      "2025-02-17 03:59:01\n",
      "2025-02-17 03:59:29\n",
      "2025-02-17 04:00:03\n",
      "2025-02-17 04:00:29\n",
      "2025-02-17 04:01:03\n",
      "2025-02-17 04:01:37\n",
      "2025-02-17 04:02:08\n",
      "2025-02-17 04:02:38\n",
      "2025-02-17 04:03:22\n",
      "2025-02-17 04:03:53\n",
      "2025-02-17 04:04:28\n",
      "2025-02-17 04:05:01\n",
      "2025-02-17 04:05:34\n",
      "2025-02-17 04:06:02\n",
      "2025-02-17 04:06:37\n",
      "2025-02-17 04:07:10\n",
      "2025-02-17 04:07:39\n",
      "2025-02-17 04:08:04\n",
      "2025-02-17 04:08:38\n",
      "2025-02-17 04:09:02\n",
      "2025-02-17 04:09:36\n",
      "2025-02-17 04:10:04\n",
      "2025-02-17 04:10:25\n",
      "2025-02-17 04:11:05\n",
      "2025-02-17 04:11:42\n",
      "2025-02-17 04:12:16\n",
      "2025-02-17 04:12:44\n",
      "2025-02-17 04:12:47\n",
      "2025-02-17 04:13:14\n",
      "2025-02-17 04:13:43\n",
      "2025-02-17 04:14:08\n",
      "2025-02-17 04:14:35\n",
      "2025-02-17 04:15:00\n",
      "2025-02-17 04:15:26\n",
      "2025-02-17 04:15:48\n",
      "2025-02-17 04:16:17\n",
      "2025-02-17 04:16:45\n",
      "2025-02-17 04:17:08\n",
      "2025-02-17 04:17:33\n",
      "2025-02-17 04:18:05\n",
      "2025-02-17 04:18:36\n",
      "2025-02-17 04:19:01\n",
      "2025-02-17 04:19:27\n",
      "2025-02-17 04:19:54\n",
      "2025-02-17 04:20:23\n",
      "2025-02-17 04:20:53\n",
      "2025-02-17 04:21:20\n",
      "2025-02-17 04:21:48\n",
      "2025-02-17 04:22:24\n",
      "2025-02-17 04:22:56\n",
      "2025-02-17 04:23:30\n",
      "2025-02-17 04:23:58\n",
      "2025-02-17 04:24:27\n",
      "2025-02-17 04:25:03\n",
      "2025-02-17 04:25:38\n",
      "2025-02-17 04:26:02\n",
      "2025-02-17 04:26:29\n",
      "2025-02-17 04:27:00\n",
      "2025-02-17 04:27:25\n",
      "2025-02-17 04:27:31\n",
      "2025-02-17 04:28:02\n",
      "2025-02-17 04:28:35\n",
      "2025-02-17 04:29:02\n",
      "2025-02-17 04:29:28\n",
      "2025-02-17 04:29:57\n",
      "2025-02-17 04:30:31\n",
      "2025-02-17 04:30:55\n",
      "2025-02-17 04:31:31\n",
      "2025-02-17 04:32:00\n",
      "2025-02-17 04:32:22\n",
      "2025-02-17 04:32:52\n",
      "2025-02-17 04:33:20\n",
      "2025-02-17 04:33:49\n",
      "2025-02-17 04:34:17\n",
      "2025-02-17 04:34:48\n",
      "2025-02-17 04:35:19\n",
      "2025-02-17 04:35:44\n",
      "2025-02-17 04:36:10\n",
      "2025-02-17 04:36:38\n",
      "2025-02-17 04:37:05\n",
      "2025-02-17 04:37:28\n",
      "2025-02-17 04:37:52\n",
      "2025-02-17 04:38:19\n",
      "2025-02-17 04:38:44\n",
      "2025-02-17 04:39:08\n",
      "2025-02-17 04:39:41\n",
      "2025-02-17 04:40:16\n",
      "2025-02-17 04:40:51\n",
      "2025-02-17 04:41:25\n",
      "2025-02-17 04:41:54\n",
      "2025-02-17 04:41:58\n",
      "2025-02-17 04:42:23\n",
      "2025-02-17 04:42:59\n",
      "2025-02-17 04:43:27\n",
      "2025-02-17 04:43:56\n",
      "2025-02-17 04:44:25\n",
      "2025-02-17 04:44:55\n",
      "2025-02-17 04:45:24\n",
      "2025-02-17 04:45:48\n",
      "2025-02-17 04:46:25\n",
      "2025-02-17 04:46:45\n",
      "2025-02-17 04:47:18\n",
      "2025-02-17 04:47:46\n",
      "2025-02-17 04:48:10\n",
      "2025-02-17 04:48:33\n",
      "2025-02-17 04:49:05\n",
      "2025-02-17 04:49:32\n",
      "2025-02-17 04:50:00\n",
      "2025-02-17 04:50:21\n",
      "2025-02-17 04:50:47\n",
      "2025-02-17 04:51:16\n",
      "2025-02-17 04:51:39\n",
      "2025-02-17 04:52:06\n",
      "2025-02-17 04:52:35\n",
      "2025-02-17 04:53:02\n",
      "2025-02-17 04:53:28\n",
      "2025-02-17 04:53:54\n",
      "2025-02-17 04:54:22\n",
      "2025-02-17 04:54:51\n",
      "2025-02-17 04:55:13\n",
      "2025-02-17 04:55:44\n",
      "2025-02-17 04:56:12\n",
      "2025-02-17 04:56:14\n",
      "2025-02-17 04:56:38\n",
      "2025-02-17 04:57:08\n",
      "2025-02-17 04:57:35\n",
      "2025-02-17 04:58:05\n",
      "2025-02-17 04:58:40\n",
      "2025-02-17 04:59:06\n",
      "2025-02-17 04:59:39\n",
      "2025-02-17 05:00:05\n",
      "2025-02-17 05:00:36\n",
      "2025-02-17 05:01:08\n",
      "2025-02-17 05:01:41\n",
      "2025-02-17 05:02:11\n",
      "2025-02-17 05:02:42\n",
      "2025-02-17 05:03:07\n",
      "2025-02-17 05:03:36\n",
      "2025-02-17 05:04:10\n",
      "2025-02-17 05:04:42\n",
      "2025-02-17 05:05:24\n",
      "2025-02-17 05:06:00\n",
      "2025-02-17 05:06:37\n",
      "2025-02-17 05:07:04\n",
      "2025-02-17 05:07:35\n",
      "2025-02-17 05:08:04\n",
      "2025-02-17 05:08:34\n",
      "2025-02-17 05:09:02\n",
      "2025-02-17 05:09:26\n",
      "2025-02-17 05:09:54\n",
      "2025-02-17 05:10:22\n",
      "2025-02-17 05:10:46\n",
      "2025-02-17 05:11:10\n",
      "2025-02-17 05:11:14\n",
      "2025-02-17 05:11:32\n",
      "2025-02-17 05:11:56\n",
      "2025-02-17 05:12:21\n",
      "2025-02-17 05:12:48\n",
      "2025-02-17 05:13:09\n",
      "2025-02-17 05:13:34\n",
      "2025-02-17 05:14:08\n",
      "2025-02-17 05:14:38\n",
      "2025-02-17 05:15:03\n",
      "2025-02-17 05:15:29\n",
      "2025-02-17 05:15:54\n",
      "2025-02-17 05:16:15\n",
      "2025-02-17 05:16:35\n",
      "2025-02-17 05:17:11\n",
      "2025-02-17 05:17:36\n",
      "2025-02-17 05:18:08\n",
      "2025-02-17 05:18:34\n",
      "2025-02-17 05:19:03\n",
      "2025-02-17 05:19:36\n",
      "2025-02-17 05:20:01\n",
      "2025-02-17 05:20:30\n",
      "2025-02-17 05:21:02\n",
      "2025-02-17 05:21:26\n",
      "2025-02-17 05:21:51\n",
      "2025-02-17 05:22:12\n",
      "2025-02-17 05:22:44\n",
      "2025-02-17 05:23:22\n",
      "2025-02-17 05:23:44\n",
      "2025-02-17 05:24:10\n",
      "2025-02-17 05:24:36\n",
      "2025-02-17 05:25:07\n",
      "2025-02-17 05:25:10\n",
      "2025-02-17 05:25:30\n",
      "2025-02-17 05:26:00\n",
      "2025-02-17 05:26:24\n",
      "2025-02-17 05:26:49\n",
      "2025-02-17 05:27:16\n",
      "2025-02-17 05:27:42\n",
      "2025-02-17 05:28:06\n",
      "2025-02-17 05:28:34\n",
      "2025-02-17 05:28:57\n",
      "2025-02-17 05:29:19\n",
      "2025-02-17 05:29:51\n",
      "2025-02-17 05:30:17\n",
      "2025-02-17 05:30:42\n",
      "2025-02-17 05:31:07\n",
      "2025-02-17 05:31:37\n",
      "2025-02-17 05:32:04\n",
      "2025-02-17 05:32:38\n",
      "2025-02-17 05:33:01\n",
      "2025-02-17 05:33:27\n",
      "2025-02-17 05:34:03\n",
      "2025-02-17 05:34:32\n",
      "2025-02-17 05:34:57\n",
      "2025-02-17 05:35:29\n",
      "2025-02-17 05:35:50\n",
      "2025-02-17 05:36:13\n",
      "2025-02-17 05:36:39\n",
      "2025-02-17 05:37:05\n",
      "2025-02-17 05:37:34\n",
      "2025-02-17 05:38:01\n",
      "2025-02-17 05:38:26\n",
      "2025-02-17 05:38:53\n",
      "2025-02-17 05:38:55\n",
      "2025-02-17 05:39:20\n",
      "2025-02-17 05:39:45\n",
      "2025-02-17 05:40:06\n",
      "2025-02-17 05:40:37\n",
      "2025-02-17 05:41:05\n",
      "2025-02-17 05:41:35\n",
      "2025-02-17 05:41:59\n",
      "2025-02-17 05:42:25\n",
      "2025-02-17 05:42:53\n",
      "2025-02-17 05:43:16\n",
      "2025-02-17 05:43:45\n",
      "2025-02-17 05:44:09\n",
      "2025-02-17 05:44:35\n",
      "2025-02-17 05:44:58\n",
      "2025-02-17 05:45:19\n",
      "2025-02-17 05:45:47\n",
      "2025-02-17 05:46:11\n",
      "2025-02-17 05:46:36\n",
      "2025-02-17 05:47:05\n",
      "2025-02-17 05:47:26\n",
      "2025-02-17 05:47:51\n",
      "2025-02-17 05:48:24\n",
      "2025-02-17 05:48:49\n",
      "2025-02-17 05:49:15\n",
      "2025-02-17 05:49:41\n",
      "2025-02-17 05:50:08\n",
      "2025-02-17 05:50:40\n",
      "2025-02-17 05:51:06\n",
      "2025-02-17 05:51:10\n",
      "2025-02-17 05:51:37\n",
      "2025-02-17 05:52:07\n",
      "2025-02-17 05:52:40\n",
      "2025-02-17 05:53:04\n",
      "2025-02-17 05:53:33\n",
      "2025-02-17 05:53:55\n",
      "2025-02-17 05:54:17\n",
      "2025-02-17 05:54:45\n",
      "2025-02-17 05:55:20\n",
      "2025-02-17 05:55:45\n",
      "2025-02-17 05:56:04\n",
      "2025-02-17 05:56:25\n",
      "2025-02-17 05:56:49\n",
      "2025-02-17 05:57:13\n",
      "2025-02-17 05:57:38\n",
      "2025-02-17 05:58:05\n",
      "2025-02-17 05:58:34\n",
      "2025-02-17 05:59:01\n",
      "2025-02-17 05:59:34\n",
      "2025-02-17 05:59:56\n",
      "2025-02-17 06:00:27\n",
      "2025-02-17 06:00:49\n",
      "2025-02-17 06:01:18\n",
      "2025-02-17 06:01:48\n",
      "2025-02-17 06:02:17\n",
      "2025-02-17 06:02:43\n",
      "2025-02-17 06:03:10\n",
      "2025-02-17 06:03:33\n",
      "2025-02-17 06:04:00\n",
      "2025-02-17 06:04:27\n",
      "2025-02-17 06:04:53\n",
      "2025-02-17 06:04:57\n",
      "2025-02-17 06:05:19\n",
      "2025-02-17 06:05:44\n",
      "2025-02-17 06:06:11\n",
      "2025-02-17 06:06:38\n",
      "2025-02-17 06:07:03\n",
      "2025-02-17 06:07:27\n",
      "2025-02-17 06:07:52\n",
      "2025-02-17 06:08:14\n",
      "2025-02-17 06:08:41\n",
      "2025-02-17 06:09:03\n",
      "2025-02-17 06:09:30\n",
      "2025-02-17 06:09:56\n",
      "2025-02-17 06:10:21\n",
      "2025-02-17 06:10:44\n",
      "2025-02-17 06:11:14\n",
      "2025-02-17 06:11:49\n",
      "2025-02-17 06:12:16\n",
      "2025-02-17 06:12:40\n",
      "2025-02-17 06:13:11\n",
      "2025-02-17 06:13:45\n",
      "2025-02-17 06:14:09\n",
      "2025-02-17 06:14:33\n",
      "2025-02-17 06:15:02\n",
      "2025-02-17 06:15:31\n",
      "2025-02-17 06:15:52\n",
      "2025-02-17 06:16:15\n",
      "2025-02-17 06:16:44\n",
      "2025-02-17 06:17:12\n",
      "2025-02-17 06:17:36\n",
      "2025-02-17 06:18:13\n",
      "2025-02-17 06:18:16\n",
      "2025-02-17 06:18:42\n",
      "2025-02-17 06:19:08\n",
      "2025-02-17 06:19:37\n",
      "2025-02-17 06:20:05\n",
      "2025-02-17 06:20:26\n",
      "2025-02-17 06:20:59\n",
      "2025-02-17 06:21:21\n",
      "2025-02-17 06:21:47\n",
      "2025-02-17 06:22:14\n",
      "2025-02-17 06:22:39\n",
      "2025-02-17 06:23:05\n",
      "2025-02-17 06:23:31\n",
      "2025-02-17 06:23:56\n",
      "2025-02-17 06:24:18\n",
      "2025-02-17 06:24:39\n",
      "2025-02-17 06:25:05\n",
      "2025-02-17 06:25:23\n",
      "2025-02-17 06:25:47\n",
      "2025-02-17 06:26:06\n",
      "2025-02-17 06:26:31\n",
      "2025-02-17 06:26:55\n",
      "2025-02-17 06:27:16\n",
      "2025-02-17 06:27:40\n",
      "2025-02-17 06:28:07\n",
      "2025-02-17 06:28:31\n",
      "2025-02-17 06:28:53\n",
      "2025-02-17 06:29:21\n",
      "2025-02-17 06:29:50\n",
      "2025-02-17 06:30:18\n",
      "2025-02-17 06:30:44\n",
      "2025-02-17 06:31:09\n",
      "2025-02-17 06:31:11\n",
      "2025-02-17 06:31:30\n",
      "2025-02-17 06:32:02\n",
      "2025-02-17 06:32:26\n",
      "2025-02-17 06:33:04\n",
      "2025-02-17 06:33:26\n",
      "2025-02-17 06:33:48\n",
      "2025-02-17 06:34:17\n",
      "2025-02-17 06:34:41\n",
      "2025-02-17 06:35:14\n",
      "2025-02-17 06:35:39\n",
      "2025-02-17 06:36:03\n",
      "2025-02-17 06:36:25\n",
      "2025-02-17 06:36:48\n",
      "2025-02-17 06:37:23\n",
      "2025-02-17 06:37:43\n",
      "2025-02-17 06:38:05\n",
      "2025-02-17 06:38:27\n",
      "2025-02-17 06:38:52\n",
      "2025-02-17 06:39:11\n",
      "2025-02-17 06:39:38\n",
      "2025-02-17 06:40:04\n",
      "2025-02-17 06:40:28\n",
      "2025-02-17 06:40:47\n",
      "2025-02-17 06:41:05\n",
      "2025-02-17 06:41:26\n",
      "2025-02-17 06:41:43\n",
      "2025-02-17 06:42:07\n",
      "2025-02-17 06:42:21\n",
      "2025-02-17 06:42:38\n",
      "2025-02-17 06:43:01\n",
      "2025-02-17 06:43:03\n",
      "2025-02-17 06:43:18\n",
      "2025-02-17 06:43:34\n",
      "2025-02-17 06:43:53\n",
      "2025-02-17 06:44:07\n",
      "2025-02-17 06:44:26\n",
      "2025-02-17 06:44:44\n",
      "2025-02-17 06:45:01\n",
      "2025-02-17 06:45:16\n",
      "2025-02-17 06:45:33\n",
      "2025-02-17 06:45:49\n",
      "2025-02-17 06:46:05\n",
      "2025-02-17 06:46:20\n",
      "2025-02-17 06:46:35\n",
      "2025-02-17 06:46:50\n",
      "2025-02-17 06:47:05\n",
      "2025-02-17 06:47:23\n",
      "2025-02-17 06:47:43\n",
      "2025-02-17 06:48:01\n",
      "2025-02-17 06:48:17\n",
      "2025-02-17 06:48:33\n",
      "2025-02-17 06:48:49\n",
      "2025-02-17 06:49:04\n",
      "2025-02-17 06:49:21\n",
      "2025-02-17 06:49:38\n",
      "2025-02-17 06:49:56\n",
      "2025-02-17 06:50:13\n",
      "2025-02-17 06:50:33\n",
      "2025-02-17 06:50:55\n",
      "2025-02-17 06:51:23\n",
      "2025-02-17 06:51:46\n",
      "2025-02-17 06:52:08\n",
      "2025-02-17 06:52:10\n",
      "2025-02-17 06:52:26\n",
      "2025-02-17 06:52:44\n",
      "2025-02-17 06:53:05\n",
      "2025-02-17 06:53:19\n",
      "2025-02-17 06:53:39\n",
      "2025-02-17 06:53:54\n",
      "2025-02-17 06:54:10\n",
      "2025-02-17 06:54:25\n",
      "2025-02-17 06:54:38\n",
      "2025-02-17 06:54:51\n",
      "2025-02-17 06:55:08\n",
      "2025-02-17 06:55:26\n",
      "2025-02-17 06:55:43\n",
      "2025-02-17 06:55:58\n",
      "2025-02-17 06:56:17\n",
      "2025-02-17 06:56:35\n",
      "2025-02-17 06:56:54\n",
      "2025-02-17 06:57:10\n",
      "2025-02-17 06:57:26\n",
      "2025-02-17 06:57:40\n",
      "2025-02-17 06:57:58\n",
      "2025-02-17 06:58:12\n",
      "2025-02-17 06:58:29\n",
      "2025-02-17 06:58:45\n",
      "2025-02-17 06:59:02\n",
      "2025-02-17 06:59:15\n",
      "2025-02-17 06:59:40\n",
      "2025-02-17 07:00:00\n",
      "2025-02-17 07:00:21\n",
      "2025-02-17 07:00:39\n",
      "2025-02-17 07:00:53\n",
      "2025-02-17 07:00:54\n",
      "2025-02-17 07:01:07\n",
      "2025-02-17 07:01:25\n",
      "2025-02-17 07:01:41\n",
      "2025-02-17 07:01:55\n",
      "2025-02-17 07:02:08\n",
      "2025-02-17 07:02:20\n",
      "2025-02-17 07:02:33\n",
      "2025-02-17 07:02:47\n",
      "2025-02-17 07:03:00\n",
      "2025-02-17 07:03:14\n",
      "2025-02-17 07:03:28\n",
      "2025-02-17 07:03:42\n",
      "2025-02-17 07:03:54\n",
      "2025-02-17 07:04:07\n",
      "2025-02-17 07:04:19\n",
      "2025-02-17 07:04:31\n",
      "2025-02-17 07:04:44\n",
      "2025-02-17 07:04:56\n",
      "2025-02-17 07:05:09\n",
      "2025-02-17 07:05:21\n",
      "2025-02-17 07:05:34\n",
      "2025-02-17 07:05:46\n",
      "2025-02-17 07:05:59\n",
      "2025-02-17 07:06:12\n",
      "2025-02-17 07:06:25\n",
      "2025-02-17 07:06:38\n",
      "2025-02-17 07:06:50\n",
      "2025-02-17 07:07:03\n",
      "2025-02-17 07:07:15\n",
      "2025-02-17 07:07:38\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('/N/project/Zli_lab/Data/Other/tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/prec_acc_files/'\n",
    "\n",
    "start_year = 2019\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "            ds_era = xr.Dataset({'p': (['time', 'latitude', 'longitude'], ds.PREC_ACC_NC.values)},\n",
    "                                coords={'longitude': (['longitude'], ds.XLONG.values[500]),\n",
    "                                        'latitude': (['latitude'], ds.XLAT.values[:,500]),\n",
    "                                        'time': ('time', ds.Time.values)})\n",
    "            ds_era_lon, ds_era_lat = np.meshgrid(ds_era.longitude.values, ds_era.latitude.values, indexing='xy')\n",
    "            # 转换为 xarray DataArray，确保其维度与 ds_era_clipped 对齐\n",
    "            ds_era_lon_da = xr.DataArray(ds_era_lon, dims=(\"latitude\", \"longitude\"), coords={\"latitude\": ds_era.latitude, \"longitude\": ds_era.longitude})\n",
    "            ds_era_lat_da = xr.DataArray(ds_era_lat, dims=(\"latitude\", \"longitude\"), coords={\"latitude\": ds_era.latitude, \"longitude\": ds_era.longitude})\n",
    "\n",
    "            # 使用 assign_coords 将二维坐标添加到 ds_era_clipped\n",
    "            ds_era_clipped = ds_era.assign_coords(lon_2d=ds_era_lon_da, lat_2d=ds_era_lat_da)\n",
    "\n",
    "            lon = ds_era_clipped['lon_2d'].values\n",
    "            lat = ds_era_clipped['lat_2d'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "\n",
    "            mask = np.full(ds_era_clipped['p'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds_era_clipped['p'].dims[1:], coords={'latitude': ds_era_clipped['p'].coords['latitude'], 'longitude': ds_era_clipped['p'].coords['longitude']})\n",
    "            ds_sss = ds_era_clipped.where(mask_da, drop=True)\n",
    "            ds_sss = ds_sss.drop_vars(['lon_2d', 'lat_2d'])\n",
    "\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.longitude >= lon_min) & (ds_sss.longitude < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.latitude.size > 0 and ds_lon_subset.longitude.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.latitude.min().values\n",
    "                    lat_max = ds_lon_subset.latitude.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "                    \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.latitude >= lat_min_split) & (ds_lon_subset.latitude < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '/N/project/Zli_lab/gongg/CONUS404_data/LST/re_UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17198a61-5afe-4f45-907e-04fc5bdbc353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
