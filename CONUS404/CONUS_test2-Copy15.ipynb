{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ee76b6-51df-494c-90e2-a92b2941e6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "### automatically refresh the buffer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### solve the auto-complete issue\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "### lvl 2 setups (systerm)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pylab import *\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Wedge, Circle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0073be-a0e7-4ebd-9142-f6b25ecf60d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../../tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/prec_acc_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d881bf-18cd-4ab2-8dec-b6f5799a3857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-06 17:11:14\n",
      "2024-10-06 17:24:32\n",
      "2024-10-06 17:37:55\n",
      "2024-10-06 17:51:58\n",
      "2024-10-06 18:06:29\n",
      "2024-10-06 18:19:32\n",
      "2024-10-06 18:33:38\n",
      "2024-10-06 18:47:54\n",
      "2024-10-06 19:03:22\n",
      "2024-10-06 19:18:35\n",
      "2024-10-06 19:33:07\n",
      "2024-10-06 19:46:49\n",
      "2024-10-06 20:00:24\n",
      "2024-10-06 20:14:02\n",
      "2024-10-06 20:26:53\n",
      "2024-10-06 20:39:27\n",
      "2024-10-06 20:52:06\n",
      "2024-10-06 21:03:39\n",
      "2024-10-06 21:16:22\n",
      "2024-10-06 21:29:06\n",
      "2024-10-06 21:41:30\n",
      "2024-10-06 21:53:45\n",
      "2024-10-06 22:06:41\n",
      "2024-10-06 22:20:19\n"
     ]
    }
   ],
   "source": [
    "start_year = 2009\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "        # 提取CONUS数据\n",
    "            lon = ds['XLONG'].values\n",
    "            lat = ds['XLAT'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "            \n",
    "            mask = np.full(ds['PREC_ACC_NC'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds['PREC_ACC_NC'].dims[1:], coords={'south_north': ds['PREC_ACC_NC'].coords['south_north'], 'west_east': ds['PREC_ACC_NC'].coords['west_east']})\n",
    "            ds_s = ds.where(mask_da, drop=True)\n",
    "            lonn = np.linspace(-124.848, -66.885, 1137)\n",
    "            latt = np.linspace(24.396, 49.384, 708)\n",
    "            prec = ds_s.PREC_ACC_NC.values\n",
    "            lat_min = latt.min()\n",
    "            lat_max = latt.max()\n",
    "            ds_sss = xr.Dataset({'p': (['time', 'lat', 'lon'], prec)},\n",
    "                                coords={'lon': (['lon'], lonn),\n",
    "                                        'lat': (['lat'], latt),\n",
    "                                        'time': ('time', ds_s.Time.values)})\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            \n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.lon >= lon_min) & (ds_sss.lon < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.lat.min().values\n",
    "                    lat_max = ds_lon_subset.lat.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "            \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.lat >= lat_min_split) & (ds_lon_subset.lat < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '../CONUS404_data/LST/UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df60ff8-0058-4436-83bf-dd1bd6795dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02 20:41:37\n",
      "2024-11-02 20:55:22\n",
      "2024-11-02 21:08:35\n",
      "2024-11-02 21:22:27\n",
      "2024-11-02 21:37:06\n",
      "2024-11-02 21:50:01\n",
      "2024-11-02 22:04:50\n",
      "2024-11-02 22:17:59\n",
      "2024-11-02 22:32:18\n",
      "2024-11-02 22:46:31\n",
      "2024-11-02 23:00:21\n",
      "2024-11-02 23:13:42\n",
      "2024-11-02 23:27:43\n",
      "2024-11-02 23:41:56\n",
      "2024-11-02 23:54:11\n",
      "2024-11-03 00:07:12\n",
      "2024-11-03 00:20:50\n",
      "2024-11-03 00:32:37\n",
      "2024-11-03 00:47:10\n",
      "2024-11-03 01:00:03\n",
      "2024-11-03 01:13:32\n",
      "2024-11-03 01:26:45\n",
      "2024-11-03 01:41:36\n",
      "2024-11-03 01:56:52\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('../../tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/CONUS404_T_dT/TarFiles/'\n",
    "\n",
    "start_year = 2009\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'765041.T2.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "        # 提取CONUS数据\n",
    "            lon = ds['XLONG'].values\n",
    "            lat = ds['XLAT'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "            \n",
    "            mask = np.full(ds['T2'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds['T2'].dims[1:], coords={'south_north': ds['T2'].coords['south_north'], 'west_east': ds['T2'].coords['west_east']})\n",
    "            ds_s = ds.where(mask_da, drop=True)\n",
    "            lonn = np.linspace(-124.848, -66.885, 1137)\n",
    "            latt = np.linspace(24.396, 49.384, 708)\n",
    "            prec = ds_s['T2'].values\n",
    "            lat_min = latt.min()\n",
    "            lat_max = latt.max()\n",
    "            ds_sss = xr.Dataset({'t2': (['time', 'lat', 'lon'], prec)},\n",
    "                                coords={'lon': (['lon'], lonn),\n",
    "                                        'lat': (['lat'], latt),\n",
    "                                        'time': ('time', ds_s.Time.values)})\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            \n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.lon >= lon_min) & (ds_sss.lon < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.lat.min().values\n",
    "                    lat_max = ds_lon_subset.lat.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "            \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.lat >= lat_min_split) & (ds_lon_subset.lat < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '../CONUS404_data/LST/UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'T2.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574d8a26-f15d-4618-971f-cd6d25807257",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-03 01:10:25\n",
      "2024-11-03 01:23:54\n",
      "2024-11-03 01:37:55\n",
      "2024-11-03 01:53:10\n",
      "2024-11-03 02:07:32\n",
      "2024-11-03 02:21:08\n",
      "2024-11-03 02:35:48\n",
      "2024-11-03 02:49:00\n",
      "2024-11-03 03:03:07\n",
      "2024-11-03 03:17:25\n",
      "2024-11-03 03:31:45\n",
      "2024-11-03 03:45:30\n",
      "2024-11-03 03:59:31\n",
      "2024-11-03 04:13:12\n",
      "2024-11-03 04:26:54\n",
      "2024-11-03 04:41:10\n",
      "2024-11-03 04:55:27\n",
      "2024-11-03 05:08:00\n",
      "2024-11-03 05:21:57\n",
      "2024-11-03 05:34:50\n",
      "2024-11-03 05:48:06\n",
      "2024-11-03 06:00:20\n",
      "2024-11-03 06:12:52\n",
      "2024-11-03 06:24:24\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('../../tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/CONUS404_T_dT/TarFiles/'\n",
    "\n",
    "start_year = 2009\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  \n",
    "            else:\n",
    "                num_days = 28  \n",
    "\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'765041.TD2.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "\n",
    "            lon = ds['XLONG'].values\n",
    "            lat = ds['XLAT'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "            \n",
    "            mask = np.full(ds['TD2'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds['TD2'].dims[1:], coords={'south_north': ds['TD2'].coords['south_north'], 'west_east': ds['TD2'].coords['west_east']})\n",
    "            ds_s = ds.where(mask_da, drop=True)\n",
    "            lonn = np.linspace(-124.848, -66.885, 1137)\n",
    "            latt = np.linspace(24.396, 49.384, 708)\n",
    "            prec = ds_s['TD2'].values\n",
    "            lat_min = latt.min()\n",
    "            lat_max = latt.max()\n",
    "            ds_sss = xr.Dataset({'td2': (['time', 'lat', 'lon'], prec)},\n",
    "                                coords={'lon': (['lon'], lonn),\n",
    "                                        'lat': (['lat'], latt),\n",
    "                                        'time': ('time', ds_s.Time.values)})\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            \n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.lon >= lon_min) & (ds_sss.lon < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.lat.min().values\n",
    "                    lat_max = ds_lon_subset.lat.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "            \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.lat >= lat_min_split) & (ds_lon_subset.lat < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '../CONUS404_data/LST/UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'TD2.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320aef11-f94a-4086-ae43-f6509dfcf349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:52:59.015308\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/N/project/Zli_lab/gongg/CONUS404_data/LST/JJA_dailydata/U-58_mt_1980_06_01.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/N/project/Zli_lab/gongg/CONUS404_data/LST/JJA_dailydata/U-58_mt_1980_06_01.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '0c2f1824-2b50-4ad6-8328-c807e423f9ef']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m filename_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mdt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# 导出每日数据为 NetCDF 文件\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mds_day_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfilename_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m ds_day_dt\u001b[38;5;241m.\u001b[39mto_netcdf(output\u001b[38;5;241m+\u001b[39mfilename_dt)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/core/dataset.py:2329\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   2326\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 2329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2337\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2340\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/backends/api.py:1343\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized option \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1342\u001b[0m         )\n\u001b[0;32m-> 1343\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mstore_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unlimited_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     unlimited_dims \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mencoding\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlimited_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:408\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    402\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    403\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    406\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    407\u001b[0m )\n\u001b[0;32m--> 408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:355\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:417\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:411\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 411\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/N/soft/rhel8/python/gnu/3.11.4/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2470\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2107\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/N/project/Zli_lab/gongg/CONUS404_data/LST/JJA_dailydata/U-58_mt_1980_06_01.nc'"
     ]
    }
   ],
   "source": [
    "input_folder_t = '/N/project/Zli_lab/gongg/CONUS404_data/LST/JJA/'\n",
    "base_path = '/N/project/Zli_lab/gongg/CONUS404_data/LST/UTC/'\n",
    "file_pattern_t = 'T2.wrf2d_d01_????-??-??.nc'\n",
    "file_pattern_dt = 'TD2.wrf2d_d01_????-??-??.nc'\n",
    "output = '/N/project/Zli_lab/gongg/CONUS404_data/LST/JJA_dailydata/'\n",
    "\n",
    "\n",
    "folder_names = ['U-58', \n",
    "     # 'U-50', 'U-51', 'U-52', 'U-53', 'U-54', 'U-55', 'U-56', 'U-57', 'U-58',\n",
    "     # 'U-60', 'U-61', 'U-62', 'U-63', 'U-64', 'U-65', 'U-66', 'U-67', 'U-68',\n",
    "     # 'U-70', 'U-71', 'U-72', 'U-73', 'U-74', 'U-75', 'U-76', 'U-77', 'U-78',\n",
    "     # 'U-80', 'U-81', 'U-82', 'U-83', 'U-84', 'U-85', 'U-86', 'U-87', 'U-88',\n",
    "]\n",
    "for folder in folder_names:\n",
    "    print(datetime.datetime.now().time())\n",
    "    full_path_t = os.path.join(base_path, folder, file_pattern_t)\n",
    "    full_path_dt = os.path.join(base_path, folder, file_pattern_dt)\n",
    "    all_files_t = glob.glob(full_path_t)\n",
    "    all_files_dt = glob.glob(full_path_dt)\n",
    "    #####\n",
    "    summer_files_t = [f for f in all_files_t if '-06-' in f or '-07-' in f or '-08-' in f or '-09-' in f]\n",
    "    summer_files_dt = [f for f in all_files_dt if '-06-' in f or '-07-' in f or '-08-' in f or '-09-' in f]\n",
    "    \n",
    "    \n",
    "    ds_t = xr.open_mfdataset(summer_files_t)\n",
    "    ds_t = ds_t.sel(time=ds_t['time'].dt.month.isin([6, 7, 8]))\n",
    "    ds_dt = xr.open_mfdataset(summer_files_dt)\n",
    "    ds_dt = ds_dt.sel(time=ds_dt['time'].dt.month.isin([6, 7, 8]))    \n",
    "    \n",
    "\n",
    "    grouped_t = ds_t.groupby('time.year').groups\n",
    "    grouped_dt = ds_dt.groupby('time.year').groups\n",
    "\n",
    "    for year, year_indices_t in grouped_t.items():\n",
    "        year_indices_t = grouped_t[year]\n",
    "        year_indices_dt = grouped_dt[year]\n",
    "\n",
    "        ds_year_t = ds_t.isel(time=year_indices_t)\n",
    "        ds_year_dt = ds_dt.isel(time=year_indices_dt)\n",
    "\n",
    "        monthly_groups_t = ds_year_t.groupby('time.month').groups\n",
    "        monthly_groups_dt = ds_year_dt.groupby('time.month').groups\n",
    "\n",
    "        for month, month_indices_t in monthly_groups_t.items():\n",
    "            month_indices_t = monthly_groups_t[month]\n",
    "            month_indices_dt = monthly_groups_dt[month]\n",
    "\n",
    "            ds_month_t = ds_year_t.isel(time=month_indices_t)\n",
    "            ds_month_dt = ds_year_dt.isel(time=month_indices_dt)\n",
    "\n",
    "            daily_groups_t = ds_month_t.groupby('time.day').groups\n",
    "            daily_groups_dt = ds_month_dt.groupby('time.day').groups\n",
    "\n",
    "            # 循环遍历每日的数据\n",
    "            for day, day_indices_t in daily_groups_t.items():\n",
    "                day_indices_t = daily_groups_t[day]\n",
    "                day_indices_dt = daily_groups_dt[day]\n",
    "\n",
    "                ds_day_t = ds_month_t.isel(time=day_indices_t)\n",
    "                ds_day_dt = ds_month_dt.isel(time=day_indices_dt)\n",
    "\n",
    "                filename_t = f'{folder}_mt_{year}_{month:02d}_{day:02d}.nc'\n",
    "                filename_dt = f'{folder}_mdt_{year}_{month:02d}_{day:02d}.nc'\n",
    "\n",
    "                # 导出每日数据为 NetCDF 文件\n",
    "                ds_day_t.to_netcdf(output+filename_t)\n",
    "                ds_day_dt.to_netcdf(output+filename_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e9161d-22fb-45d7-a67b-306385831026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-17 01:18:11\n",
      "2025-02-17 01:18:32\n",
      "2025-02-17 01:18:56\n",
      "2025-02-17 01:19:19\n",
      "2025-02-17 01:19:43\n",
      "2025-02-17 01:20:05\n",
      "2025-02-17 01:20:26\n",
      "2025-02-17 01:20:44\n",
      "2025-02-17 01:21:04\n",
      "2025-02-17 01:21:23\n",
      "2025-02-17 01:21:45\n",
      "2025-02-17 01:22:05\n",
      "2025-02-17 01:22:25\n",
      "2025-02-17 01:22:42\n",
      "2025-02-17 01:23:04\n",
      "2025-02-17 01:23:25\n",
      "2025-02-17 01:23:42\n",
      "2025-02-17 01:24:06\n",
      "2025-02-17 01:24:27\n",
      "2025-02-17 01:24:56\n",
      "2025-02-17 01:25:17\n",
      "2025-02-17 01:25:40\n",
      "2025-02-17 01:26:01\n",
      "2025-02-17 01:26:23\n",
      "2025-02-17 01:26:47\n",
      "2025-02-17 01:27:08\n",
      "2025-02-17 01:27:33\n",
      "2025-02-17 01:27:51\n",
      "2025-02-17 01:28:07\n",
      "2025-02-17 01:28:26\n",
      "2025-02-17 01:28:47\n",
      "2025-02-17 01:29:09\n",
      "2025-02-17 01:29:10\n",
      "2025-02-17 01:29:26\n",
      "2025-02-17 01:29:48\n",
      "2025-02-17 01:30:09\n",
      "2025-02-17 01:30:29\n",
      "2025-02-17 01:30:51\n",
      "2025-02-17 01:31:14\n",
      "2025-02-17 01:31:34\n",
      "2025-02-17 01:31:57\n",
      "2025-02-17 01:32:22\n",
      "2025-02-17 01:32:42\n",
      "2025-02-17 01:33:10\n",
      "2025-02-17 01:33:35\n",
      "2025-02-17 01:34:04\n",
      "2025-02-17 01:34:30\n",
      "2025-02-17 01:35:05\n",
      "2025-02-17 01:35:30\n",
      "2025-02-17 01:36:12\n",
      "2025-02-17 01:36:49\n",
      "2025-02-17 01:37:11\n",
      "2025-02-17 01:37:41\n",
      "2025-02-17 01:38:04\n",
      "2025-02-17 01:38:23\n",
      "2025-02-17 01:38:42\n",
      "2025-02-17 01:39:03\n",
      "2025-02-17 01:39:36\n",
      "2025-02-17 01:39:55\n",
      "2025-02-17 01:40:16\n",
      "2025-02-17 01:40:58\n",
      "2025-02-17 01:41:24\n",
      "2025-02-17 01:41:52\n",
      "2025-02-17 01:41:55\n",
      "2025-02-17 01:42:10\n",
      "2025-02-17 01:42:37\n",
      "2025-02-17 01:43:07\n",
      "2025-02-17 01:43:35\n",
      "2025-02-17 01:44:08\n",
      "2025-02-17 01:44:40\n",
      "2025-02-17 01:45:04\n",
      "2025-02-17 01:45:37\n",
      "2025-02-17 01:46:03\n",
      "2025-02-17 01:46:33\n",
      "2025-02-17 01:47:00\n",
      "2025-02-17 01:47:26\n",
      "2025-02-17 01:47:55\n",
      "2025-02-17 01:48:24\n",
      "2025-02-17 01:48:49\n",
      "2025-02-17 01:49:14\n",
      "2025-02-17 01:49:38\n",
      "2025-02-17 01:50:03\n",
      "2025-02-17 01:50:28\n",
      "2025-02-17 01:50:54\n",
      "2025-02-17 01:51:21\n",
      "2025-02-17 01:51:48\n",
      "2025-02-17 01:52:14\n",
      "2025-02-17 01:52:43\n",
      "2025-02-17 01:53:09\n",
      "2025-02-17 01:53:33\n",
      "2025-02-17 01:54:00\n",
      "2025-02-17 01:54:30\n",
      "2025-02-17 01:54:56\n",
      "2025-02-17 01:55:27\n",
      "2025-02-17 01:55:59\n",
      "2025-02-17 01:56:01\n",
      "2025-02-17 01:56:24\n",
      "2025-02-17 01:56:50\n",
      "2025-02-17 01:57:18\n",
      "2025-02-17 01:57:46\n",
      "2025-02-17 01:58:13\n",
      "2025-02-17 01:58:44\n",
      "2025-02-17 01:59:13\n",
      "2025-02-17 01:59:42\n",
      "2025-02-17 02:00:11\n",
      "2025-02-17 02:00:39\n",
      "2025-02-17 02:01:05\n",
      "2025-02-17 02:01:34\n",
      "2025-02-17 02:02:03\n",
      "2025-02-17 02:02:31\n",
      "2025-02-17 02:02:59\n",
      "2025-02-17 02:03:27\n",
      "2025-02-17 02:03:58\n",
      "2025-02-17 02:04:28\n",
      "2025-02-17 02:04:53\n",
      "2025-02-17 02:05:25\n",
      "2025-02-17 02:05:53\n",
      "2025-02-17 02:06:14\n",
      "2025-02-17 02:06:41\n",
      "2025-02-17 02:07:08\n",
      "2025-02-17 02:07:29\n",
      "2025-02-17 02:07:52\n",
      "2025-02-17 02:08:25\n",
      "2025-02-17 02:08:55\n",
      "2025-02-17 02:09:28\n",
      "2025-02-17 02:10:01\n",
      "2025-02-17 02:10:31\n",
      "2025-02-17 02:10:34\n",
      "2025-02-17 02:11:03\n",
      "2025-02-17 02:11:35\n",
      "2025-02-17 02:12:08\n",
      "2025-02-17 02:12:40\n",
      "2025-02-17 02:13:13\n",
      "2025-02-17 02:13:43\n",
      "2025-02-17 02:14:18\n",
      "2025-02-17 02:14:51\n",
      "2025-02-17 02:15:20\n",
      "2025-02-17 02:15:49\n",
      "2025-02-17 02:16:33\n",
      "2025-02-17 02:17:04\n",
      "2025-02-17 02:17:40\n",
      "2025-02-17 02:18:13\n",
      "2025-02-17 02:18:50\n",
      "2025-02-17 02:19:28\n",
      "2025-02-17 02:19:58\n",
      "2025-02-17 02:20:33\n",
      "2025-02-17 02:21:13\n",
      "2025-02-17 02:21:50\n",
      "2025-02-17 02:22:23\n",
      "2025-02-17 02:22:58\n",
      "2025-02-17 02:23:29\n",
      "2025-02-17 02:23:58\n",
      "2025-02-17 02:24:43\n",
      "2025-02-17 02:25:13\n",
      "2025-02-17 02:25:48\n",
      "2025-02-17 02:26:20\n",
      "2025-02-17 02:26:23\n",
      "2025-02-17 02:26:55\n",
      "2025-02-17 02:27:24\n",
      "2025-02-17 02:27:53\n",
      "2025-02-17 02:28:21\n",
      "2025-02-17 02:28:54\n",
      "2025-02-17 02:29:23\n",
      "2025-02-17 02:29:51\n",
      "2025-02-17 02:30:22\n",
      "2025-02-17 02:30:53\n",
      "2025-02-17 02:31:23\n",
      "2025-02-17 02:31:55\n",
      "2025-02-17 02:32:25\n",
      "2025-02-17 02:32:53\n",
      "2025-02-17 02:33:18\n",
      "2025-02-17 02:33:51\n",
      "2025-02-17 02:34:20\n",
      "2025-02-17 02:34:47\n",
      "2025-02-17 02:35:16\n",
      "2025-02-17 02:35:43\n",
      "2025-02-17 02:36:14\n",
      "2025-02-17 02:36:45\n",
      "2025-02-17 02:37:13\n",
      "2025-02-17 02:37:41\n",
      "2025-02-17 02:38:09\n",
      "2025-02-17 02:38:36\n",
      "2025-02-17 02:39:05\n",
      "2025-02-17 02:39:30\n",
      "2025-02-17 02:40:00\n",
      "2025-02-17 02:40:28\n",
      "2025-02-17 02:40:56\n",
      "2025-02-17 02:41:24\n",
      "2025-02-17 02:41:27\n",
      "2025-02-17 02:41:52\n",
      "2025-02-17 02:42:18\n",
      "2025-02-17 02:42:46\n",
      "2025-02-17 02:43:15\n",
      "2025-02-17 02:43:42\n",
      "2025-02-17 02:44:13\n",
      "2025-02-17 02:44:45\n",
      "2025-02-17 02:45:16\n",
      "2025-02-17 02:45:41\n",
      "2025-02-17 02:46:11\n",
      "2025-02-17 02:46:41\n",
      "2025-02-17 02:47:08\n",
      "2025-02-17 02:47:41\n",
      "2025-02-17 02:48:08\n",
      "2025-02-17 02:48:38\n",
      "2025-02-17 02:49:01\n",
      "2025-02-17 02:49:38\n",
      "2025-02-17 02:50:18\n",
      "2025-02-17 02:50:45\n",
      "2025-02-17 02:51:22\n",
      "2025-02-17 02:51:54\n",
      "2025-02-17 02:52:24\n",
      "2025-02-17 02:52:53\n",
      "2025-02-17 02:53:28\n",
      "2025-02-17 02:54:03\n",
      "2025-02-17 02:54:46\n",
      "2025-02-17 02:55:14\n",
      "2025-02-17 02:55:53\n",
      "2025-02-17 02:56:24\n",
      "2025-02-17 02:57:03\n",
      "2025-02-17 02:57:06\n",
      "2025-02-17 02:57:39\n",
      "2025-02-17 02:58:14\n",
      "2025-02-17 02:58:49\n",
      "2025-02-17 02:59:20\n",
      "2025-02-17 02:59:50\n",
      "2025-02-17 03:00:28\n",
      "2025-02-17 03:01:04\n",
      "2025-02-17 03:01:35\n",
      "2025-02-17 03:02:07\n",
      "2025-02-17 03:02:39\n",
      "2025-02-17 03:03:15\n",
      "2025-02-17 03:03:47\n",
      "2025-02-17 03:04:17\n",
      "2025-02-17 03:04:52\n",
      "2025-02-17 03:05:24\n",
      "2025-02-17 03:05:57\n",
      "2025-02-17 03:06:30\n",
      "2025-02-17 03:06:58\n",
      "2025-02-17 03:07:32\n",
      "2025-02-17 03:08:02\n",
      "2025-02-17 03:08:31\n",
      "2025-02-17 03:09:03\n",
      "2025-02-17 03:09:36\n",
      "2025-02-17 03:10:09\n",
      "2025-02-17 03:10:41\n",
      "2025-02-17 03:11:12\n",
      "2025-02-17 03:11:45\n",
      "2025-02-17 03:12:17\n",
      "2025-02-17 03:12:48\n",
      "2025-02-17 03:13:21\n",
      "2025-02-17 03:13:53\n",
      "2025-02-17 03:13:56\n",
      "2025-02-17 03:14:27\n",
      "2025-02-17 03:15:01\n",
      "2025-02-17 03:15:35\n",
      "2025-02-17 03:16:07\n",
      "2025-02-17 03:16:38\n",
      "2025-02-17 03:17:11\n",
      "2025-02-17 03:17:49\n",
      "2025-02-17 03:18:25\n",
      "2025-02-17 03:18:51\n",
      "2025-02-17 03:19:27\n",
      "2025-02-17 03:20:05\n",
      "2025-02-17 03:20:42\n",
      "2025-02-17 03:21:15\n",
      "2025-02-17 03:21:48\n",
      "2025-02-17 03:22:25\n",
      "2025-02-17 03:22:57\n",
      "2025-02-17 03:23:32\n",
      "2025-02-17 03:24:05\n",
      "2025-02-17 03:24:45\n",
      "2025-02-17 03:25:23\n",
      "2025-02-17 03:25:56\n",
      "2025-02-17 03:26:27\n",
      "2025-02-17 03:27:04\n",
      "2025-02-17 03:27:38\n",
      "2025-02-17 03:28:10\n",
      "2025-02-17 03:28:44\n",
      "2025-02-17 03:29:13\n",
      "2025-02-17 03:29:46\n",
      "2025-02-17 03:30:16\n",
      "2025-02-17 03:30:46\n",
      "2025-02-17 03:30:49\n",
      "2025-02-17 03:31:15\n",
      "2025-02-17 03:31:45\n",
      "2025-02-17 03:32:13\n",
      "2025-02-17 03:32:40\n",
      "2025-02-17 03:33:10\n",
      "2025-02-17 03:33:36\n",
      "2025-02-17 03:34:04\n",
      "2025-02-17 03:34:32\n",
      "2025-02-17 03:34:58\n",
      "2025-02-17 03:35:40\n",
      "2025-02-17 03:36:19\n",
      "2025-02-17 03:36:44\n",
      "2025-02-17 03:37:14\n",
      "2025-02-17 03:37:42\n",
      "2025-02-17 03:38:18\n",
      "2025-02-17 03:38:50\n",
      "2025-02-17 03:39:24\n",
      "2025-02-17 03:39:46\n",
      "2025-02-17 03:40:15\n",
      "2025-02-17 03:40:43\n",
      "2025-02-17 03:41:11\n",
      "2025-02-17 03:41:44\n",
      "2025-02-17 03:42:10\n",
      "2025-02-17 03:42:39\n",
      "2025-02-17 03:43:05\n",
      "2025-02-17 03:43:37\n",
      "2025-02-17 03:44:04\n",
      "2025-02-17 03:44:35\n",
      "2025-02-17 03:45:07\n",
      "2025-02-17 03:45:34\n",
      "2025-02-17 03:46:11\n",
      "2025-02-17 03:46:15\n",
      "2025-02-17 03:46:41\n",
      "2025-02-17 03:47:13\n",
      "2025-02-17 03:47:40\n",
      "2025-02-17 03:48:13\n",
      "2025-02-17 03:48:46\n",
      "2025-02-17 03:49:12\n",
      "2025-02-17 03:49:43\n",
      "2025-02-17 03:50:10\n",
      "2025-02-17 03:50:42\n",
      "2025-02-17 03:51:09\n",
      "2025-02-17 03:51:41\n",
      "2025-02-17 03:52:11\n",
      "2025-02-17 03:52:42\n",
      "2025-02-17 03:53:11\n",
      "2025-02-17 03:53:36\n",
      "2025-02-17 03:54:04\n",
      "2025-02-17 03:54:31\n",
      "2025-02-17 03:55:09\n",
      "2025-02-17 03:55:37\n",
      "2025-02-17 03:56:03\n",
      "2025-02-17 03:56:35\n",
      "2025-02-17 03:57:03\n",
      "2025-02-17 03:57:33\n",
      "2025-02-17 03:58:00\n",
      "2025-02-17 03:58:27\n",
      "2025-02-17 03:59:01\n",
      "2025-02-17 03:59:31\n",
      "2025-02-17 04:00:03\n",
      "2025-02-17 04:00:35\n",
      "2025-02-17 04:01:05\n",
      "2025-02-17 04:01:29\n",
      "2025-02-17 04:01:34\n",
      "2025-02-17 04:02:00\n",
      "2025-02-17 04:02:22\n",
      "2025-02-17 04:02:46\n",
      "2025-02-17 04:03:20\n",
      "2025-02-17 04:03:57\n",
      "2025-02-17 04:04:26\n",
      "2025-02-17 04:05:02\n",
      "2025-02-17 04:05:31\n",
      "2025-02-17 04:06:06\n",
      "2025-02-17 04:06:32\n",
      "2025-02-17 04:07:06\n",
      "2025-02-17 04:07:33\n",
      "2025-02-17 04:08:08\n",
      "2025-02-17 04:08:39\n",
      "2025-02-17 04:09:05\n",
      "2025-02-17 04:09:38\n",
      "2025-02-17 04:10:04\n",
      "2025-02-17 04:10:34\n",
      "2025-02-17 04:11:04\n",
      "2025-02-17 04:11:39\n",
      "2025-02-17 04:12:11\n",
      "2025-02-17 04:12:44\n",
      "2025-02-17 04:13:10\n",
      "2025-02-17 04:13:38\n",
      "2025-02-17 04:14:05\n",
      "2025-02-17 04:14:37\n",
      "2025-02-17 04:15:04\n",
      "2025-02-17 04:15:36\n",
      "2025-02-17 04:16:11\n",
      "2025-02-17 04:16:41\n",
      "2025-02-17 04:16:45\n",
      "2025-02-17 04:17:10\n",
      "2025-02-17 04:17:32\n",
      "2025-02-17 04:18:06\n",
      "2025-02-17 04:18:35\n",
      "2025-02-17 04:19:04\n",
      "2025-02-17 04:19:32\n",
      "2025-02-17 04:19:59\n",
      "2025-02-17 04:20:25\n",
      "2025-02-17 04:20:57\n",
      "2025-02-17 04:21:29\n",
      "2025-02-17 04:21:58\n",
      "2025-02-17 04:22:27\n",
      "2025-02-17 04:22:54\n",
      "2025-02-17 04:23:20\n",
      "2025-02-17 04:23:51\n",
      "2025-02-17 04:24:16\n",
      "2025-02-17 04:24:48\n",
      "2025-02-17 04:25:11\n",
      "2025-02-17 04:25:36\n",
      "2025-02-17 04:26:05\n",
      "2025-02-17 04:26:30\n",
      "2025-02-17 04:26:56\n",
      "2025-02-17 04:27:27\n",
      "2025-02-17 04:27:51\n",
      "2025-02-17 04:28:26\n",
      "2025-02-17 04:28:54\n",
      "2025-02-17 04:29:20\n",
      "2025-02-17 04:29:48\n",
      "2025-02-17 04:30:25\n",
      "2025-02-17 04:30:52\n",
      "2025-02-17 04:31:31\n",
      "2025-02-17 04:31:33\n",
      "2025-02-17 04:31:55\n",
      "2025-02-17 04:32:21\n",
      "2025-02-17 04:32:51\n",
      "2025-02-17 04:33:20\n",
      "2025-02-17 04:33:51\n",
      "2025-02-17 04:34:20\n",
      "2025-02-17 04:34:42\n",
      "2025-02-17 04:35:12\n",
      "2025-02-17 04:35:39\n",
      "2025-02-17 04:36:08\n",
      "2025-02-17 04:36:36\n",
      "2025-02-17 04:37:01\n",
      "2025-02-17 04:37:30\n",
      "2025-02-17 04:37:56\n",
      "2025-02-17 04:38:20\n",
      "2025-02-17 04:38:43\n",
      "2025-02-17 04:39:10\n",
      "2025-02-17 04:39:43\n",
      "2025-02-17 04:40:18\n",
      "2025-02-17 04:40:50\n",
      "2025-02-17 04:41:13\n",
      "2025-02-17 04:41:45\n",
      "2025-02-17 04:42:18\n",
      "2025-02-17 04:42:44\n",
      "2025-02-17 04:43:11\n",
      "2025-02-17 04:43:54\n",
      "2025-02-17 04:44:25\n",
      "2025-02-17 04:44:57\n",
      "2025-02-17 04:45:22\n",
      "2025-02-17 04:45:49\n",
      "2025-02-17 04:45:52\n",
      "2025-02-17 04:46:23\n",
      "2025-02-17 04:46:50\n",
      "2025-02-17 04:47:17\n",
      "2025-02-17 04:47:46\n",
      "2025-02-17 04:48:14\n",
      "2025-02-17 04:48:45\n",
      "2025-02-17 04:49:16\n",
      "2025-02-17 04:49:44\n",
      "2025-02-17 04:50:16\n",
      "2025-02-17 04:50:41\n",
      "2025-02-17 04:51:15\n",
      "2025-02-17 04:51:42\n",
      "2025-02-17 04:52:10\n",
      "2025-02-17 04:52:38\n",
      "2025-02-17 04:53:02\n",
      "2025-02-17 04:53:28\n",
      "2025-02-17 04:53:53\n",
      "2025-02-17 04:54:18\n",
      "2025-02-17 04:54:49\n",
      "2025-02-17 04:55:15\n",
      "2025-02-17 04:55:44\n",
      "2025-02-17 04:56:10\n",
      "2025-02-17 04:56:38\n",
      "2025-02-17 04:57:04\n",
      "2025-02-17 04:57:37\n",
      "2025-02-17 04:58:12\n",
      "2025-02-17 04:58:35\n",
      "2025-02-17 04:59:06\n",
      "2025-02-17 04:59:36\n",
      "2025-02-17 05:00:06\n",
      "2025-02-17 05:00:39\n",
      "2025-02-17 05:00:42\n",
      "2025-02-17 05:01:10\n",
      "2025-02-17 05:01:40\n",
      "2025-02-17 05:02:16\n",
      "2025-02-17 05:02:41\n",
      "2025-02-17 05:03:07\n",
      "2025-02-17 05:03:46\n",
      "2025-02-17 05:04:12\n",
      "2025-02-17 05:04:39\n",
      "2025-02-17 05:05:04\n",
      "2025-02-17 05:05:33\n",
      "2025-02-17 05:06:02\n",
      "2025-02-17 05:06:35\n",
      "2025-02-17 05:07:03\n",
      "2025-02-17 05:07:31\n",
      "2025-02-17 05:08:01\n",
      "2025-02-17 05:08:34\n",
      "2025-02-17 05:09:02\n",
      "2025-02-17 05:09:25\n",
      "2025-02-17 05:09:52\n",
      "2025-02-17 05:10:21\n",
      "2025-02-17 05:10:49\n",
      "2025-02-17 05:11:11\n",
      "2025-02-17 05:11:35\n",
      "2025-02-17 05:11:59\n",
      "2025-02-17 05:12:23\n",
      "2025-02-17 05:12:48\n",
      "2025-02-17 05:13:13\n",
      "2025-02-17 05:13:37\n",
      "2025-02-17 05:14:04\n",
      "2025-02-17 05:14:25\n",
      "2025-02-17 05:14:44\n",
      "2025-02-17 05:14:46\n",
      "2025-02-17 05:15:17\n",
      "2025-02-17 05:15:47\n",
      "2025-02-17 05:16:16\n",
      "2025-02-17 05:16:52\n",
      "2025-02-17 05:17:26\n",
      "2025-02-17 05:17:54\n",
      "2025-02-17 05:18:22\n",
      "2025-02-17 05:18:39\n",
      "2025-02-17 05:19:06\n",
      "2025-02-17 05:19:30\n",
      "2025-02-17 05:20:00\n",
      "2025-02-17 05:20:29\n",
      "2025-02-17 05:20:59\n",
      "2025-02-17 05:21:29\n",
      "2025-02-17 05:21:57\n",
      "2025-02-17 05:22:25\n",
      "2025-02-17 05:22:52\n",
      "2025-02-17 05:23:18\n",
      "2025-02-17 05:23:44\n",
      "2025-02-17 05:24:11\n",
      "2025-02-17 05:24:38\n",
      "2025-02-17 05:25:10\n",
      "2025-02-17 05:25:33\n",
      "2025-02-17 05:25:56\n",
      "2025-02-17 05:26:22\n",
      "2025-02-17 05:26:49\n",
      "2025-02-17 05:27:15\n",
      "2025-02-17 05:27:39\n",
      "2025-02-17 05:27:42\n",
      "2025-02-17 05:28:05\n",
      "2025-02-17 05:28:33\n",
      "2025-02-17 05:28:52\n",
      "2025-02-17 05:29:20\n",
      "2025-02-17 05:29:50\n",
      "2025-02-17 05:30:18\n",
      "2025-02-17 05:30:44\n",
      "2025-02-17 05:31:10\n",
      "2025-02-17 05:31:40\n",
      "2025-02-17 05:32:06\n",
      "2025-02-17 05:32:34\n",
      "2025-02-17 05:32:59\n",
      "2025-02-17 05:33:31\n",
      "2025-02-17 05:33:57\n",
      "2025-02-17 05:34:24\n",
      "2025-02-17 05:34:59\n",
      "2025-02-17 05:35:34\n",
      "2025-02-17 05:36:08\n",
      "2025-02-17 05:36:41\n",
      "2025-02-17 05:37:06\n",
      "2025-02-17 05:37:29\n",
      "2025-02-17 05:37:57\n",
      "2025-02-17 05:38:25\n",
      "2025-02-17 05:38:47\n",
      "2025-02-17 05:39:18\n",
      "2025-02-17 05:39:41\n",
      "2025-02-17 05:40:07\n",
      "2025-02-17 05:40:38\n",
      "2025-02-17 05:41:01\n",
      "2025-02-17 05:41:35\n",
      "2025-02-17 05:41:57\n",
      "2025-02-17 05:42:00\n",
      "2025-02-17 05:42:18\n",
      "2025-02-17 05:42:45\n",
      "2025-02-17 05:43:13\n",
      "2025-02-17 05:43:42\n",
      "2025-02-17 05:44:09\n",
      "2025-02-17 05:44:33\n",
      "2025-02-17 05:44:57\n",
      "2025-02-17 05:45:19\n",
      "2025-02-17 05:45:43\n",
      "2025-02-17 05:46:12\n",
      "2025-02-17 05:46:38\n",
      "2025-02-17 05:47:04\n",
      "2025-02-17 05:47:28\n",
      "2025-02-17 05:47:54\n",
      "2025-02-17 05:48:20\n",
      "2025-02-17 05:48:48\n",
      "2025-02-17 05:49:19\n",
      "2025-02-17 05:49:41\n",
      "2025-02-17 05:50:08\n",
      "2025-02-17 05:50:37\n",
      "2025-02-17 05:51:11\n",
      "2025-02-17 05:51:38\n",
      "2025-02-17 05:52:03\n",
      "2025-02-17 05:52:31\n",
      "2025-02-17 05:53:01\n",
      "2025-02-17 05:53:25\n",
      "2025-02-17 05:53:48\n",
      "2025-02-17 05:54:08\n",
      "2025-02-17 05:54:31\n",
      "2025-02-17 05:54:53\n",
      "2025-02-17 05:54:55\n",
      "2025-02-17 05:55:20\n",
      "2025-02-17 05:55:42\n",
      "2025-02-17 05:56:19\n",
      "2025-02-17 05:56:42\n",
      "2025-02-17 05:57:07\n",
      "2025-02-17 05:57:34\n",
      "2025-02-17 05:58:00\n",
      "2025-02-17 05:58:32\n",
      "2025-02-17 05:59:00\n",
      "2025-02-17 05:59:24\n",
      "2025-02-17 06:00:01\n",
      "2025-02-17 06:00:22\n",
      "2025-02-17 06:00:46\n",
      "2025-02-17 06:01:19\n",
      "2025-02-17 06:01:45\n",
      "2025-02-17 06:02:16\n",
      "2025-02-17 06:02:43\n",
      "2025-02-17 06:03:10\n",
      "2025-02-17 06:03:33\n",
      "2025-02-17 06:03:58\n",
      "2025-02-17 06:04:24\n",
      "2025-02-17 06:04:54\n",
      "2025-02-17 06:05:19\n",
      "2025-02-17 06:05:45\n",
      "2025-02-17 06:06:10\n",
      "2025-02-17 06:06:37\n",
      "2025-02-17 06:07:04\n",
      "2025-02-17 06:07:28\n",
      "2025-02-17 06:07:55\n",
      "2025-02-17 06:08:22\n",
      "2025-02-17 06:08:51\n",
      "2025-02-17 06:08:57\n",
      "2025-02-17 06:09:13\n",
      "2025-02-17 06:09:37\n",
      "2025-02-17 06:09:58\n",
      "2025-02-17 06:10:18\n",
      "2025-02-17 06:10:47\n",
      "2025-02-17 06:11:18\n",
      "2025-02-17 06:11:47\n",
      "2025-02-17 06:12:14\n",
      "2025-02-17 06:12:38\n",
      "2025-02-17 06:13:13\n",
      "2025-02-17 06:13:35\n",
      "2025-02-17 06:14:07\n",
      "2025-02-17 06:14:34\n",
      "2025-02-17 06:14:55\n",
      "2025-02-17 06:15:32\n",
      "2025-02-17 06:16:04\n",
      "2025-02-17 06:16:24\n",
      "2025-02-17 06:16:53\n",
      "2025-02-17 06:17:23\n",
      "2025-02-17 06:17:47\n",
      "2025-02-17 06:18:13\n",
      "2025-02-17 06:18:45\n",
      "2025-02-17 06:19:11\n",
      "2025-02-17 06:19:34\n",
      "2025-02-17 06:20:04\n",
      "2025-02-17 06:20:33\n",
      "2025-02-17 06:20:57\n",
      "2025-02-17 06:21:20\n",
      "2025-02-17 06:21:48\n",
      "2025-02-17 06:22:11\n",
      "2025-02-17 06:22:14\n",
      "2025-02-17 06:22:39\n",
      "2025-02-17 06:23:07\n",
      "2025-02-17 06:23:31\n",
      "2025-02-17 06:23:57\n",
      "2025-02-17 06:24:18\n",
      "2025-02-17 06:24:40\n",
      "2025-02-17 06:24:59\n",
      "2025-02-17 06:25:28\n",
      "2025-02-17 06:25:50\n",
      "2025-02-17 06:26:11\n",
      "2025-02-17 06:26:35\n",
      "2025-02-17 06:26:58\n",
      "2025-02-17 06:27:18\n",
      "2025-02-17 06:27:42\n",
      "2025-02-17 06:28:07\n",
      "2025-02-17 06:28:30\n",
      "2025-02-17 06:28:54\n",
      "2025-02-17 06:29:20\n",
      "2025-02-17 06:29:53\n",
      "2025-02-17 06:30:15\n",
      "2025-02-17 06:30:42\n",
      "2025-02-17 06:31:10\n",
      "2025-02-17 06:31:34\n",
      "2025-02-17 06:32:04\n",
      "2025-02-17 06:32:28\n",
      "2025-02-17 06:32:51\n",
      "2025-02-17 06:33:11\n",
      "2025-02-17 06:33:39\n",
      "2025-02-17 06:34:06\n",
      "2025-02-17 06:34:33\n",
      "2025-02-17 06:34:56\n",
      "2025-02-17 06:34:58\n",
      "2025-02-17 06:35:16\n",
      "2025-02-17 06:35:40\n",
      "2025-02-17 06:36:07\n",
      "2025-02-17 06:36:32\n",
      "2025-02-17 06:36:57\n",
      "2025-02-17 06:37:20\n",
      "2025-02-17 06:37:40\n",
      "2025-02-17 06:38:04\n",
      "2025-02-17 06:38:43\n",
      "2025-02-17 06:39:06\n",
      "2025-02-17 06:39:30\n",
      "2025-02-17 06:40:03\n",
      "2025-02-17 06:40:23\n",
      "2025-02-17 06:40:42\n",
      "2025-02-17 06:41:00\n",
      "2025-02-17 06:41:26\n",
      "2025-02-17 06:41:46\n",
      "2025-02-17 06:42:04\n",
      "2025-02-17 06:42:25\n",
      "2025-02-17 06:42:44\n",
      "2025-02-17 06:43:02\n",
      "2025-02-17 06:43:19\n",
      "2025-02-17 06:43:36\n",
      "2025-02-17 06:43:54\n",
      "2025-02-17 06:44:09\n",
      "2025-02-17 06:44:28\n",
      "2025-02-17 06:44:43\n",
      "2025-02-17 06:45:01\n",
      "2025-02-17 06:45:18\n",
      "2025-02-17 06:45:34\n",
      "2025-02-17 06:45:50\n",
      "2025-02-17 06:45:53\n",
      "2025-02-17 06:46:09\n",
      "2025-02-17 06:46:25\n",
      "2025-02-17 06:46:41\n",
      "2025-02-17 06:46:58\n",
      "2025-02-17 06:47:13\n",
      "2025-02-17 06:47:28\n",
      "2025-02-17 06:47:43\n",
      "2025-02-17 06:47:59\n",
      "2025-02-17 06:48:16\n",
      "2025-02-17 06:48:33\n",
      "2025-02-17 06:48:48\n",
      "2025-02-17 06:49:06\n",
      "2025-02-17 06:49:25\n",
      "2025-02-17 06:49:41\n",
      "2025-02-17 06:49:58\n",
      "2025-02-17 06:50:21\n",
      "2025-02-17 06:50:36\n",
      "2025-02-17 06:50:56\n",
      "2025-02-17 06:51:25\n",
      "2025-02-17 06:51:47\n",
      "2025-02-17 06:52:15\n",
      "2025-02-17 06:52:35\n",
      "2025-02-17 06:52:53\n",
      "2025-02-17 06:53:09\n",
      "2025-02-17 06:53:28\n",
      "2025-02-17 06:53:43\n",
      "2025-02-17 06:54:02\n",
      "2025-02-17 06:54:15\n",
      "2025-02-17 06:54:29\n",
      "2025-02-17 06:54:43\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('/N/project/Zli_lab/Data/Other/tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/prec_acc_files/'\n",
    "\n",
    "start_year = 2005\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "            ds_era = xr.Dataset({'p': (['time', 'latitude', 'longitude'], ds.PREC_ACC_NC.values)},\n",
    "                                coords={'longitude': (['longitude'], ds.XLONG.values[500]),\n",
    "                                        'latitude': (['latitude'], ds.XLAT.values[:,500]),\n",
    "                                        'time': ('time', ds.Time.values)})\n",
    "            ds_era_lon, ds_era_lat = np.meshgrid(ds_era.longitude.values, ds_era.latitude.values, indexing='xy')\n",
    "            # 转换为 xarray DataArray，确保其维度与 ds_era_clipped 对齐\n",
    "            ds_era_lon_da = xr.DataArray(ds_era_lon, dims=(\"latitude\", \"longitude\"), coords={\"latitude\": ds_era.latitude, \"longitude\": ds_era.longitude})\n",
    "            ds_era_lat_da = xr.DataArray(ds_era_lat, dims=(\"latitude\", \"longitude\"), coords={\"latitude\": ds_era.latitude, \"longitude\": ds_era.longitude})\n",
    "\n",
    "            # 使用 assign_coords 将二维坐标添加到 ds_era_clipped\n",
    "            ds_era_clipped = ds_era.assign_coords(lon_2d=ds_era_lon_da, lat_2d=ds_era_lat_da)\n",
    "\n",
    "            lon = ds_era_clipped['lon_2d'].values\n",
    "            lat = ds_era_clipped['lat_2d'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "\n",
    "            mask = np.full(ds_era_clipped['p'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds_era_clipped['p'].dims[1:], coords={'latitude': ds_era_clipped['p'].coords['latitude'], 'longitude': ds_era_clipped['p'].coords['longitude']})\n",
    "            ds_sss = ds_era_clipped.where(mask_da, drop=True)\n",
    "            ds_sss = ds_sss.drop_vars(['lon_2d', 'lat_2d'])\n",
    "\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.longitude >= lon_min) & (ds_sss.longitude < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.latitude.size > 0 and ds_lon_subset.longitude.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.latitude.min().values\n",
    "                    lat_max = ds_lon_subset.latitude.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "                    \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.latitude >= lat_min_split) & (ds_lon_subset.latitude < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '/N/project/Zli_lab/gongg/CONUS404_data/LST/re_UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612089f-6cb3-4450-9b72-30ec25715d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
