{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ee76b6-51df-494c-90e2-a92b2941e6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### automatically refresh the buffer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### solve the auto-complete issue\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "### lvl 2 setups (systerm)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pylab import *\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Wedge, Circle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0073be-a0e7-4ebd-9142-f6b25ecf60d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../../tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/prec_acc_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d881bf-18cd-4ab2-8dec-b6f5799a3857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-06 17:09:07\n",
      "2024-10-06 17:20:21\n",
      "2024-10-06 17:32:43\n",
      "2024-10-06 17:46:09\n",
      "2024-10-06 18:00:05\n",
      "2024-10-06 18:13:28\n",
      "2024-10-06 18:27:06\n",
      "2024-10-06 18:40:27\n",
      "2024-10-06 18:53:54\n",
      "2024-10-06 19:07:10\n",
      "2024-10-06 19:21:16\n",
      "2024-10-06 19:35:44\n",
      "2024-10-06 19:49:16\n",
      "2024-10-06 20:04:02\n",
      "2024-10-06 20:17:04\n",
      "2024-10-06 20:31:00\n",
      "2024-10-06 20:44:18\n",
      "2024-10-06 20:56:22\n",
      "2024-10-06 21:09:58\n",
      "2024-10-06 21:22:53\n",
      "2024-10-06 21:35:46\n",
      "2024-10-06 21:48:13\n",
      "2024-10-06 22:01:16\n",
      "2024-10-06 22:14:20\n"
     ]
    }
   ],
   "source": [
    "start_year = 1991\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "        # 提取CONUS数据\n",
    "            lon = ds['XLONG'].values\n",
    "            lat = ds['XLAT'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "            \n",
    "            mask = np.full(ds['PREC_ACC_NC'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds['PREC_ACC_NC'].dims[1:], coords={'south_north': ds['PREC_ACC_NC'].coords['south_north'], 'west_east': ds['PREC_ACC_NC'].coords['west_east']})\n",
    "            ds_s = ds.where(mask_da, drop=True)\n",
    "            lonn = np.linspace(-124.848, -66.885, 1137)\n",
    "            latt = np.linspace(24.396, 49.384, 708)\n",
    "            prec = ds_s.PREC_ACC_NC.values\n",
    "            lat_min = latt.min()\n",
    "            lat_max = latt.max()\n",
    "            ds_sss = xr.Dataset({'p': (['time', 'lat', 'lon'], prec)},\n",
    "                                coords={'lon': (['lon'], lonn),\n",
    "                                        'lat': (['lat'], latt),\n",
    "                                        'time': ('time', ds_s.Time.values)})\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            \n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.lon >= lon_min) & (ds_sss.lon < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.lat.min().values\n",
    "                    lat_max = ds_lon_subset.lat.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "            \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.lat >= lat_min_split) & (ds_lon_subset.lat < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '../CONUS404_data/LST/UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df60ff8-0058-4436-83bf-dd1bd6795dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02 20:39:47\n",
      "2024-11-02 20:52:28\n",
      "2024-11-02 21:06:20\n",
      "2024-11-02 21:19:38\n",
      "2024-11-02 21:33:50\n",
      "2024-11-02 21:46:35\n",
      "2024-11-02 22:00:29\n",
      "2024-11-02 22:13:52\n",
      "2024-11-02 22:27:31\n",
      "2024-11-02 22:41:17\n",
      "2024-11-02 22:54:45\n",
      "2024-11-02 23:08:39\n",
      "2024-11-02 23:21:56\n",
      "2024-11-02 23:35:55\n",
      "2024-11-02 23:48:37\n",
      "2024-11-03 00:01:46\n",
      "2024-11-03 00:14:51\n",
      "2024-11-03 00:26:52\n",
      "2024-11-03 00:40:51\n",
      "2024-11-03 00:54:37\n",
      "2024-11-03 01:08:40\n",
      "2024-11-03 01:22:21\n",
      "2024-11-03 01:36:17\n",
      "2024-11-03 01:50:00\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('../../tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/CONUS404_T_dT/TarFiles/'\n",
    "\n",
    "start_year = 1991\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'765041.T2.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "        # 提取CONUS数据\n",
    "            lon = ds['XLONG'].values\n",
    "            lat = ds['XLAT'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "            \n",
    "            mask = np.full(ds['T2'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds['T2'].dims[1:], coords={'south_north': ds['T2'].coords['south_north'], 'west_east': ds['T2'].coords['west_east']})\n",
    "            ds_s = ds.where(mask_da, drop=True)\n",
    "            lonn = np.linspace(-124.848, -66.885, 1137)\n",
    "            latt = np.linspace(24.396, 49.384, 708)\n",
    "            prec = ds_s['T2'].values\n",
    "            lat_min = latt.min()\n",
    "            lat_max = latt.max()\n",
    "            ds_sss = xr.Dataset({'t2': (['time', 'lat', 'lon'], prec)},\n",
    "                                coords={'lon': (['lon'], lonn),\n",
    "                                        'lat': (['lat'], latt),\n",
    "                                        'time': ('time', ds_s.Time.values)})\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            \n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.lon >= lon_min) & (ds_sss.lon < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.lat.min().values\n",
    "                    lat_max = ds_lon_subset.lat.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "            \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.lat >= lat_min_split) & (ds_lon_subset.lat < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '../CONUS404_data/LST/UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'T2.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2db5cc-c474-405b-9ab7-ad873e5489e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-03 01:03:28\n",
      "2024-11-03 01:17:45\n",
      "2024-11-03 01:31:24\n",
      "2024-11-03 01:46:06\n",
      "2024-11-03 02:01:10\n",
      "2024-11-03 02:15:29\n",
      "2024-11-03 02:28:59\n",
      "2024-11-03 02:41:29\n",
      "2024-11-03 02:54:34\n",
      "2024-11-03 03:07:05\n",
      "2024-11-03 03:21:36\n",
      "2024-11-03 03:35:42\n",
      "2024-11-03 03:48:48\n",
      "2024-11-03 04:01:59\n",
      "2024-11-03 04:15:07\n",
      "2024-11-03 04:28:56\n",
      "2024-11-03 04:42:59\n",
      "2024-11-03 04:54:58\n",
      "2024-11-03 05:09:02\n",
      "2024-11-03 05:21:57\n",
      "2024-11-03 05:34:52\n",
      "2024-11-03 05:47:10\n",
      "2024-11-03 05:59:54\n",
      "2024-11-03 06:12:28\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('../../tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/CONUS404_T_dT/TarFiles/'\n",
    "\n",
    "start_year = 1991\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  \n",
    "            else:\n",
    "                num_days = 28  \n",
    "\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'765041.TD2.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "\n",
    "            lon = ds['XLONG'].values\n",
    "            lat = ds['XLAT'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "            \n",
    "            mask = np.full(ds['TD2'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds['TD2'].dims[1:], coords={'south_north': ds['TD2'].coords['south_north'], 'west_east': ds['TD2'].coords['west_east']})\n",
    "            ds_s = ds.where(mask_da, drop=True)\n",
    "            lonn = np.linspace(-124.848, -66.885, 1137)\n",
    "            latt = np.linspace(24.396, 49.384, 708)\n",
    "            prec = ds_s['TD2'].values\n",
    "            lat_min = latt.min()\n",
    "            lat_max = latt.max()\n",
    "            ds_sss = xr.Dataset({'td2': (['time', 'lat', 'lon'], prec)},\n",
    "                                coords={'lon': (['lon'], lonn),\n",
    "                                        'lat': (['lat'], latt),\n",
    "                                        'time': ('time', ds_s.Time.values)})\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            \n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.lon >= lon_min) & (ds_sss.lon < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.lat.size > 0 and ds_lon_subset.lon.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.lat.min().values\n",
    "                    lat_max = ds_lon_subset.lat.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "            \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.lat >= lat_min_split) & (ds_lon_subset.lat < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '../CONUS404_data/LST/UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'TD2.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09e95f1-0b23-4caa-afff-321bd1db3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def create_temp_dataset(arr_t, latt, lonn):\n",
    "\n",
    "    arr_ntt = arr_t.reshape(43, 92, 24, arr_t.shape[1], arr_t.shape[2])\n",
    "    selected_data = np.concatenate((arr_ntt[:, :, 0:6, :, :], arr_ntt[:, :, 18:24, :, :]), axis=2)\n",
    "\n",
    "    arr_tmin = np.nanmean(np.nanmin(selected_data, axis=2),axis=1)\n",
    "    arr_tmean = np.nanmean(np.nanmean(selected_data, axis=2),axis=1)\n",
    "    \n",
    "    ds_tmin = xr.Dataset(\n",
    "        {'t': (['year',  'lat', 'lon'], arr_tmin)},\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(1980, 2023)),\n",
    "            'lat': (['lat'], latt),\n",
    "            'lon': (['lon'], lonn)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    ds_tmean = xr.Dataset(\n",
    "        {'t': (['year',  'lat', 'lon'], arr_tmean)},\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(1980, 2023)),\n",
    "            'lat': (['lat'], latt),\n",
    "            'lon': (['lon'], lonn)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return ds_tmin,ds_tmean\n",
    "\n",
    "\n",
    "\n",
    "def create_dtemp_dataset(arr_t, latt, lonn):\n",
    "\n",
    "    arr_ntt = arr_t.reshape(43, 92, 24, arr_t.shape[1], arr_t.shape[2])\n",
    "    selected_data = np.concatenate((arr_ntt[:, :, 0:6, :, :], arr_ntt[:, :, 18:24, :, :]), axis=2)\n",
    "\n",
    "    arr_tmin = np.nanmean(np.nanmin(selected_data, axis=2),axis=1)\n",
    "    arr_tmean = np.nanmean(np.nanmean(selected_data, axis=2),axis=1)\n",
    "    \n",
    "    ds_dtmin = xr.Dataset(\n",
    "        {'dt': (['year',  'lat', 'lon'], arr_tmin)},\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(1980, 2023)),\n",
    "            'lat': (['lat'], latt),\n",
    "            'lon': (['lon'], lonn)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    ds_dtmean = xr.Dataset(\n",
    "        {'dt': (['year',  'lat', 'lon'], arr_tmean)},\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(1980, 2023)),\n",
    "            'lat': (['lat'], latt),\n",
    "            'lon': (['lon'], lonn)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return ds_dtmin,ds_dtmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1382971d-5291-4dbf-b897-85cd34785769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-03 21:16:20\n",
      "2024-11-03 21:21:33\n",
      "2024-11-03 21:26:41\n",
      "2024-11-03 21:31:59\n",
      "2024-11-03 21:37:18\n",
      "2024-11-03 21:42:18\n",
      "2024-11-03 21:47:37\n",
      "2024-11-03 21:53:08\n",
      "2024-11-03 21:58:30\n"
     ]
    }
   ],
   "source": [
    "base_path = '/N/project/Zli_lab/gongg/CONUS404_data/LST/UTC/'\n",
    "file_pattern = 'TD2.wrf2d_d01_????-??-??.nc'\n",
    "\n",
    "folder_names = [\n",
    "\n",
    "    'U-70', 'U-71', 'U-72', 'U-73', 'U-74', 'U-75', 'U-76', 'U-77', 'U-78',\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "for folder in folder_names:\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    full_path = os.path.join(base_path, folder, file_pattern)\n",
    "    all_files = glob.glob(full_path)\n",
    "    #####\n",
    "    summer_files = [f for f in all_files if '-06-' in f or '-07-' in f or '-08-' in f or '-09-' in f]\n",
    "    ds_summer = xr.open_mfdataset(summer_files)\n",
    "    ds_jja = ds_summer.sel(time=ds_summer['time'].dt.month.isin([6, 7, 8]))\n",
    "    lonn = ds_jja.lon.values\n",
    "    latt = ds_jja.lat.values\n",
    "    arr_t = ds_jja.td2.values\n",
    "\n",
    "    ds_dtmin,ds_dtmean = create_dtemp_dataset(arr_t, latt, lonn)\n",
    "\n",
    "    output_folder = '/N/project/Zli_lab/gongg/CONUS404_data/LST/JJA/'\n",
    "    ds_dtmin.to_netcdf(output_folder+'dtemp_min_'+folder+'.nc')\n",
    "    ds_dtmean.to_netcdf(output_folder+'dtemp_mean_'+folder+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed0ac7a-aa90-4580-8e8c-d5426cc36245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-17 01:09:17\n",
      "2025-02-17 01:09:32\n",
      "2025-02-17 01:09:47\n",
      "2025-02-17 01:10:00\n",
      "2025-02-17 01:10:16\n",
      "2025-02-17 01:10:30\n",
      "2025-02-17 01:10:44\n",
      "2025-02-17 01:10:59\n",
      "2025-02-17 01:11:15\n",
      "2025-02-17 01:11:38\n",
      "2025-02-17 01:11:53\n",
      "2025-02-17 01:12:12\n",
      "2025-02-17 01:12:25\n",
      "2025-02-17 01:12:41\n",
      "2025-02-17 01:12:56\n",
      "2025-02-17 01:13:18\n",
      "2025-02-17 01:13:32\n",
      "2025-02-17 01:13:51\n",
      "2025-02-17 01:14:10\n",
      "2025-02-17 01:14:24\n",
      "2025-02-17 01:14:40\n",
      "2025-02-17 01:14:52\n",
      "2025-02-17 01:15:13\n",
      "2025-02-17 01:15:27\n",
      "2025-02-17 01:15:41\n",
      "2025-02-17 01:15:55\n",
      "2025-02-17 01:16:10\n",
      "2025-02-17 01:16:28\n",
      "2025-02-17 01:16:48\n",
      "2025-02-17 01:17:02\n",
      "2025-02-17 01:17:20\n",
      "2025-02-17 01:17:34\n",
      "2025-02-17 01:17:36\n",
      "2025-02-17 01:17:52\n",
      "2025-02-17 01:18:06\n",
      "2025-02-17 01:18:22\n",
      "2025-02-17 01:18:40\n",
      "2025-02-17 01:18:57\n",
      "2025-02-17 01:19:15\n",
      "2025-02-17 01:19:36\n",
      "2025-02-17 01:19:53\n",
      "2025-02-17 01:20:10\n",
      "2025-02-17 01:20:27\n",
      "2025-02-17 01:20:50\n",
      "2025-02-17 01:21:06\n",
      "2025-02-17 01:21:23\n",
      "2025-02-17 01:21:40\n",
      "2025-02-17 01:21:59\n",
      "2025-02-17 01:22:18\n",
      "2025-02-17 01:22:34\n",
      "2025-02-17 01:22:52\n",
      "2025-02-17 01:23:13\n",
      "2025-02-17 01:23:31\n",
      "2025-02-17 01:23:51\n",
      "2025-02-17 01:24:12\n",
      "2025-02-17 01:24:34\n",
      "2025-02-17 01:24:59\n",
      "2025-02-17 01:25:20\n",
      "2025-02-17 01:25:39\n",
      "2025-02-17 01:26:01\n",
      "2025-02-17 01:26:23\n",
      "2025-02-17 01:26:48\n",
      "2025-02-17 01:27:09\n",
      "2025-02-17 01:27:11\n",
      "2025-02-17 01:27:26\n",
      "2025-02-17 01:27:46\n",
      "2025-02-17 01:28:05\n",
      "2025-02-17 01:28:25\n",
      "2025-02-17 01:28:46\n",
      "2025-02-17 01:29:04\n",
      "2025-02-17 01:29:24\n",
      "2025-02-17 01:29:42\n",
      "2025-02-17 01:30:05\n",
      "2025-02-17 01:30:29\n",
      "2025-02-17 01:30:52\n",
      "2025-02-17 01:31:12\n",
      "2025-02-17 01:31:36\n",
      "2025-02-17 01:31:56\n",
      "2025-02-17 01:32:24\n",
      "2025-02-17 01:32:43\n",
      "2025-02-17 01:33:07\n",
      "2025-02-17 01:33:34\n",
      "2025-02-17 01:33:59\n",
      "2025-02-17 01:34:17\n",
      "2025-02-17 01:34:50\n",
      "2025-02-17 01:35:11\n",
      "2025-02-17 01:35:42\n",
      "2025-02-17 01:36:05\n",
      "2025-02-17 01:36:29\n",
      "2025-02-17 01:36:47\n",
      "2025-02-17 01:37:10\n",
      "2025-02-17 01:37:29\n",
      "2025-02-17 01:38:03\n",
      "2025-02-17 01:38:34\n",
      "2025-02-17 01:39:01\n",
      "2025-02-17 01:39:05\n",
      "2025-02-17 01:39:30\n",
      "2025-02-17 01:39:55\n",
      "2025-02-17 01:40:24\n",
      "2025-02-17 01:40:51\n",
      "2025-02-17 01:41:18\n",
      "2025-02-17 01:41:51\n",
      "2025-02-17 01:42:13\n",
      "2025-02-17 01:42:33\n",
      "2025-02-17 01:43:07\n",
      "2025-02-17 01:43:34\n",
      "2025-02-17 01:44:09\n",
      "2025-02-17 01:44:36\n",
      "2025-02-17 01:45:06\n",
      "2025-02-17 01:45:37\n",
      "2025-02-17 01:46:03\n",
      "2025-02-17 01:46:31\n",
      "2025-02-17 01:46:57\n",
      "2025-02-17 01:47:24\n",
      "2025-02-17 01:47:46\n",
      "2025-02-17 01:48:10\n",
      "2025-02-17 01:48:36\n",
      "2025-02-17 01:49:06\n",
      "2025-02-17 01:49:33\n",
      "2025-02-17 01:49:58\n",
      "2025-02-17 01:50:24\n",
      "2025-02-17 01:50:52\n",
      "2025-02-17 01:51:20\n",
      "2025-02-17 01:51:49\n",
      "2025-02-17 01:52:15\n",
      "2025-02-17 01:52:44\n",
      "2025-02-17 01:53:04\n",
      "2025-02-17 01:53:08\n",
      "2025-02-17 01:53:30\n",
      "2025-02-17 01:54:00\n",
      "2025-02-17 01:54:30\n",
      "2025-02-17 01:54:56\n",
      "2025-02-17 01:55:27\n",
      "2025-02-17 01:55:56\n",
      "2025-02-17 01:56:24\n",
      "2025-02-17 01:56:51\n",
      "2025-02-17 01:57:18\n",
      "2025-02-17 01:57:44\n",
      "2025-02-17 01:58:13\n",
      "2025-02-17 01:58:43\n",
      "2025-02-17 01:59:12\n",
      "2025-02-17 01:59:42\n",
      "2025-02-17 02:00:11\n",
      "2025-02-17 02:00:37\n",
      "2025-02-17 02:01:05\n",
      "2025-02-17 02:01:34\n",
      "2025-02-17 02:02:01\n",
      "2025-02-17 02:02:30\n",
      "2025-02-17 02:02:56\n",
      "2025-02-17 02:03:21\n",
      "2025-02-17 02:03:37\n",
      "2025-02-17 02:04:01\n",
      "2025-02-17 02:04:29\n",
      "2025-02-17 02:04:56\n",
      "2025-02-17 02:05:26\n",
      "2025-02-17 02:05:52\n",
      "2025-02-17 02:06:15\n",
      "2025-02-17 02:06:19\n",
      "2025-02-17 02:06:42\n",
      "2025-02-17 02:07:15\n",
      "2025-02-17 02:07:43\n",
      "2025-02-17 02:08:18\n",
      "2025-02-17 02:08:55\n",
      "2025-02-17 02:09:27\n",
      "2025-02-17 02:10:01\n",
      "2025-02-17 02:10:31\n",
      "2025-02-17 02:11:02\n",
      "2025-02-17 02:11:34\n",
      "2025-02-17 02:12:02\n",
      "2025-02-17 02:12:36\n",
      "2025-02-17 02:13:13\n",
      "2025-02-17 02:13:45\n",
      "2025-02-17 02:14:18\n",
      "2025-02-17 02:14:51\n",
      "2025-02-17 02:15:24\n",
      "2025-02-17 02:15:54\n",
      "2025-02-17 02:16:31\n",
      "2025-02-17 02:17:11\n",
      "2025-02-17 02:17:42\n",
      "2025-02-17 02:18:18\n",
      "2025-02-17 02:18:50\n",
      "2025-02-17 02:19:24\n",
      "2025-02-17 02:19:59\n",
      "2025-02-17 02:20:37\n",
      "2025-02-17 02:21:11\n",
      "2025-02-17 02:21:43\n",
      "2025-02-17 02:22:15\n",
      "2025-02-17 02:22:51\n",
      "2025-02-17 02:23:30\n",
      "2025-02-17 02:23:35\n",
      "2025-02-17 02:24:06\n",
      "2025-02-17 02:24:42\n",
      "2025-02-17 02:25:14\n",
      "2025-02-17 02:25:46\n",
      "2025-02-17 02:26:13\n",
      "2025-02-17 02:26:47\n",
      "2025-02-17 02:27:18\n",
      "2025-02-17 02:27:49\n",
      "2025-02-17 02:28:21\n",
      "2025-02-17 02:28:54\n",
      "2025-02-17 02:29:22\n",
      "2025-02-17 02:29:51\n",
      "2025-02-17 02:30:20\n",
      "2025-02-17 02:30:51\n",
      "2025-02-17 02:31:22\n",
      "2025-02-17 02:31:54\n",
      "2025-02-17 02:32:24\n",
      "2025-02-17 02:32:50\n",
      "2025-02-17 02:33:20\n",
      "2025-02-17 02:33:50\n",
      "2025-02-17 02:34:18\n",
      "2025-02-17 02:34:45\n",
      "2025-02-17 02:35:15\n",
      "2025-02-17 02:35:44\n",
      "2025-02-17 02:36:14\n",
      "2025-02-17 02:36:45\n",
      "2025-02-17 02:37:13\n",
      "2025-02-17 02:37:40\n",
      "2025-02-17 02:38:08\n",
      "2025-02-17 02:38:36\n",
      "2025-02-17 02:38:38\n",
      "2025-02-17 02:39:06\n",
      "2025-02-17 02:39:31\n",
      "2025-02-17 02:39:59\n",
      "2025-02-17 02:40:28\n",
      "2025-02-17 02:40:56\n",
      "2025-02-17 02:41:24\n",
      "2025-02-17 02:41:52\n",
      "2025-02-17 02:42:20\n",
      "2025-02-17 02:42:48\n",
      "2025-02-17 02:43:15\n",
      "2025-02-17 02:43:42\n",
      "2025-02-17 02:44:13\n",
      "2025-02-17 02:44:47\n",
      "2025-02-17 02:45:15\n",
      "2025-02-17 02:45:42\n",
      "2025-02-17 02:46:12\n",
      "2025-02-17 02:46:38\n",
      "2025-02-17 02:47:07\n",
      "2025-02-17 02:47:40\n",
      "2025-02-17 02:48:12\n",
      "2025-02-17 02:48:43\n",
      "2025-02-17 02:49:12\n",
      "2025-02-17 02:49:40\n",
      "2025-02-17 02:50:11\n",
      "2025-02-17 02:50:43\n",
      "2025-02-17 02:51:18\n",
      "2025-02-17 02:51:52\n",
      "2025-02-17 02:52:23\n",
      "2025-02-17 02:52:56\n",
      "2025-02-17 02:53:28\n",
      "2025-02-17 02:54:02\n",
      "2025-02-17 02:54:05\n",
      "2025-02-17 02:54:29\n",
      "2025-02-17 02:54:57\n",
      "2025-02-17 02:55:21\n",
      "2025-02-17 02:55:54\n",
      "2025-02-17 02:56:22\n",
      "2025-02-17 02:56:52\n",
      "2025-02-17 02:57:16\n",
      "2025-02-17 02:57:45\n",
      "2025-02-17 02:58:15\n",
      "2025-02-17 02:58:49\n",
      "2025-02-17 02:59:19\n",
      "2025-02-17 02:59:48\n",
      "2025-02-17 03:00:26\n",
      "2025-02-17 03:01:03\n",
      "2025-02-17 03:01:37\n",
      "2025-02-17 03:02:08\n",
      "2025-02-17 03:02:43\n",
      "2025-02-17 03:03:13\n",
      "2025-02-17 03:03:46\n",
      "2025-02-17 03:04:18\n",
      "2025-02-17 03:04:54\n",
      "2025-02-17 03:05:25\n",
      "2025-02-17 03:05:58\n",
      "2025-02-17 03:06:29\n",
      "2025-02-17 03:07:02\n",
      "2025-02-17 03:07:31\n",
      "2025-02-17 03:08:03\n",
      "2025-02-17 03:08:33\n",
      "2025-02-17 03:09:04\n",
      "2025-02-17 03:09:35\n",
      "2025-02-17 03:09:39\n",
      "2025-02-17 03:10:05\n",
      "2025-02-17 03:10:38\n",
      "2025-02-17 03:11:09\n",
      "2025-02-17 03:11:43\n",
      "2025-02-17 03:12:17\n",
      "2025-02-17 03:12:49\n",
      "2025-02-17 03:13:21\n",
      "2025-02-17 03:13:51\n",
      "2025-02-17 03:14:30\n",
      "2025-02-17 03:15:03\n",
      "2025-02-17 03:15:33\n",
      "2025-02-17 03:16:06\n",
      "2025-02-17 03:16:40\n",
      "2025-02-17 03:17:17\n",
      "2025-02-17 03:17:48\n",
      "2025-02-17 03:18:20\n",
      "2025-02-17 03:18:53\n",
      "2025-02-17 03:19:23\n",
      "2025-02-17 03:19:42\n",
      "2025-02-17 03:20:10\n",
      "2025-02-17 03:20:38\n",
      "2025-02-17 03:21:12\n",
      "2025-02-17 03:21:46\n",
      "2025-02-17 03:22:20\n",
      "2025-02-17 03:22:55\n",
      "2025-02-17 03:23:30\n",
      "2025-02-17 03:23:58\n",
      "2025-02-17 03:24:23\n",
      "2025-02-17 03:24:51\n",
      "2025-02-17 03:25:21\n",
      "2025-02-17 03:25:58\n",
      "2025-02-17 03:26:01\n",
      "2025-02-17 03:26:28\n",
      "2025-02-17 03:27:04\n",
      "2025-02-17 03:27:35\n",
      "2025-02-17 03:28:09\n",
      "2025-02-17 03:28:41\n",
      "2025-02-17 03:29:11\n",
      "2025-02-17 03:29:46\n",
      "2025-02-17 03:30:18\n",
      "2025-02-17 03:30:46\n",
      "2025-02-17 03:31:15\n",
      "2025-02-17 03:31:45\n",
      "2025-02-17 03:32:12\n",
      "2025-02-17 03:32:39\n",
      "2025-02-17 03:33:08\n",
      "2025-02-17 03:33:33\n",
      "2025-02-17 03:34:00\n",
      "2025-02-17 03:34:21\n",
      "2025-02-17 03:34:39\n",
      "2025-02-17 03:35:03\n",
      "2025-02-17 03:35:24\n",
      "2025-02-17 03:35:52\n",
      "2025-02-17 03:36:14\n",
      "2025-02-17 03:36:38\n",
      "2025-02-17 03:37:05\n",
      "2025-02-17 03:37:29\n",
      "2025-02-17 03:37:51\n",
      "2025-02-17 03:38:16\n",
      "2025-02-17 03:38:37\n",
      "2025-02-17 03:39:01\n",
      "2025-02-17 03:39:26\n",
      "2025-02-17 03:39:53\n",
      "2025-02-17 03:39:56\n",
      "2025-02-17 03:40:19\n",
      "2025-02-17 03:40:48\n",
      "2025-02-17 03:41:13\n",
      "2025-02-17 03:41:43\n",
      "2025-02-17 03:42:12\n",
      "2025-02-17 03:42:40\n",
      "2025-02-17 03:43:11\n",
      "2025-02-17 03:43:34\n",
      "2025-02-17 03:44:01\n",
      "2025-02-17 03:44:31\n",
      "2025-02-17 03:44:59\n",
      "2025-02-17 03:45:30\n",
      "2025-02-17 03:45:59\n",
      "2025-02-17 03:46:27\n",
      "2025-02-17 03:46:49\n",
      "2025-02-17 03:47:17\n",
      "2025-02-17 03:47:44\n",
      "2025-02-17 03:48:14\n",
      "2025-02-17 03:48:42\n",
      "2025-02-17 03:49:10\n",
      "2025-02-17 03:49:41\n",
      "2025-02-17 03:50:09\n",
      "2025-02-17 03:50:41\n",
      "2025-02-17 03:51:08\n",
      "2025-02-17 03:51:39\n",
      "2025-02-17 03:52:07\n",
      "2025-02-17 03:52:37\n",
      "2025-02-17 03:53:07\n",
      "2025-02-17 03:53:35\n",
      "2025-02-17 03:54:04\n",
      "2025-02-17 03:54:07\n",
      "2025-02-17 03:54:32\n",
      "2025-02-17 03:55:07\n",
      "2025-02-17 03:55:34\n",
      "2025-02-17 03:56:02\n",
      "2025-02-17 03:56:29\n",
      "2025-02-17 03:56:59\n",
      "2025-02-17 03:57:27\n",
      "2025-02-17 03:57:54\n",
      "2025-02-17 03:58:22\n",
      "2025-02-17 03:58:57\n",
      "2025-02-17 03:59:20\n",
      "2025-02-17 03:59:52\n",
      "2025-02-17 04:00:13\n",
      "2025-02-17 04:00:41\n",
      "2025-02-17 04:01:08\n",
      "2025-02-17 04:01:33\n",
      "2025-02-17 04:02:00\n",
      "2025-02-17 04:02:22\n",
      "2025-02-17 04:02:51\n",
      "2025-02-17 04:03:15\n",
      "2025-02-17 04:03:46\n",
      "2025-02-17 04:04:15\n",
      "2025-02-17 04:04:42\n",
      "2025-02-17 04:05:13\n",
      "2025-02-17 04:05:40\n",
      "2025-02-17 04:06:10\n",
      "2025-02-17 04:06:33\n",
      "2025-02-17 04:06:59\n",
      "2025-02-17 04:07:38\n",
      "2025-02-17 04:08:07\n",
      "2025-02-17 04:08:32\n",
      "2025-02-17 04:08:35\n",
      "2025-02-17 04:09:00\n",
      "2025-02-17 04:09:29\n",
      "2025-02-17 04:09:58\n",
      "2025-02-17 04:10:25\n",
      "2025-02-17 04:10:48\n",
      "2025-02-17 04:11:16\n",
      "2025-02-17 04:11:38\n",
      "2025-02-17 04:12:04\n",
      "2025-02-17 04:12:31\n",
      "2025-02-17 04:12:52\n",
      "2025-02-17 04:13:18\n",
      "2025-02-17 04:13:46\n",
      "2025-02-17 04:14:16\n",
      "2025-02-17 04:14:43\n",
      "2025-02-17 04:15:11\n",
      "2025-02-17 04:15:38\n",
      "2025-02-17 04:16:05\n",
      "2025-02-17 04:16:32\n",
      "2025-02-17 04:17:00\n",
      "2025-02-17 04:17:25\n",
      "2025-02-17 04:17:51\n",
      "2025-02-17 04:18:18\n",
      "2025-02-17 04:18:46\n",
      "2025-02-17 04:19:17\n",
      "2025-02-17 04:19:44\n",
      "2025-02-17 04:20:12\n",
      "2025-02-17 04:20:36\n",
      "2025-02-17 04:21:03\n",
      "2025-02-17 04:21:35\n",
      "2025-02-17 04:22:06\n",
      "2025-02-17 04:22:09\n",
      "2025-02-17 04:22:32\n",
      "2025-02-17 04:23:03\n",
      "2025-02-17 04:23:38\n",
      "2025-02-17 04:24:02\n",
      "2025-02-17 04:24:35\n",
      "2025-02-17 04:25:02\n",
      "2025-02-17 04:25:30\n",
      "2025-02-17 04:26:01\n",
      "2025-02-17 04:26:34\n",
      "2025-02-17 04:27:00\n",
      "2025-02-17 04:27:29\n",
      "2025-02-17 04:28:04\n",
      "2025-02-17 04:28:29\n",
      "2025-02-17 04:28:58\n",
      "2025-02-17 04:29:32\n",
      "2025-02-17 04:30:06\n",
      "2025-02-17 04:30:36\n",
      "2025-02-17 04:31:07\n",
      "2025-02-17 04:31:33\n",
      "2025-02-17 04:32:04\n",
      "2025-02-17 04:32:31\n",
      "2025-02-17 04:33:00\n",
      "2025-02-17 04:33:28\n",
      "2025-02-17 04:33:55\n",
      "2025-02-17 04:34:19\n",
      "2025-02-17 04:34:42\n",
      "2025-02-17 04:35:08\n",
      "2025-02-17 04:35:35\n",
      "2025-02-17 04:36:02\n",
      "2025-02-17 04:36:35\n",
      "2025-02-17 04:37:05\n",
      "2025-02-17 04:37:09\n",
      "2025-02-17 04:37:36\n",
      "2025-02-17 04:38:07\n",
      "2025-02-17 04:38:34\n",
      "2025-02-17 04:39:04\n",
      "2025-02-17 04:39:38\n",
      "2025-02-17 04:40:09\n",
      "2025-02-17 04:40:38\n",
      "2025-02-17 04:41:15\n",
      "2025-02-17 04:41:44\n",
      "2025-02-17 04:42:13\n",
      "2025-02-17 04:42:41\n",
      "2025-02-17 04:43:04\n",
      "2025-02-17 04:43:31\n",
      "2025-02-17 04:43:58\n",
      "2025-02-17 04:44:28\n",
      "2025-02-17 04:45:00\n",
      "2025-02-17 04:45:28\n",
      "2025-02-17 04:46:04\n",
      "2025-02-17 04:46:31\n",
      "2025-02-17 04:46:53\n",
      "2025-02-17 04:47:19\n",
      "2025-02-17 04:47:40\n",
      "2025-02-17 04:48:04\n",
      "2025-02-17 04:48:33\n",
      "2025-02-17 04:48:58\n",
      "2025-02-17 04:49:24\n",
      "2025-02-17 04:49:51\n",
      "2025-02-17 04:50:18\n",
      "2025-02-17 04:50:50\n",
      "2025-02-17 04:51:17\n",
      "2025-02-17 04:51:49\n",
      "2025-02-17 04:51:53\n",
      "2025-02-17 04:52:19\n",
      "2025-02-17 04:52:49\n",
      "2025-02-17 04:53:19\n",
      "2025-02-17 04:53:45\n",
      "2025-02-17 04:54:11\n",
      "2025-02-17 04:54:40\n",
      "2025-02-17 04:55:06\n",
      "2025-02-17 04:55:34\n",
      "2025-02-17 04:55:59\n",
      "2025-02-17 04:56:27\n",
      "2025-02-17 04:56:51\n",
      "2025-02-17 04:57:21\n",
      "2025-02-17 04:57:47\n",
      "2025-02-17 04:58:14\n",
      "2025-02-17 04:58:43\n",
      "2025-02-17 04:59:12\n",
      "2025-02-17 04:59:38\n",
      "2025-02-17 05:00:11\n",
      "2025-02-17 05:00:39\n",
      "2025-02-17 05:01:05\n",
      "2025-02-17 05:01:35\n",
      "2025-02-17 05:02:07\n",
      "2025-02-17 05:02:36\n",
      "2025-02-17 05:02:56\n",
      "2025-02-17 05:03:19\n",
      "2025-02-17 05:03:43\n",
      "2025-02-17 05:04:16\n",
      "2025-02-17 05:04:47\n",
      "2025-02-17 05:04:49\n",
      "2025-02-17 05:05:07\n",
      "2025-02-17 05:05:30\n",
      "2025-02-17 05:05:53\n",
      "2025-02-17 05:06:19\n",
      "2025-02-17 05:06:44\n",
      "2025-02-17 05:07:14\n",
      "2025-02-17 05:07:44\n",
      "2025-02-17 05:08:11\n",
      "2025-02-17 05:08:39\n",
      "2025-02-17 05:09:08\n",
      "2025-02-17 05:09:37\n",
      "2025-02-17 05:10:07\n",
      "2025-02-17 05:10:36\n",
      "2025-02-17 05:11:05\n",
      "2025-02-17 05:11:35\n",
      "2025-02-17 05:12:06\n",
      "2025-02-17 05:12:33\n",
      "2025-02-17 05:13:02\n",
      "2025-02-17 05:13:30\n",
      "2025-02-17 05:14:03\n",
      "2025-02-17 05:14:31\n",
      "2025-02-17 05:14:58\n",
      "2025-02-17 05:15:33\n",
      "2025-02-17 05:15:59\n",
      "2025-02-17 05:16:36\n",
      "2025-02-17 05:17:13\n",
      "2025-02-17 05:17:45\n",
      "2025-02-17 05:18:17\n",
      "2025-02-17 05:18:46\n",
      "2025-02-17 05:19:17\n",
      "2025-02-17 05:19:47\n",
      "2025-02-17 05:19:50\n",
      "2025-02-17 05:20:12\n",
      "2025-02-17 05:20:35\n",
      "2025-02-17 05:20:57\n",
      "2025-02-17 05:21:23\n",
      "2025-02-17 05:21:46\n",
      "2025-02-17 05:22:14\n",
      "2025-02-17 05:22:45\n",
      "2025-02-17 05:23:19\n",
      "2025-02-17 05:23:48\n",
      "2025-02-17 05:24:15\n",
      "2025-02-17 05:24:44\n",
      "2025-02-17 05:25:14\n",
      "2025-02-17 05:25:40\n",
      "2025-02-17 05:26:07\n",
      "2025-02-17 05:26:30\n",
      "2025-02-17 05:26:50\n",
      "2025-02-17 05:27:16\n",
      "2025-02-17 05:27:45\n",
      "2025-02-17 05:28:15\n",
      "2025-02-17 05:28:40\n",
      "2025-02-17 05:29:09\n",
      "2025-02-17 05:29:40\n",
      "2025-02-17 05:30:10\n",
      "2025-02-17 05:30:39\n",
      "2025-02-17 05:31:08\n",
      "2025-02-17 05:31:40\n",
      "2025-02-17 05:32:14\n",
      "2025-02-17 05:32:43\n",
      "2025-02-17 05:33:14\n",
      "2025-02-17 05:33:40\n",
      "2025-02-17 05:33:44\n",
      "2025-02-17 05:34:12\n",
      "2025-02-17 05:34:37\n",
      "2025-02-17 05:35:03\n",
      "2025-02-17 05:35:23\n",
      "2025-02-17 05:35:48\n",
      "2025-02-17 05:36:14\n",
      "2025-02-17 05:36:44\n",
      "2025-02-17 05:37:15\n",
      "2025-02-17 05:37:54\n",
      "2025-02-17 05:38:26\n",
      "2025-02-17 05:38:58\n",
      "2025-02-17 05:39:25\n",
      "2025-02-17 05:39:59\n",
      "2025-02-17 05:40:31\n",
      "2025-02-17 05:41:06\n",
      "2025-02-17 05:41:38\n",
      "2025-02-17 05:42:06\n",
      "2025-02-17 05:42:36\n",
      "2025-02-17 05:43:07\n",
      "2025-02-17 05:43:39\n",
      "2025-02-17 05:44:04\n",
      "2025-02-17 05:44:39\n",
      "2025-02-17 05:45:05\n",
      "2025-02-17 05:45:37\n",
      "2025-02-17 05:46:07\n",
      "2025-02-17 05:46:39\n",
      "2025-02-17 05:47:07\n",
      "2025-02-17 05:47:34\n",
      "2025-02-17 05:48:01\n",
      "2025-02-17 05:48:33\n",
      "2025-02-17 05:49:03\n",
      "2025-02-17 05:49:05\n",
      "2025-02-17 05:49:34\n",
      "2025-02-17 05:50:03\n",
      "2025-02-17 05:50:30\n",
      "2025-02-17 05:51:07\n",
      "2025-02-17 05:51:44\n",
      "2025-02-17 05:52:16\n",
      "2025-02-17 05:52:46\n",
      "2025-02-17 05:53:18\n",
      "2025-02-17 05:53:48\n",
      "2025-02-17 05:54:16\n",
      "2025-02-17 05:54:44\n",
      "2025-02-17 05:55:15\n",
      "2025-02-17 05:55:37\n",
      "2025-02-17 05:56:07\n",
      "2025-02-17 05:56:34\n",
      "2025-02-17 05:56:58\n",
      "2025-02-17 05:57:26\n",
      "2025-02-17 05:58:03\n",
      "2025-02-17 05:58:40\n",
      "2025-02-17 05:59:10\n",
      "2025-02-17 05:59:37\n",
      "2025-02-17 06:00:00\n",
      "2025-02-17 06:00:31\n",
      "2025-02-17 06:00:59\n",
      "2025-02-17 06:01:33\n",
      "2025-02-17 06:01:59\n",
      "2025-02-17 06:02:23\n",
      "2025-02-17 06:02:45\n",
      "2025-02-17 06:03:10\n",
      "2025-02-17 06:03:41\n",
      "2025-02-17 06:03:44\n",
      "2025-02-17 06:04:11\n",
      "2025-02-17 06:04:38\n",
      "2025-02-17 06:05:11\n",
      "2025-02-17 06:05:40\n",
      "2025-02-17 06:06:08\n",
      "2025-02-17 06:06:36\n",
      "2025-02-17 06:07:03\n",
      "2025-02-17 06:07:34\n",
      "2025-02-17 06:08:04\n",
      "2025-02-17 06:08:35\n",
      "2025-02-17 06:09:02\n",
      "2025-02-17 06:09:31\n",
      "2025-02-17 06:10:01\n",
      "2025-02-17 06:10:31\n",
      "2025-02-17 06:11:01\n",
      "2025-02-17 06:11:52\n",
      "2025-02-17 06:12:24\n",
      "2025-02-17 06:12:58\n",
      "2025-02-17 06:13:30\n",
      "2025-02-17 06:14:00\n",
      "2025-02-17 06:14:28\n",
      "2025-02-17 06:14:57\n",
      "2025-02-17 06:15:18\n",
      "2025-02-17 06:15:43\n",
      "2025-02-17 06:16:09\n",
      "2025-02-17 06:16:34\n",
      "2025-02-17 06:17:08\n",
      "2025-02-17 06:17:35\n",
      "2025-02-17 06:18:00\n",
      "2025-02-17 06:18:32\n",
      "2025-02-17 06:18:58\n",
      "2025-02-17 06:19:01\n",
      "2025-02-17 06:19:25\n",
      "2025-02-17 06:19:57\n",
      "2025-02-17 06:20:26\n",
      "2025-02-17 06:20:56\n",
      "2025-02-17 06:21:25\n",
      "2025-02-17 06:21:52\n",
      "2025-02-17 06:22:19\n",
      "2025-02-17 06:22:44\n",
      "2025-02-17 06:23:14\n",
      "2025-02-17 06:23:42\n",
      "2025-02-17 06:24:12\n",
      "2025-02-17 06:24:40\n",
      "2025-02-17 06:25:10\n",
      "2025-02-17 06:25:37\n",
      "2025-02-17 06:26:09\n",
      "2025-02-17 06:26:37\n",
      "2025-02-17 06:27:05\n",
      "2025-02-17 06:27:34\n",
      "2025-02-17 06:28:01\n",
      "2025-02-17 06:28:30\n",
      "2025-02-17 06:29:00\n",
      "2025-02-17 06:29:28\n",
      "2025-02-17 06:30:00\n",
      "2025-02-17 06:30:24\n",
      "2025-02-17 06:30:48\n",
      "2025-02-17 06:31:10\n",
      "2025-02-17 06:31:35\n",
      "2025-02-17 06:32:03\n",
      "2025-02-17 06:32:27\n",
      "2025-02-17 06:33:00\n",
      "2025-02-17 06:33:30\n",
      "2025-02-17 06:33:33\n",
      "2025-02-17 06:33:53\n",
      "2025-02-17 06:34:18\n",
      "2025-02-17 06:34:41\n",
      "2025-02-17 06:35:06\n",
      "2025-02-17 06:35:35\n",
      "2025-02-17 06:36:01\n",
      "2025-02-17 06:36:30\n",
      "2025-02-17 06:37:06\n",
      "2025-02-17 06:37:35\n",
      "2025-02-17 06:38:00\n",
      "2025-02-17 06:38:32\n",
      "2025-02-17 06:38:59\n",
      "2025-02-17 06:39:17\n",
      "2025-02-17 06:39:42\n",
      "2025-02-17 06:40:01\n",
      "2025-02-17 06:40:24\n",
      "2025-02-17 06:40:48\n",
      "2025-02-17 06:41:07\n",
      "2025-02-17 06:41:28\n",
      "2025-02-17 06:41:49\n",
      "2025-02-17 06:42:12\n",
      "2025-02-17 06:42:33\n",
      "2025-02-17 06:42:58\n",
      "2025-02-17 06:43:22\n",
      "2025-02-17 06:43:47\n",
      "2025-02-17 06:44:09\n",
      "2025-02-17 06:44:30\n",
      "2025-02-17 06:44:52\n",
      "2025-02-17 06:45:13\n",
      "2025-02-17 06:45:34\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file('/N/project/Zli_lab/Data/Other/tl_2019_us_state/tl_2019_us_state.shp')\n",
    "input_folder = '/N/project/Zli_lab/Data/Observations/NCAR/prec_acc_files/'\n",
    "\n",
    "start_year = 1987\n",
    "end_year = start_year+3\n",
    "for year in range(start_year, end_year):  # 1989不包含\n",
    "\n",
    "    months = range(10, 13) if year == start_year else range(1, 10) if year == (end_year - 1) else range(1, 13)\n",
    "    # 遍历月份\n",
    "    for month in months:\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "        # 获取当前月份的天数\n",
    "        if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "            num_days = 31\n",
    "        elif month in [4, 6, 9, 11]:\n",
    "            num_days = 30\n",
    "        elif month == 2:\n",
    "            # 考虑闰年\n",
    "            if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0):\n",
    "                num_days = 29  # 闰年\n",
    "            else:\n",
    "                num_days = 28  # 平年\n",
    "\n",
    "        # 遍历每个月的天数\n",
    "        for day in range(1, num_days + 1):\n",
    "            \n",
    "            month_str = f\"{month:02}\"\n",
    "            day_str = f\"{day:02}\"\n",
    "            input_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}_*.nc'\n",
    "            ds = xr.open_mfdataset(input_folder + input_file)\n",
    "            ds_era = xr.Dataset({'p': (['time', 'latitude', 'longitude'], ds.PREC_ACC_NC.values)},\n",
    "                                coords={'longitude': (['longitude'], ds.XLONG.values[500]),\n",
    "                                        'latitude': (['latitude'], ds.XLAT.values[:,500]),\n",
    "                                        'time': ('time', ds.Time.values)})\n",
    "            ds_era_lon, ds_era_lat = np.meshgrid(ds_era.longitude.values, ds_era.latitude.values, indexing='xy')\n",
    "            # 转换为 xarray DataArray，确保其维度与 ds_era_clipped 对齐\n",
    "            ds_era_lon_da = xr.DataArray(ds_era_lon, dims=(\"latitude\", \"longitude\"), coords={\"latitude\": ds_era.latitude, \"longitude\": ds_era.longitude})\n",
    "            ds_era_lat_da = xr.DataArray(ds_era_lat, dims=(\"latitude\", \"longitude\"), coords={\"latitude\": ds_era.latitude, \"longitude\": ds_era.longitude})\n",
    "\n",
    "            # 使用 assign_coords 将二维坐标添加到 ds_era_clipped\n",
    "            ds_era_clipped = ds_era.assign_coords(lon_2d=ds_era_lon_da, lat_2d=ds_era_lat_da)\n",
    "\n",
    "            lon = ds_era_clipped['lon_2d'].values\n",
    "            lat = ds_era_clipped['lat_2d'].values\n",
    "            grid = gpd.GeoDataFrame(\n",
    "                geometry=gpd.points_from_xy(lon.flatten(), lat.flatten()),\n",
    "                index=np.arange(lon.size)\n",
    "            )\n",
    "            grid.set_crs(gdf.crs, inplace=True)\n",
    "            grid_s = gpd.sjoin(grid, gdf, how='inner', predicate='within')\n",
    "\n",
    "            mask = np.full(ds_era_clipped['p'].shape[1:], False) \n",
    "            for index in grid_s.index:\n",
    "                row, col = np.unravel_index(index, mask.shape)  # 获取行列索引\n",
    "                mask[row, col] = True\n",
    "            mask_da = xr.DataArray(mask, dims=ds_era_clipped['p'].dims[1:], coords={'latitude': ds_era_clipped['p'].coords['latitude'], 'longitude': ds_era_clipped['p'].coords['longitude']})\n",
    "            ds_sss = ds_era_clipped.where(mask_da, drop=True)\n",
    "            ds_sss = ds_sss.drop_vars(['lon_2d', 'lat_2d'])\n",
    "\n",
    "\n",
    "            original_times = ds_sss.time.values \n",
    "            \n",
    "            lon_ranges = [(-np.inf, -112.5), (-112.5, -97.5), (-97.5, -82.5), (-82.5, np.inf)]\n",
    "            utc_offsets = [-8, -7, -6, -5]\n",
    "            print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "            for (lon_min, lon_max), offset in zip(lon_ranges, utc_offsets):\n",
    "                mask = (ds_sss.longitude >= lon_min) & (ds_sss.longitude < lon_max)\n",
    "                ds_lon_subset = ds_sss.where(mask, drop=True)\n",
    "                if ds_lon_subset.latitude.size > 0 and ds_lon_subset.longitude.size > 0:\n",
    "            \n",
    "                    adjusted_times = original_times + np.timedelta64(offset, 'h')  # 保持24个时间点\n",
    "            \n",
    "                    ds_lon_subset = ds_lon_subset.assign_coords(time=adjusted_times)\n",
    "            \n",
    "                    lat_min = ds_lon_subset.latitude.min().values\n",
    "                    lat_max = ds_lon_subset.latitude.max().values\n",
    "            \n",
    "                    lat_splits = np.linspace(lat_min, lat_max, 10)  # 10个值分9段\n",
    "                    \n",
    "                    for i in range(len(lat_splits) - 1):\n",
    "                        lat_min_split = lat_splits[i]\n",
    "                        lat_max_split = lat_splits[i + 1]\n",
    "                        lat_mask = (ds_lon_subset.latitude >= lat_min_split) & (ds_lon_subset.latitude < lat_max_split)\n",
    "                        ds_lat_subset = ds_lon_subset.where(lat_mask, drop=True)\n",
    "                        \n",
    "                        output_folder = '/N/project/Zli_lab/gongg/CONUS404_data/LST/re_UTC/U' + str(offset)+str(i) + '/'\n",
    "                        output_file = f'PREC_ACC_NC.wrf2d_d01_{year}-{month_str}-{day_str}.nc'\n",
    "                        output_path = os.path.join(output_folder, output_file)\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        ds_lat_subset.to_netcdf(output_folder + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72f155-dcd3-4a85-a6f7-6c2a2d041d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
