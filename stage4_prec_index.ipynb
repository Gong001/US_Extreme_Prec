{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ff4da3-d590-428f-b71f-9933069c4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "### lvl 2 setups (systerm)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pylab import *\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Wedge, Circle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0649dc18-5b61-4597-8dfc-bd2be9318431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RxHhr(prec, latt, lonn, n):\n",
    "\n",
    "    arr = prec.reshape(23, 2208, prec.shape[1], prec.shape[2])\n",
    "    max_prec = np.full((23, prec.shape[1], prec.shape[2]), np.nan)\n",
    "\n",
    "    for year in range(23):\n",
    "        for i in range(prec.shape[1]):\n",
    "            for j in range(prec.shape[2]):\n",
    "                sliding_windows = np.lib.stride_tricks.sliding_window_view(arr[year, :, i, j], n)\n",
    "                window_sums = np.sum(sliding_windows, axis=1)\n",
    "                local_max = np.max(window_sums)\n",
    "                if local_max > 1:\n",
    "                    max_prec[year, i, j] = local_max\n",
    "\n",
    "\n",
    "    ds_RxHhr = xr.Dataset(\n",
    "        {'p': (['time', 'lat', 'lon'], max_prec)},\n",
    "        coords={\n",
    "            'time': (['time'], np.arange(2002, 2025)),  \n",
    "            'lat': (['lat', 'lon'], latt),   \n",
    "            'lon': (['lat', 'lon'], lonn)        \n",
    "        }\n",
    "    )\n",
    "    return ds_RxHhr\n",
    "\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def Rx1hrP(prec, latt, lonn):\n",
    "    # Reshape the precipitation data to a 5-dimensional array (years, days, hours, lat, lon)\n",
    "    arr = prec.reshape(23, 92, 24, prec.shape[1], prec.shape[2])\n",
    "    \n",
    "    # Initialize the output array for storing percentages\n",
    "    arr_percent = np.full((23, 92, prec.shape[1], prec.shape[2]), np.nan)\n",
    "    \n",
    "    # Loop over years, days, and spatial dimensions\n",
    "    for year in range(23):\n",
    "        for day in range(92):\n",
    "            for i in range(prec.shape[1]):  # Latitude\n",
    "                for j in range(prec.shape[2]):  # Longitude\n",
    "                    # Calculate the daily total precipitation using nansum to ignore NaNs\n",
    "                    daily_total = np.sum(arr[year, day, :, i, j])\n",
    "                    \n",
    "                    # Calculate the maximum hourly precipitation using nanmax to ignore NaNs\n",
    "                    daily_max = np.max(arr[year, day, :, i, j])\n",
    "                    \n",
    "                    # Calculate the percentage if daily total is not zero\n",
    "                    if daily_total > 0:\n",
    "                        arr_percent[year, day, i, j] = (daily_max / daily_total) \n",
    "                    if daily_total == 0:\n",
    "                        arr_percent[year, day, i, j] = 0\n",
    "    # Create an xarray dataset with the arr_percent data and appropriate coordinates\n",
    "    ds_Rx1hrP = xr.Dataset(\n",
    "        {'percent': (['year', 'day', 'lat', 'lon'], arr_percent)},\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(2002, 2025)),\n",
    "            'day': (['day'], np.arange(0, 92)),  # Assuming days are indexed from 1 to 92\n",
    "            'lat': (['lat', 'lon'], latt),   \n",
    "            'lon': (['lat', 'lon'], lonn)    \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return ds_Rx1hrP\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def RQpwHhrP(prec, latt, lonn):\n",
    "    # Reshape the precipitation data\n",
    "    arr = prec.reshape(23, 2208, prec.shape[1], prec.shape[2])\n",
    "\n",
    "    # Calculate the mask based on NaN presence in the original data\n",
    "    mask = np.isnan(np.nanmean(prec, axis=0))\n",
    "\n",
    "    # Initialize output arrays\n",
    "    percent_95 = np.full((23, prec.shape[1], prec.shape[2]), np.nan)\n",
    "    percent_99 = np.full((23, prec.shape[1], prec.shape[2]), np.nan)\n",
    "    quantile_95 = np.full((prec.shape[1], prec.shape[2]), np.nan)\n",
    "    quantile_99 = np.full((prec.shape[1], prec.shape[2]), np.nan)\n",
    "\n",
    "    # Processing data\n",
    "    for year in range(23):\n",
    "        for i in range(prec.shape[1]):\n",
    "            for j in range(prec.shape[2]):\n",
    "                # Extract yearly precipitation data\n",
    "                yearly_precip = arr[year, :, i, j]\n",
    "\n",
    "                # Filter wet hours\n",
    "                wet_hours = yearly_precip[yearly_precip >= 0.1]\n",
    "\n",
    "                # Calculate 95% and 99% quantiles\n",
    "                q95 = np.percentile(wet_hours, 95) if len(wet_hours) > 0 else np.nan\n",
    "                q99 = np.percentile(wet_hours, 99) if len(wet_hours) > 0 else np.nan\n",
    "                \n",
    "                quantile_95[i, j] = q95\n",
    "                quantile_99[i, j] = q99\n",
    "                \n",
    "                # Total precipitation for wet hours\n",
    "                total_wet_precip = np.sum(wet_hours)\n",
    "\n",
    "                # Total exceeding 95% and 99% quantiles\n",
    "                sum_over_q95 = np.sum(yearly_precip[yearly_precip >= q95])\n",
    "                sum_over_q99 = np.sum(yearly_precip[yearly_precip >= q99])\n",
    "\n",
    "                # Calculate percentages\n",
    "                if total_wet_precip >= 0.1:\n",
    "                    percent_95[year, i, j] = (sum_over_q95 / total_wet_precip)\n",
    "                    percent_99[year, i, j] = (sum_over_q99 / total_wet_precip)\n",
    "                else:\n",
    "                    percent_95[year, i, j] = 0\n",
    "                    percent_99[year, i, j] = 0\n",
    "\n",
    "    # Apply mask\n",
    "    percent_95[:, mask] = np.nan\n",
    "    percent_99[:, mask] = np.nan\n",
    "\n",
    "    # Create xarray datasets\n",
    "    ds_percent = xr.Dataset(\n",
    "        {\n",
    "            'percent_95': (['year', 'lat', 'lon'], percent_95),\n",
    "            'percent_99': (['year', 'lat', 'lon'], percent_99)\n",
    "        },\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(2002, 2025)),\n",
    "            'lat': (['lat', 'lon'], latt),   \n",
    "            'lon': (['lat', 'lon'], lonn)    \n",
    "        }\n",
    "    )\n",
    "    ds_quantile = xr.Dataset(\n",
    "        {\n",
    "            'q_95': (['lat', 'lon'], quantile_95),\n",
    "            'q_99': (['lat', 'lon'], quantile_99)\n",
    "        },\n",
    "        coords={\n",
    "            'lat': (['lat', 'lon'], latt),   \n",
    "            'lon': (['lat', 'lon'], lonn)    \n",
    "        }\n",
    "    )\n",
    "\n",
    "    return ds_percent, ds_quantile\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def RHhrTmm(prec, latt, lonn, H):\n",
    "\n",
    "    years = 23  # Assuming each year has 2208 hours\n",
    "    # Reshape precipitation data to (years, hours, lat, lon)\n",
    "    arr = prec.reshape(years, 2208, prec.shape[1], prec.shape[2])\n",
    "\n",
    "    # Calculate the mask for NaN values in the original data\n",
    "    mask = np.isnan(np.nanmean(prec, axis=0))\n",
    "\n",
    "    # Initialize the result array\n",
    "    arr_RHhrTmm_10 = np.zeros((years, prec.shape[1], prec.shape[2]), dtype=float)\n",
    "    arr_RHhrTmm_20 = np.zeros((years, prec.shape[1], prec.shape[2]), dtype=float)\n",
    "    arr_RHhrTmm_30 = np.zeros((years, prec.shape[1], prec.shape[2]), dtype=float)\n",
    "    arr_RHhrTmm_50 = np.zeros((years, prec.shape[1], prec.shape[2]), dtype=float)\n",
    "    # Process each year\n",
    "    for year in range(years):\n",
    "        for hour in range(0, 2208, H):\n",
    "            # Calculate summed precipitation over the interval\n",
    "            if hour + H <= 2208:\n",
    "                summed_precip = np.nansum(arr[year, hour:hour + H, :, :], axis=0)\n",
    "            else:\n",
    "                summed_precip = np.nansum(arr[year, hour:2208, :, :], axis=0)\n",
    "\n",
    "            # Check for exceedances over the threshold\n",
    "            exceedances_10 = summed_precip >= 10\n",
    "            exceedances_20 = summed_precip >= 20\n",
    "            exceedances_30 = summed_precip >= 30\n",
    "            exceedances_50 = summed_precip >= 50\n",
    "            arr_RHhrTmm_10[year, :, :] += exceedances_10.astype(int)\n",
    "            arr_RHhrTmm_20[year, :, :] += exceedances_20.astype(int)\n",
    "            arr_RHhrTmm_30[year, :, :] += exceedances_30.astype(int)\n",
    "            arr_RHhrTmm_50[year, :, :] += exceedances_50.astype(int)\n",
    "            \n",
    "            \n",
    "    # Apply the mask to the result array\n",
    "    arr_RHhrTmm_10[:, mask] = np.nan\n",
    "    arr_RHhrTmm_20[:, mask] = np.nan\n",
    "    arr_RHhrTmm_30[:, mask] = np.nan\n",
    "    arr_RHhrTmm_50[:, mask] = np.nan\n",
    "    # Create an xarray dataset to store the results\n",
    "    ds_RHhrTmm = xr.Dataset(\n",
    "        {\n",
    "            'c_10': (['year', 'lat', 'lon'], arr_RHhrTmm_10),\n",
    "            'c_20': (['year', 'lat', 'lon'], arr_RHhrTmm_20),\n",
    "            'c_30': (['year', 'lat', 'lon'], arr_RHhrTmm_30),\n",
    "            'c_50': (['year', 'lat', 'lon'], arr_RHhrTmm_50),\n",
    "        },\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(2002, 2002 + years)),\n",
    "            'lat': (['lat', 'lon'], latt),   \n",
    "            'lon': (['lat', 'lon'], lonn)    \n",
    "        }\n",
    "    )\n",
    "\n",
    "    return ds_RHhrTmm\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def NWH(prec, latt, lonn):\n",
    "    arr = prec.reshape(23, 2208, prec.shape[1], prec.shape[2])\n",
    "    mask = np.isnan(np.nanmean(prec, axis=0))\n",
    "\n",
    "    nwh = np.zeros((23, prec.shape[1], prec.shape[2]))\n",
    "\n",
    "    for year in range(23):\n",
    "        for i in range(prec.shape[1]):\n",
    "            for j in range(prec.shape[2]):\n",
    "                hourly_data = arr[year, :, i, j]\n",
    "                wet_hours = hourly_data >= 0.1\n",
    "                nwh[year, i, j] = np.sum(wet_hours)\n",
    "\n",
    "    nwh[:, mask] = np.nan\n",
    "    ds_NWH = xr.Dataset(\n",
    "        {'c': (['year', 'lat', 'lon'], nwh)},\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(2002, 2025)),\n",
    "            'lat': (['lat', 'lon'], latt),   \n",
    "            'lon': (['lat', 'lon'], lonn)    \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return ds_NWH\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def MeLWS_MxLWS(prec,latt,lonn):\n",
    "\n",
    "    arr = prec.reshape(23, 2208, prec.shape[1], prec.shape[2])\n",
    "    mask = np.isnan(np.nanmean(prec, axis=0))\n",
    "    MeLWS = np.full((23, prec.shape[1], prec.shape[2]), np.nan)\n",
    "    MxLWS = np.full((23, prec.shape[1], prec.shape[2]), np.nan)\n",
    "\n",
    "    for year in range(23):\n",
    "        for i in range(prec.shape[1]):\n",
    "            for j in range(prec.shape[2]):\n",
    "                yearly_precip = arr[year, :, i, j]\n",
    "                is_wet = yearly_precip >= 0.1\n",
    "                wet_starts = np.where(np.diff(is_wet.astype(int)) == 1)[0] + 1\n",
    "                wet_ends = np.where(np.diff(is_wet.astype(int)) == -1)[0] + 1\n",
    "\n",
    "                if is_wet[0]:\n",
    "                    wet_starts = np.insert(wet_starts, 0, 0)\n",
    "                if is_wet[-1]:\n",
    "                    wet_ends = np.append(wet_ends, is_wet.size)\n",
    "\n",
    "                if wet_starts.size > 0:  \n",
    "                    wet_lengths = wet_ends - wet_starts\n",
    "                    MeLWS[year, i, j] = np.mean(wet_lengths)\n",
    "                    MxLWS[year, i, j] = np.max(wet_lengths)\n",
    "                else:\n",
    "                    MeLWS[year, i, j] = 0\n",
    "                    MxLWS[year, i, j] = 0\n",
    "\n",
    "\n",
    "    MeLWS[:, mask] = np.nan\n",
    "    MxLWS[:, mask] = np.nan\n",
    "\n",
    "    ds_MeLWS_MxLWS = xr.Dataset(\n",
    "        {\n",
    "            'MeLWS': (['year', 'lat', 'lon'], MeLWS),\n",
    "            'MxLWS': (['year', 'lat', 'lon'], MxLWS)\n",
    "        },\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(2002, 2025)),\n",
    "            'lat': (['lat', 'lon'], latt),   \n",
    "            'lon': (['lat', 'lon'], lonn)    \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return ds_MeLWS_MxLWS\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def SPIIHhr(prec, latt, lonn, H):\n",
    "    arr = prec.reshape(23,2208, prec.shape[1], prec.shape[2])\n",
    "    spi_ihhr = np.full((23, prec.shape[1], prec.shape[2]), np.nan)\n",
    "\n",
    "    for year in range(23):\n",
    "        for i in range(prec.shape[1]):\n",
    "            for j in range(prec.shape[2]):\n",
    "                total_precip = []\n",
    "\n",
    "                for hour in range(0, 2208, H):\n",
    "                    if hour + H <= 2208:\n",
    "                        precip_sum = np.sum(arr[year, hour:hour + H, i, j])\n",
    "                    else:\n",
    "                        precip_sum = np.sum(arr[year, hour:, i, j])\n",
    "\n",
    "                    if precip_sum >= 0.1:\n",
    "                        total_precip.append(precip_sum)\n",
    "\n",
    "                if total_precip:\n",
    "                    spi_ihhr[year, i, j] = np.mean(total_precip)\n",
    "\n",
    "    ds_SPIIHhr = xr.Dataset(\n",
    "        {'p': (['year', 'lat', 'lon'], spi_ihhr)},\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(2002, 2025)),\n",
    "            'lat': (['lat', 'lon'], latt),   \n",
    "            'lon': (['lat', 'lon'], lonn)    \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return ds_SPIIHhr\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def RTot(prec,latt,lonn):\n",
    "    arr = prec.reshape(23, 2208, prec.shape[1], prec.shape[2])\n",
    "    mask = np.isnan(np.nanmean(prec, axis=0))\n",
    "    new_arr = np.where(arr > 0.1, arr, np.nan)\n",
    "    RTot = np.nansum(new_arr,axis=1)\n",
    "    RTot[:, mask] = np.nan\n",
    "    ds_RTot = xr.Dataset(\n",
    "        {'p': (['year', 'lat', 'lon'], RTot)},\n",
    "        coords={\n",
    "            'year': (['year'], np.arange(2002, 2025)),\n",
    "            'lat': (['lat', 'lon'], latt),   \n",
    "            'lon': (['lat', 'lon'], lonn)    \n",
    "        }\n",
    "    )\n",
    "    return ds_RTot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e730a0a-5cd9-4954-92dd-35c63b46c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-22 21:06:25.484652\n"
     ]
    }
   ],
   "source": [
    "base_path = '/N/project/Zli_lab/gongg/stage4_data/stage4_area'\n",
    "output_folder = '/N/project/Zli_lab/gongg/stage4_data/prec_index/'\n",
    "file_pattern = '????????.nc'\n",
    "folder_names = [\n",
    "    'sub01',\n",
    "]\n",
    "\n",
    "for folder in folder_names:\n",
    "    print(datetime.datetime.now())\n",
    "    full_path = os.path.join(base_path, folder, file_pattern)\n",
    "    all_files = glob.glob(full_path)\n",
    "    ds = xr.open_mfdataset(all_files)\n",
    "    lonn = ds.lon.values[:,:,0]\n",
    "    latt = ds.lat.values[:,:,0]\n",
    "    prec = ds.tp.values\n",
    "\n",
    "    \n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_RxHhr_1 = RxHhr(prec, latt, lonn, 1)\n",
    "    ds_RxHhr_3 = RxHhr(prec, latt, lonn, 3)\n",
    "    ds_RxHhr_6 = RxHhr(prec, latt, lonn, 6)\n",
    "    ds_RxHhr_12 = RxHhr(prec, latt, lonn, 12)\n",
    "    ds_RxHhr_24 = RxHhr(prec, latt, lonn, 24)\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_Rx1hrP = Rx1hrP(prec, latt, lonn)\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_percent, ds_quantile = RQpwHhrP(prec, latt, lonn)\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_RHhrTmm_1 = RHhrTmm(prec, latt, lonn, 1)\n",
    "    ds_RHhrTmm_3 = RHhrTmm(prec, latt, lonn, 3)\n",
    "    ds_RHhrTmm_6 = RHhrTmm(prec, latt, lonn, 6)\n",
    "    ds_RHhrTmm_12 = RHhrTmm(prec, latt, lonn, 12)\n",
    "    ds_RHhrTmm_24 = RHhrTmm(prec, latt, lonn, 24)\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_NWH = NWH(prec, latt, lonn)\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_MeLWS_MxLWS = MeLWS_MxLWS(prec,latt,lonn)\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_SPIIHhr_1 = SPIIHhr(prec, latt, lonn, 1)\n",
    "    ds_SPIIHhr_3 = SPIIHhr(prec, latt, lonn, 3)\n",
    "    ds_SPIIHhr_6 = SPIIHhr(prec, latt, lonn, 6)\n",
    "    ds_SPIIHhr_12 = SPIIHhr(prec, latt, lonn, 12)\n",
    "    ds_SPIIHhr_24 = SPIIHhr(prec, latt, lonn, 24)\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_RTot = RTot(prec,latt,lonn)\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    \n",
    "    ################################################################################################\n",
    "    \n",
    "    \n",
    "    ds_RxHhr_1.to_netcdf(output_folder+'ds_RxHhr_1_'+folder+'.nc')\n",
    "    ds_RxHhr_3.to_netcdf(output_folder+'ds_RxHhr_3_'+folder+'.nc')\n",
    "    ds_RxHhr_6.to_netcdf(output_folder+'ds_RxHhr_6_'+folder+'.nc')\n",
    "    ds_RxHhr_12.to_netcdf(output_folder+'ds_RxHhr_12_'+folder+'.nc')\n",
    "    ds_RxHhr_24.to_netcdf(output_folder+'ds_RxHhr_24_'+folder+'.nc')\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_Rx1hrP.to_netcdf(output_folder+'ds_Rx1hrP_'+folder+'.nc')\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_percent.to_netcdf(output_folder+'ds_percent_'+folder+'.nc')\n",
    "    ds_quantile.to_netcdf(output_folder+'ds_quantile_'+folder+'.nc')\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_RHhrTmm_1.to_netcdf(output_folder+'ds_RHhrTmm_1_'+folder+'.nc')\n",
    "    ds_RHhrTmm_3.to_netcdf(output_folder+'ds_RHhrTmm_3_'+folder+'.nc')\n",
    "    ds_RHhrTmm_6.to_netcdf(output_folder+'ds_RHhrTmm_6_'+folder+'.nc')\n",
    "    ds_RHhrTmm_12.to_netcdf(output_folder+'ds_RHhrTmm_12_'+folder+'.nc')\n",
    "    ds_RHhrTmm_24.to_netcdf(output_folder+'ds_RHhrTmm_24_'+folder+'.nc')\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_NWH.to_netcdf(output_folder+'ds_NWH_'+folder+'.nc')\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_MeLWS_MxLWS.to_netcdf(output_folder+'ds_MeLWS_MxLWS_'+folder+'.nc')\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_SPIIHhr_1.to_netcdf(output_folder+'ds_SPIIHhr_1_'+folder+'.nc')\n",
    "    ds_SPIIHhr_3.to_netcdf(output_folder+'ds_SPIIHhr_3_'+folder+'.nc')\n",
    "    ds_SPIIHhr_6.to_netcdf(output_folder+'ds_SPIIHhr_6_'+folder+'.nc')\n",
    "    ds_SPIIHhr_12.to_netcdf(output_folder+'ds_SPIIHhr_12_'+folder+'.nc')\n",
    "    ds_SPIIHhr_24.to_netcdf(output_folder+'ds_SPIIHhr_24_'+folder+'.nc')\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "    ds_RTot.to_netcdf(output_folder+'ds_RTot_'+folder+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ade8c53-03f9-4364-ad1b-308fb920b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_NWH.to_netcdf(output_folder+'ds_NWH_'+folder+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a51082-9b11-4f41-a1bf-bdd8674fea4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gongg)",
   "language": "python",
   "name": "gongg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
